[{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"the-challenge-of-event-related-fmri-analysis","dir":"Articles","previous_headings":"","what":"The Challenge of Event-Related fMRI Analysis","title":"Getting Started with fmrilss","text":"Imagine ’re analyzing fMRI experiment participants view different images rapid succession, seconds stimulus. want estimate brain’s response individual image, ’s problem: hemodynamic response unfolds slowly 10-15 seconds, causing responses consecutive trials overlap substantially. Traditional approaches model trials simultaneously single general linear model (GLM) can suffer collinearity, especially trials occur close together. collinearity makes difficult obtain reliable, trial-specific activation estimates essential techniques like multivariate pattern analysis (MVPA) trial--trial connectivity analyses. Least Squares Separate (LSS) approach, introduced Mumford colleagues 2012, offers elegant solution problem. Rather estimating trials , LSS fits separate GLM trial, dramatically reducing collinearity producing reliable trial-specific estimates. fmrilss package brings fast, flexible implementation powerful method, modern enhancements make practical large-scale analyses.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"understanding-the-lss-approach","dir":"Articles","previous_headings":"","what":"Understanding the LSS Approach","title":"Getting Started with fmrilss","text":"diving implementation, let’s build intuition LSS works. vignette assumes ’re familiar basic fMRI analysis concepts like general linear model, design matrices, hemodynamic response function (HRF). also comfortable R programming basic matrix operations, ’ll working throughout. standard GLM analysis (often called Least Squares LSA), create design matrix separate columns trial estimate beta coefficients simultaneously. trials closely spaced, columns become highly correlated, leading unstable estimates. LSS takes different approach: trial interest, creates simplified model just two main regressors. first regressor models trial ’re currently interested , second aggregates trials single regressor. process repeats every trial, yielding unique, stable beta estimate one. Beyond two core regressors, LSS models can include experimental regressors capture session-wide effects like linear trends block effects, want model don’t need trial-specific estimates . model can also incorporate nuisance regressors motion parameters physiological noise, projected analysis begins.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"your-first-lss-analysis","dir":"Articles","previous_headings":"","what":"Your First LSS Analysis","title":"Getting Started with fmrilss","text":"Let’s walk complete example demonstrates power LSS. ’ll start creating synthetic data mimics typical rapid event-related design, compare different analysis approaches see LSS performs.","code":"library(fmrihrf) #>  #> Attaching package: 'fmrihrf' #> The following object is masked from 'package:stats': #>  #>     deriv library(fmrilss)  set.seed(42) n_timepoints <- 150 n_trials <- 12 n_voxels <- 25"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"creating-the-experimental-design","dir":"Articles","previous_headings":"Your First LSS Analysis","what":"Creating the Experimental Design","title":"Getting Started with fmrilss","text":"foundation fMRI analysis design matrix, encodes stimuli presented expect brain respond. example, ’ll simulate experiment trials occurring regular intervals, common many cognitive neuroscience studies. trial matrix X represents expected BOLD response trial, typically convolved HRF (though ’re using simplified box-car function clarity). experimental regressors Z capture effects vary across session trial--trial, baseline activation levels linear drift. nuisance matrix contains signals want remove, like head motion breathing artifacts.","code":"# Trial design matrix (X) X <- matrix(0, n_timepoints, n_trials) # Ensure integer onsets within bounds onsets <- round(seq(from = 10, to = n_timepoints - 12, length.out = n_trials)) for(i in 1:n_trials) {   X[onsets[i]:(onsets[i] + 5), i] <- 1 }  # Experimental regressors (Z) - intercept and condition effects # These are regressors we want to model and get estimates for, but not trial-wise Z <- cbind(Intercept = 1, LinearTrend = as.vector(scale(1:n_timepoints, center = TRUE, scale = FALSE)))  # Nuisance regressors - e.g., 6 motion parameters Nuisance <- matrix(rnorm(n_timepoints * 6), n_timepoints, 6)"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"visualizing-regressors","dir":"Articles","previous_headings":"Your First LSS Analysis","what":"Visualizing Regressors","title":"Getting Started with fmrilss","text":"fitting models, helps quickly inspect experimental nuisance regressors. clean plots session‑wide experimental effects (excluding intercept) nuisance regressors, standardized comparability. ggplot2 available, use polished visuals; otherwise fall back base R.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"single-trial-regressors","dir":"Articles","previous_headings":"Your First LSS Analysis","what":"Single-Trial Regressors","title":"Getting Started with fmrilss","text":"compact way view per‑trial regressors heatmap (time × trial). makes overlaps spacing immediately visible.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"generating-realistic-data","dir":"Articles","previous_headings":"Your First LSS Analysis","what":"Generating Realistic Data","title":"Getting Started with fmrilss","text":"Now ’ll create synthetic fMRI data includes contributions components, plus noise make realistic:","code":"# Simulate effects for each component true_trial_betas <- matrix(rnorm(n_trials * n_voxels, 0, 1.2), n_trials, n_voxels) true_fixed_effects <- matrix(rnorm(2 * n_voxels, c(5, -0.1), 0.5), 2, n_voxels) true_nuisance_effects <- matrix(rnorm(6 * n_voxels, 0, 2), 6, n_voxels)  # Combine signals and add noise Y <- (Z %*% true_fixed_effects) +      (X %*% true_trial_betas) +      (Nuisance %*% true_nuisance_effects) +      matrix(rnorm(n_timepoints * n_voxels, 0, 1), n_timepoints, n_voxels)"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"running-the-analysis","dir":"Articles","previous_headings":"Your First LSS Analysis","what":"Running the Analysis","title":"Getting Started with fmrilss","text":"lss() function provides clean, modern interface adapts needs. simplest, can provide just data trial matrix, function automatically includes intercept term: complete analysis accounts experimental effects removes nuisance signals, include Z Nuisance matrices. function handles nuisance regression efficiently, projecting signals data design matrix estimating trial-specific betas:","code":"beta_basic <- lss(Y, X) # The result is a trials-by-voxels matrix dim(beta_basic) #> [1] 12 25 beta_full <- lss(Y, X, Z = Z, Nuisance = Nuisance) # The output dimensions remain the same dim(beta_full) #> [1] 12 25"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"choosing-the-right-computational-backend","dir":"Articles","previous_headings":"","what":"Choosing the Right Computational Backend","title":"Getting Started with fmrilss","text":"fmrilss package offers multiple computational backends, optimized different scenarios. default R implementation well-optimized readable, making excellent understanding algorithm debugging, ’ll often want use high-performance C++ backend real analyses, especially large datasets. C++ implementation leverages Armadillo efficient linear algebra OpenMP parallel processing across multiple CPU cores: beauty design can seamlessly switch backends without changing code, allowing use readable R implementation development optimized C++ version production analyses.","code":"# Run the same analysis with the high-performance C++ engine beta_fast <- lss(Y, X, Z = Z, Nuisance = Nuisance, method = \"cpp_optimized\")  # The results are numerically identical to the R version all.equal(beta_full, beta_fast, tolerance = 1e-8) #> [1] TRUE"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"lss-versus-traditional-glm-when-each-shines","dir":"Articles","previous_headings":"","what":"LSS versus Traditional GLM: When Each Shines","title":"Getting Started with fmrilss","text":"understand LSS offers advantages traditional approaches, let’s compare standard Least Squares (LSA) method estimates trials simultaneously:  comparison reveals important differences methods. LSS typically produces beta estimates different variance characteristics LSA, can advantageous certain analyses. choose one ? MVPA analyses, LSS generally performs better reduces collinearity trial estimates, leading distinguishable patterns. rapid event-related designs hemodynamic responses overlap substantially, LSS’s approach isolating trial helps maintain estimate stability. However, block designs well-separated trials, need compute group-level contrasts benefit stability simultaneous estimation, LSA might appropriate. Connectivity analyses require trial-specific estimates particularly benefit LSS’s approach.","code":"# LSA: Standard GLM with all trials in one model beta_lsa <- lsa(Y, X, Z = Z, Nuisance = Nuisance)  # Compare dimensions cat(\"LSS beta dimensions:\", dim(beta_full), \"\\n\") #> LSS beta dimensions: 12 25 cat(\"LSA beta dimensions:\", dim(beta_lsa), \"\\n\") #> LSA beta dimensions: 12 25  # Compare variance in beta estimates var_lss <- apply(beta_full, 2, var) var_lsa <- apply(beta_lsa, 2, var)  cat(\"\\nMean variance across voxels:\\n\") #>  #> Mean variance across voxels: cat(\"  LSS:\", mean(var_lss), \"\\n\") #>   LSS: 1.826826 cat(\"  LSA:\", mean(var_lsa), \"\\n\") #>   LSA: 4.297449  # Plot comparison par(mfrow = c(1, 2)) hist(beta_full[, 1], main = \"LSS: Beta distribution (Voxel 1)\",      xlab = \"Beta values\", col = \"lightblue\") hist(beta_lsa[, 1], main = \"LSA: Beta distribution (Voxel 1)\",      xlab = \"Beta values\", col = \"lightgreen\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"introducing-the-oasis-method","dir":"Articles","previous_headings":"","what":"Introducing the OASIS Method","title":"Getting Started with fmrilss","text":"standard LSS implementation powerful, package also includes OASIS (Optimized Analytic Single-pass Inverse Solution) method, extends LSS several sophisticated features. OASIS automatically estimates hemodynamic response functions, applies ridge regularization enhanced stability, provides efficient computation complex designs, includes built-support multi-basis HRF models. ’s taste OASIS can :","code":"# Basic OASIS usage # fmrihrf is now imported automatically beta_oasis <- lss(   Y = Y,   X = NULL,  # OASIS builds design internally   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sampling_frame(blocklens = nrow(Y), TR = 1),       cond = list(         onsets = onsets,        # reuse onsets from above         hrf = HRF_SPMG1,        # HRF model         span = 30       )     ),     ridge_mode = \"fractional\",     ridge_x = 0.01,     ridge_b = 0.01   ) )  cat(\"OASIS beta dimensions:\", dim(beta_oasis), \"\\n\") #> OASIS beta dimensions: 12 25"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"working-with-different-computational-backends","dir":"Articles","previous_headings":"","what":"Working with Different Computational Backends","title":"Getting Started with fmrilss","text":"package provides multiple backends match computational needs resources. backend implements algorithm different optimization strategies. naive implementation offers clearest code understanding algorithm, vectorized optimized R versions provide good performance pure R code. production work large datasets, C++ backend offers best performance, especially combined parallel processing.","code":"# Benchmark different methods library(microbenchmark)  methods <- c(\"naive\", \"r_vectorized\", \"r_optimized\", \"cpp_optimized\") timings <- list()  for (m in methods) {   timings[[m]] <- system.time({     lss(Y, X, method = m)   })[3] }  # Display timing comparison timing_df <- data.frame(   Method = methods,   Time = unlist(timings) ) print(timing_df)  # For large datasets, consider threading for C++ backends if (require(\"parallel\")) {   n_cores <- parallel::detectCores() - 1   # Set OpenMP threads for C++ backend if supported   Sys.setenv(OMP_NUM_THREADS = n_cores) }"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"handling-complex-experimental-designs","dir":"Articles","previous_headings":"","what":"Handling Complex Experimental Designs","title":"Getting Started with fmrilss","text":"Real experiments often involve multiple conditions, parametric modulations, various covariates. fmrilss package handles complexities gracefully. working multiple conditions, can create separate design matrices condition include condition labels experimental regressors. allows model condition-specific effects still obtaining trial-wise estimates within condition. Parametric modulations, trial responses weighted continuous variables like reaction time stimulus intensity, also straightforward implement. quantitative demo, simulate parametric effect data show recovery without modulator:","code":"# Create design with multiple conditions n_cond <- 3 X_multi <- matrix(0, n_timepoints, n_trials * n_cond)  # Generate a simple HRF for demonstration hrf <- c(0, 0.2, 0.5, 0.8, 1, 0.9, 0.7, 0.5, 0.3, 0.1)  for (c in 1:n_cond) {   trial_idx <- ((c-1) * n_trials + 1):(c * n_trials)   for (i in 1:n_trials) {     onset <- 10 + (trial_idx[i] - 1) * 5     if (onset + 9 <= n_timepoints) {       X_multi[onset:(onset + 9), trial_idx[i]] <- hrf     }   } }  # Add condition labels as experimental regressors Z_cond <- matrix(0, n_timepoints, n_cond) for (c in 1:n_cond) {   trial_idx <- ((c-1) * n_trials + 1):(c * n_trials)   Z_cond[, c] <- rowSums(X_multi[, trial_idx, drop = FALSE]) }  # Run LSS with condition regressors beta_multi <- lss(Y, X_multi, Z = Z_cond, method = \"r_optimized\") #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_28' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_29' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_30' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_31' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_32' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_33' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_34' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_35' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_36' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .lss_engine_optimized(dset = dset, bdes = bdes, Y = Y, use_cpp = #> use_cpp): No intercept detected in dmat_base. Consider adding one for proper #> baseline modeling. # Add parametric modulator (e.g., reaction time, stimulus intensity) modulator <- scale(rnorm(n_trials, mean = 0, sd = 1), center = TRUE, scale = FALSE)  # Create parametrically modulated design (scale each trial by its modulator) X_param <- sweep(X, 2, as.numeric(modulator), `*`)  # Simulate data with a parametric effect (reuse fixed and nuisance parts) Y_mod <- (Z %*% true_fixed_effects) +          (X_param %*% true_trial_betas) +          (Nuisance %*% true_nuisance_effects) +          matrix(rnorm(n_timepoints * n_voxels, 0, 1), n_timepoints, n_voxels)  # Fit models with and without the parametric modulator beta_unmod <- lss(Y_mod, X,       Z = Z, method = \"r_optimized\") beta_param <- lss(Y_mod, X_param, Z = Z, method = \"r_optimized\")  # Ground truths for comparison # - For unmodulated design X, the true coefficients are modulator * true_trial_betas true_unmod_coefs <- sweep(true_trial_betas, 1, as.numeric(modulator), `*`) # - For parametrically modulated design X_param, the true coefficients are true_trial_betas  cor_unmod <- cor(as.vector(beta_unmod), as.vector(true_unmod_coefs)) cor_param <- cor(as.vector(beta_param), as.vector(true_trial_betas))  cat(\"Correlation with true coefficients (parametric effect simulated):\\n\") #> Correlation with true coefficients (parametric effect simulated): cat(\"  Using X (no modulator):\\t\", round(cor_unmod, 3), \"\\n\") #>   Using X (no modulator):     0.532 cat(\"  Using X_param (with modulator):\", round(cor_param, 3), \"\\n\") #>   Using X_param (with modulator): 0.37"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"optimizing-performance-for-large-scale-analyses","dir":"Articles","previous_headings":"","what":"Optimizing Performance for Large-Scale Analyses","title":"Getting Started with fmrilss","text":"working whole-brain data containing hundreds thousands voxels, memory management computational efficiency become critical. package provides several strategies handling large datasets effectively. large datasets exceed available memory, can process voxels chunks. approach maintains reasonable memory usage still benefiting vectorized operations within chunk: Another optimization strategy involves preprocessing data remove nuisance signals running LSS. LSS can handle nuisance regressors internally, preprocessing can efficient running multiple analyses: Choosing right backend data size crucial optimal performance. rule thumb, small datasets fewer 100 voxels, optimized R implementation usually fast enough offers advantage easily debuggable. medium-sized datasets 10,000 voxels, C++ backend provides significant speedup. large whole-brain datasets, consider using OASIS, implements additional optimizations handling massive design matrices efficiently.","code":"# For very large datasets, process in chunks chunk_size <- 1000 n_chunks <- ceiling(ncol(Y) / chunk_size)  beta_chunks <- list() for (chunk in 1:n_chunks) {   voxel_idx <- ((chunk - 1) * chunk_size + 1):min(chunk * chunk_size, ncol(Y))   beta_chunks[[chunk]] <- lss(Y[, voxel_idx], X, method = \"cpp_optimized\") }  # Combine results beta_full <- do.call(cbind, beta_chunks) # Project out nuisance before LSS (when appropriate) # project_confounds returns the projection matrix Q; apply it to both Y and X Q_nuis <- project_confounds(Nuisance) Y_clean <- Q_nuis %*% Y X_clean <- Q_nuis %*% X  # This can be faster than including Nuisance in each LSS iteration beta_preprocessed <- lss(Y_clean, X_clean, Z = Z, method = \"r_optimized\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"troubleshooting-common-challenges","dir":"Articles","previous_headings":"","what":"Troubleshooting Common Challenges","title":"Getting Started with fmrilss","text":"Even robust implementations, certain data characteristics can cause issues. Understanding diagnose address problems help get analyses. design matrices become singular near-singular due high collinearity regressors, standard least squares solutions become unstable. can detect examining correlation matrix design: Memory limitations can also pose challenges large datasets. starting analysis, ’s wise estimate memory requirements adjust approach accordingly: encounter unexpectedly slow performance, profiling can help identify bottlenecks:","code":"# Check for collinearity cor_matrix <- cor(X) high_cor <- which(abs(cor_matrix) > 0.9 & cor_matrix != 1, arr.ind = TRUE)  if (nrow(high_cor) > 0) {   warning(\"High correlation between regressors detected\")   # Consider using ridge regression via OASIS   beta_ridge <- lss(Y, X, method = \"oasis\",                     oasis = list(ridge_mode = \"absolute\", ridge_x = 0.1)) } # Monitor memory usage mem_required <- object.size(Y) * n_trials * 2  # Rough estimate # mem_available <- memory.limit()  # Windows only  # if (mem_required > mem_available * 0.8) { #   warning(\"May run out of memory. Consider chunking or using OASIS.\") # } # Profile code to find bottlenecks Rprof(\"lss_profile.out\") beta_slow <- lss(Y, X, method = \"naive\") Rprof(NULL) summaryRprof(\"lss_profile.out\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"where-to-go-from-here","dir":"Articles","previous_headings":"","what":"Where to Go From Here","title":"Getting Started with fmrilss","text":"vignette introduced core concepts capabilities fmrilss package. ’ve learned LSS addresses collinearity problem rapid event-related designs, choose different computational backends, strategies handling complex experimental designs large datasets. deepen understanding explore advanced features, recommend examining voxel-wise HRF vignette, demonstrates model spatial variation hemodynamic responses across brain. OASIS method vignette provides comprehensive coverage powerful extension, including HRF estimation ridge regression techniques. interested hierarchical analyses, mixed models vignette shows combine LSS mixed-effects modeling frameworks. fmrilss package represents comprehensive toolkit trial-wise beta estimation, providing options range simple, interpretable implementations highly optimized solutions large-scale analyses. Whether ’re conducting exploratory analyses laptop processing massive datasets computing cluster, package offers flexibility performance need modern fMRI analysis.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Getting Started with fmrilss","text":"Mumford, J. ., Turner, B. O., Ashby, F. G., & Poldrack, R. . (2012). Deconvolving BOLD activation event-related designs multivoxel pattern classification analyses. NeuroImage, 59(3), 2636-2643.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"the-computational-challenge-of-modern-fmri","dir":"Articles","previous_headings":"","what":"The Computational Challenge of Modern fMRI","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Imagine ’re working cutting-edge fMRI dataset: sub-millimeter resolution, thousands trials, complex overlapping designs, need trial-specific estimates hundreds thousands voxels. standard LSS approach, theoretically sound, requires fitting separate models trial voxel—potentially millions model fits. large datasets, computational burden becomes significant. way achieve theoretical results efficiently? Enter OASIS—Optimized Analytic Single-pass Inverse Solution—method reimagines compute LSS estimates. Rather iterating trials one one, OASIS leverages clever mathematical reformulations compute trial estimates simultaneously single, highly optimized pass. OASIS just speed improvement; brings sophisticated features like automatic HRF estimation, ridge regularization numerical stability, seamless handling multi-basis HRF models cumbersome implement traditional frameworks. vignette assumes ’re comfortable basic LSS concepts getting started guide, understand HRF models basis functions working neuroimaging data, familiarity ridge regression regularization concepts, know basics fmrihrf package HRF modeling. foundation, ’ll explore OASIS can transform approach trial-wise beta estimation.","code":"library(fmrihrf) #>  #> Attaching package: 'fmrihrf' #> The following object is masked from 'package:stats': #>  #>     deriv library(fmrilss) set.seed(42)  # Helper function to create design matrix using fmrihrf API # (design_matrix is not exported from fmrihrf, so we create a wrapper) design_matrix <- function(sframe, conditions, tr_per_trial = FALSE) {   # Helper to safely extract condition fields without partial matching   cond_field <- function(cond, name, default = NULL) {     if (!is.null(cond[[name]])) cond[[name]] else default   }    if (tr_per_trial) {     # Create trial-wise design (one column per trial)     X_list <- list()     for (cond in conditions) {       onsets <- cond_field(cond, \"onsets\")       n_trials <- length(onsets)       # Each trial gets its own regressor       X_trial <- fmrihrf::regressor_design(         onsets = onsets,         fac = factor(seq_len(n_trials)),  # Each trial is its own level         block = rep(1L, n_trials),        # Assume single block for simplicity         sframe = sframe,         hrf = cond_field(cond, \"hrf\", fmrihrf::HRF_SPMG1),         duration = cond_field(cond, \"duration\", 0),         span = cond_field(cond, \"span\", 30),         precision = cond_field(cond, \"precision\", 0.1),         method = cond_field(cond, \"method\", \"conv\"),         summate = FALSE  # Don't sum across trials       )       X_list[[length(X_list) + 1]] <- X_trial     }     X <- do.call(cbind, X_list)   } else {     # Create aggregate design (one column per condition)     X_list <- list()     for (cond in conditions) {       onsets <- cond_field(cond, \"onsets\")       n_trials <- length(onsets)       # All trials in same condition get summed       X_cond <- fmrihrf::regressor_design(         onsets = onsets,         fac = factor(rep(1L, n_trials)),  # All trials same level         block = rep(1L, n_trials),         sframe = sframe,         hrf = cond_field(cond, \"hrf\", fmrihrf::HRF_SPMG1),         duration = cond_field(cond, \"duration\", 0),         span = cond_field(cond, \"span\", 30),         precision = cond_field(cond, \"precision\", 0.1),         method = cond_field(cond, \"method\", \"conv\"),         summate = TRUE  # Sum across trials in condition       )       X_list[[length(X_list) + 1]] <- X_cond     }     X <- do.call(cbind, X_list)   }    list(X = as.matrix(X)) }"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"understanding-the-oasis-innovation","dir":"Articles","previous_headings":"","what":"Understanding the OASIS Innovation","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"key algebra OASIS leverages special structure LSS: although naïvely looks like N separate GLMs (one per trial), per‑trial designs share components let factor computation reuse across trials. Note factoring already exploited fmrilss’s optimized backends (e.g., fused single‑pass solver residualizes reuses totals cross‑products across trials). OASIS builds algebra extends event→design construction HRFs, multi‑basis models, stabilized, diagnostics‑ready closed‑form solves. Beyond computational efficiency, OASIS adds features generic LSS path expose: built‑ridge regularization (absolute fractional) two‑regressor Gram per trial, optional AR(1) whitening, analytical standard errors diagnostics, blocked multi‑basis solver treats K>1 HRF bases 2K×2K closed‑form systems per trial. Finally, OASIS integrates directly fmrihrf: builds trial‑wise designs event specs (including multi‑condition aggregates), auto‑detects basis dimension K, supports FIR/non‑parametric bases, can run fast HRF grid selection fitting. removes manual design construction preserving exact LSS equivalence.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"what-oasis-adds-over-optimized-lss","dir":"Articles","previous_headings":"Understanding the OASIS Innovation","what":"What OASIS Adds Over Optimized LSS","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"HRF‑aware design: Builds X events via fmrihrf (single multi‑basis), optional HRF grid search. Stabilization: Ridge regularization per‑trial Gram (absolute fractional scaling design energy). Inference: Optional standard errors design diagnostics without extra passes. Whitening: Optional AR(1) prewhitening applied consistently data design. Multi‑basis efficiency: Blocked products 2K×2K closed‑form solves K>1 bases.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"starting-with-oasis-a-simple-example","dir":"Articles","previous_headings":"","what":"Starting with OASIS: A Simple Example","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Let’s begin straightforward example demonstrates OASIS action. ’ll create synthetic data known ground truth, see OASIS recovers signal: Notice OASIS takes design specification rather pre-built design matrix. allows construct optimal internal representation efficient computation. results identical ’d get standard LSS, computed much efficiently.","code":"# Create synthetic data n_time <- 300 n_voxels <- 100 TR <- 1.0  # Generate event onsets (rapid design) onsets <- seq(10, 280, by = 15)  # Events every 15 seconds n_trials <- length(onsets)  # Create sampling frame sframe <- fmrihrf::sampling_frame(blocklens = n_time, TR = TR)  # Generate synthetic fMRI data Y <- matrix(rnorm(n_time * n_voxels), n_time, n_voxels)  # Add signal to data true_betas <- matrix(rnorm(n_trials * n_voxels, mean = 1, sd = 0.5),                      n_trials, n_voxels)  # Create signal using canonical HRF dm <- design_matrix(   sframe = sframe,   conditions = list(     list(onsets = onsets, hrf = fmrihrf::HRF_SPMG1, name = \"task\")   ),   tr_per_trial = TRUE )  Y <- Y + dm$X %*% true_betas  # Run OASIS beta_oasis <- lss(   Y = Y,   X = NULL,  # OASIS builds design internally   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(         onsets = onsets,         hrf = fmrihrf::HRF_SPMG1,         span = 30  # HRF duration       )     )   ) )  cat(\"OASIS results:\\n\") #> OASIS results: cat(\"  Beta dimensions:\", dim(beta_oasis), \"\\n\") #>   Beta dimensions: 19 100 cat(\"  Mean beta:\", round(mean(beta_oasis), 3), \"\\n\") #>   Mean beta: 1.01 cat(\"  Beta SD:\", round(sd(beta_oasis), 3), \"\\n\") #>   Beta SD: 0.587"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"the-power-of-ridge-regularization","dir":"Articles","previous_headings":"","what":"The Power of Ridge Regularization","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"One OASIS’s valuable features built-ridge regularization. rapid event-related designs, close temporal spacing trials can lead highly correlated regressors unstable estimates. Ridge regression adds small penalty term “shrinks” estimates toward zero, trading small amount bias large reduction variance. OASIS offers two approaches ridge regularization, suited different scenarios. Let’s explore :","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"absolute-ridge-regularization","dir":"Articles","previous_headings":"The Power of Ridge Regularization","what":"Absolute Ridge Regularization","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"absolute ridge, specify fixed penalty values added diagonal normal equations. approach gives direct control regularization strength:","code":"# Absolute ridge: fixed penalty values beta_ridge_abs <- lss(   Y = Y,   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(onsets = onsets, hrf = HRF_SPMG1, span = 30)     ),     ridge_mode = \"absolute\",     ridge_x = 0.1,  # Penalty on trial regressor     ridge_b = 0.1   # Penalty on aggregator regressor   ) )  # Compare with unregularized cat(\"Comparison with unregularized:\\n\") #> Comparison with unregularized: cat(\"  Correlation:\", round(cor(as.vector(beta_oasis),                                as.vector(beta_ridge_abs)), 3), \"\\n\") #>   Correlation: 1 cat(\"  Mean absolute difference:\",     round(mean(abs(beta_oasis - beta_ridge_abs)), 4), \"\\n\") #>   Mean absolute difference: 0.0092"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"fractional-ridge-regularization","dir":"Articles","previous_headings":"The Power of Ridge Regularization","what":"Fractional Ridge Regularization","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Fractional ridge scales penalty relative “energy” (sum squares) design matrix. adaptive approach automatically adjusts scale data: variance reduction demonstrates ridge regression’s stabilizing effect. practice, translates reliable estimates, especially noisy data complex designs.","code":"# Fractional ridge: penalty as fraction of design energy beta_ridge_frac <- lss(   Y = Y,   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(onsets = onsets, hrf = HRF_SPMG1, span = 30)     ),     ridge_mode = \"fractional\",     ridge_x = 0.05,  # 5% of mean design energy     ridge_b = 0.05   # 5% of mean aggregator energy   ) )  # Ridge typically reduces variance in estimates var_unreg <- apply(beta_oasis, 2, var) var_ridge <- apply(beta_ridge_frac, 2, var)  cat(\"\\nVariance reduction with ridge:\\n\") #>  #> Variance reduction with ridge: cat(\"  Mean variance (unregularized):\", round(mean(var_unreg), 4), \"\\n\") #>   Mean variance (unregularized): 0.3378 cat(\"  Mean variance (ridge):\", round(mean(var_ridge), 4), \"\\n\") #>   Mean variance (ridge): 0.3065 cat(\"  Reduction:\", round((1 - mean(var_ridge)/mean(var_unreg)) * 100, 1), \"%\\n\") #>   Reduction: 9.3 %"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"working-with-multi-basis-hrfs","dir":"Articles","previous_headings":"","what":"Working with Multi-Basis HRFs","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Real hemodynamic responses rarely match canonical HRF perfectly. might peak earlier later, wider narrower, different undershoot characteristics. Multi-basis HRF models capture variability representing response weighted combination basis functions. OASIS handles multi-basis HRFs naturally, returning separate estimates basis component:  multi-basis approach reveals hemodynamic response varies across trials. Large temporal derivative values suggest timing variability, dispersion derivative values indicate width changes. information can valuable understanding physiological variations task-related modulations hemodynamic response.","code":"# Use SPMG3: canonical + temporal derivative + dispersion derivative beta_spmg3 <- lss(   Y = Y,   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(         onsets = onsets,         hrf = HRF_SPMG3,  # 3 basis functions         span = 30       )     )   ) )  # SPMG3 returns K×N rows where K=number of basis functions, N=number of trials # The results are organized in blocks: [trial1_basis1, trial1_basis2, trial1_basis3, #                                       trial2_basis1, trial2_basis2, trial2_basis3, ...] cat(\"Multi-basis results:\\n\") #> Multi-basis results: cat(\"  Beta dimensions:\", dim(beta_spmg3), \"\\n\") #>   Beta dimensions: 57 100 cat(\"  Basis functions (K):\", 3, \"\\n\") #>   Basis functions (K): 3 cat(\"  Trials (N):\", n_trials, \"\\n\") #>   Trials (N): 19 cat(\"  Total rows (K×N):\", nrow(beta_spmg3), \"\\n\") #>   Total rows (K×N): 57  # Extract components using the K-stride pattern # For K=3 basis functions, every 3rd row starting from position k gives basis k K <- 3  # Number of basis functions in SPMG3 canonical_betas <- beta_spmg3[seq(1, nrow(beta_spmg3), by = K), ]    # Basis 1: Canonical temporal_betas <- beta_spmg3[seq(2, nrow(beta_spmg3), by = K), ]     # Basis 2: Temporal derivative dispersion_betas <- beta_spmg3[seq(3, nrow(beta_spmg3), by = K), ]   # Basis 3: Dispersion derivative  # Verify dimensions: each should be n_trials × n_voxels cat(\"\\nExtracted component dimensions:\\n\") #>  #> Extracted component dimensions: cat(\"  Each basis matrix:\", dim(canonical_betas), \"\\n\") #>   Each basis matrix: 19 100  # Analyze contributions cat(\"\\nBasis function contributions:\\n\") #>  #> Basis function contributions: cat(\"  Canonical mean |beta|:\", round(mean(abs(canonical_betas)), 3), \"\\n\") #>   Canonical mean |beta|: 1.046 cat(\"  Temporal deriv mean |beta|:\", round(mean(abs(temporal_betas)), 3), \"\\n\") #>   Temporal deriv mean |beta|: 0.686 cat(\"  Dispersion deriv mean |beta|:\", round(mean(abs(dispersion_betas)), 3), \"\\n\") #>   Dispersion deriv mean |beta|: 1.235  # Visualize first voxel par(mfrow = c(1, 3)) plot(canonical_betas[, 1], type = \"b\", main = \"Canonical\",      ylab = \"Beta\", xlab = \"Trial\") plot(temporal_betas[, 1], type = \"b\", main = \"Temporal Derivative\",      ylab = \"Beta\", xlab = \"Trial\") plot(dispersion_betas[, 1], type = \"b\", main = \"Dispersion Derivative\",      ylab = \"Beta\", xlab = \"Trial\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"non-parametric-hrf-modeling-with-fir","dir":"Articles","previous_headings":"","what":"Non-Parametric HRF Modeling with FIR","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Sometimes want make assumptions HRF shape . Finite Impulse Response (FIR) basis provides completely non-parametric approach, estimating response time point independently:  FIR approach reveals actual shape hemodynamic response without parametric constraints. trial now contributes one coefficient per time bin, individual voxel-level estimates can look jagged—variance simply much higher single-parameter canonical fit. Averaging across trials voxels (adding modest ridge penalty) recovers smooth, HRF-like curve still allowing deviations canonical shape. practice typically pool information across voxels/regions apply additional smoothing/regularization working FIR bases.","code":"# Create FIR basis with 15 time bins (2s width over a 30s window) fir_hrf <- hrf_fir_generator(nbasis = 15, span = 30) fir_params <- attr(fir_hrf, \"params\") bin_width <- as.numeric(fir_params[[\"bin_width\"]]) n_bins <- attr(fir_hrf, \"nbasis\")  beta_fir <- lss(   Y = Y,   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(         onsets = onsets,         hrf = fir_hrf,         span = 30       )     ),     ridge_mode = \"fractional\",     ridge_x = 0.2,  # Moderate ridge improves stability for high-dimensional FIR fits     ridge_b = 0.2   ) )  cat(\"FIR basis results:\\n\") #> FIR basis results: cat(\"  Beta dimensions:\", dim(beta_fir), \"\\n\") #>   Beta dimensions: 285 100 cat(\"  Time bins per trial:\", nrow(beta_fir) / n_trials, \"\\n\") #>   Time bins per trial: 15  # Organise coefficients as (time bin × trial × voxel) fir_array <- array(beta_fir, dim = c(n_bins, n_trials, ncol(beta_fir)))  # Average across trials and voxels to recover a smooth HRF estimate fir_mean <- apply(fir_array, 1, mean) fir_se <- apply(fir_array, 1, sd) / sqrt(n_trials * ncol(beta_fir)) time_points <- seq(0, (n_bins - 1) * bin_width, by = bin_width)  # Plot mean HRF with ±1 SE ribbon upper <- fir_mean + fir_se lower <- fir_mean - fir_se  plot(time_points, fir_mean, type = \"l\",      ylim = range(c(lower, upper)),      main = \"FIR-derived HRF (mean across trials/voxels)\",      xlab = \"Time (seconds)\", ylab = \"Response\",      col = \"navy\", lwd = 2) polygon(c(time_points, rev(time_points)), c(upper, rev(lower)),         col = grDevices::adjustcolor(\"navy\", alpha.f = 0.2), border = NA) lines(time_points, fir_mean, col = \"navy\", lwd = 2)  # Add canonical HRF sampled on the same grid for reference canonical <- evaluate(HRF_SPMG1, time_points) scale_factor <- max(fir_mean) / max(canonical) lines(time_points, canonical * scale_factor, col = \"firebrick\", lty = 2, lwd = 2) legend(\"topright\",        c(\"FIR mean\", \"±1 SE\", \"Canonical (scaled)\"),        col = c(\"navy\", NA, \"firebrick\"),        lty = c(1, NA, 2),        lwd = c(2, NA, 2),        pch = c(NA, 15, NA),        pt.cex = c(NA, 2, NA),        pt.bg = c(NA, grDevices::adjustcolor(\"navy\", alpha.f = 0.2), NA),        bty = \"n\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"optimizing-hrf-models-through-grid-search","dir":"Articles","previous_headings":"","what":"Optimizing HRF Models Through Grid Search","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"’re unsure HRF model best fits data, OASIS can efficiently evaluate multiple candidates. exploratory approach helps identify optimal HRF parameters specific dataset brain regions: Grid search reveals HRF parameters best explain data. data-driven approach can uncover unexpected characteristics hemodynamic response specific experimental context.","code":"# Source HRF recovery functions (from previous vignette) source(\"../R/oasis_hrf_recovery.R\")  # Create a grid of HRF models with varying parameters hrf_grid <- create_lwu_grid(   tau_range = c(4, 8),      # Peak time   sigma_range = c(2, 3.5),  # Width   rho_range = c(0.2, 0.5),  # Undershoot   n_tau = 3,   n_sigma = 2,   n_rho = 2 )  cat(\"Testing\", length(hrf_grid$hrfs), \"different HRF models\\n\\n\") #> Testing 12 different HRF models  # Test each HRF and select best based on fit best_fit <- -Inf best_idx <- 1  for (i in seq_along(hrf_grid$hrfs)) {   # Create HRF object   tau_val <- hrf_grid$parameters$tau[i]   sigma_val <- hrf_grid$parameters$sigma[i]   rho_val <- hrf_grid$parameters$rho[i]    hrf_obj <- structure(     function(t) {       hrf_lwu(t, tau = tau_val, sigma = sigma_val, rho = rho_val, normalize = \"height\")     },     class = c(\"hrf\", \"function\"),     span = 30   )    # Fit OASIS with this HRF   beta_test <- lss(     Y = Y[, 1:10],  # Test on subset for speed     X = NULL,     method = \"oasis\",     oasis = list(       design_spec = list(         sframe = sframe,         cond = list(onsets = onsets, hrf = hrf_obj, span = 30)       ),       ridge_mode = \"fractional\",       ridge_x = 0.01,       ridge_b = 0.01     )   )    # Calculate fit (simplified - residual sum of squares)   X_test <- design_matrix(     sframe = sframe,     conditions = list(list(onsets = onsets, hrf = hrf_obj)),     tr_per_trial = TRUE   )$X    fitted <- X_test %*% beta_test   rss <- sum((Y[, 1:10] - fitted)^2)    if (-rss > best_fit) {     best_fit <- -rss     best_idx <- i   } }  cat(\"Best HRF parameters:\\n\") #> Best HRF parameters: cat(\"  tau:\", hrf_grid$parameters$tau[best_idx], \"\\n\") #>   tau: 4 cat(\"  sigma:\", hrf_grid$parameters$sigma[best_idx], \"\\n\") #>   sigma: 2 cat(\"  rho:\", hrf_grid$parameters$rho[best_idx], \"\\n\") #>   rho: 0.2"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"handling-complex-experimental-designs","dir":"Articles","previous_headings":"","what":"Handling Complex Experimental Designs","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Real experiments often involve multiple conditions, trials interest others serving nuisance events. OASIS elegantly handles complex scenarios: approach ensures variance conditions properly accounted without conflating trials interest.","code":"# Create design with two conditions onsets_cond1 <- seq(10, 280, by = 30) onsets_cond2 <- seq(25, 280, by = 30)  # Condition 1 as target, Condition 2 as nuisance beta_multi <- lss(   Y = Y,   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(         onsets = onsets_cond1,         hrf = HRF_SPMG1,         span = 30       ),       others = list(         list(onsets = onsets_cond2)  # Other conditions as nuisance       )     )   ) )  cat(\"Multi-condition OASIS:\\n\") #> Multi-condition OASIS: cat(\"  Analyzing condition 1 trials:\", length(onsets_cond1), \"\\n\") #>   Analyzing condition 1 trials: 10 cat(\"  Condition 2 included as nuisance\\n\") #>   Condition 2 included as nuisance cat(\"  Beta dimensions:\", dim(beta_multi), \"\\n\") #>   Beta dimensions: 10 100"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"beyond-point-estimates-standard-errors-and-diagnostics","dir":"Articles","previous_headings":"","what":"Beyond Point Estimates: Standard Errors and Diagnostics","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"beta estimates valuable, understanding uncertainty crucial proper inference. OASIS can provide standard errors diagnostic information:  Standard errors reveal estimates reliable. Trials higher standard errors might overlapping responses occurring periods higher noise.","code":"# Request standard errors result_with_se <- lss(   Y = Y[, 1:10],  # Subset for demonstration   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(onsets = onsets[1:10], hrf = HRF_SPMG1, span = 30)     ),     return_se = TRUE,     return_diag = TRUE   ) )  cat(\"Results with diagnostics:\\n\") #> Results with diagnostics: cat(\"  Beta dimensions:\", dim(result_with_se$beta), \"\\n\") #>   Beta dimensions: 10 10 cat(\"  SE dimensions:\", dim(result_with_se$se), \"\\n\") #>   SE dimensions: 10 10 cat(\"  Mean SE:\", round(mean(result_with_se$se), 4), \"\\n\") #>   Mean SE: 0.3537  # Calculate t-statistics t_stats <- result_with_se$beta / result_with_se$se cat(\"  Mean |t-statistic|:\", round(mean(abs(t_stats)), 2), \"\\n\") #>   Mean |t-statistic|: 2.43  # Visualize SE across trials plot(rowMeans(result_with_se$se), type = \"b\",      main = \"Standard Error Across Trials\",      xlab = \"Trial\", ylab = \"Mean SE\",      col = \"darkblue\", pch = 19)"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"performance-in-practice","dir":"Articles","previous_headings":"","what":"Performance in Practice","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"understand OASIS’s efficiency, let’s conduct systematic benchmarks comparing traditional LSS implementations across different dataset sizes:  capability allows test hypotheses hemodynamic response characteristics adapt models software packages.","code":"# Benchmark across different dataset sizes sizes <- list(   small  = list(timepoints = 300, voxels = 500),   medium = list(timepoints = 400, voxels = 2000),   large  = list(timepoints = 600, voxels = 8000),   xlarge = list(timepoints = 800, voxels = 16000) )  benchmark_results <- data.frame()  for (size_name in names(sizes)) {   n_time <- sizes[[size_name]][['timepoints']]   n_vox  <- sizes[[size_name]][['voxels']]    # Create test data   Y_bench <- matrix(rnorm(n_time * n_vox), n_time, n_vox)    # Create sampling frame and onsets for this size   sframe_bench <- fmrihrf::sampling_frame(blocklens = n_time, TR = TR)   n_trials <- min(60, floor(n_time / 10))   onsets_bench <- seq(10, n_time - 20, length.out = n_trials)    # Standard LSS with pre-built design (shared across methods)   dm_bench <- design_matrix(     sframe = sframe_bench,     conditions = list(list(onsets = onsets_bench, hrf = fmrihrf::HRF_SPMG1)),     tr_per_trial = TRUE   )[['X']]    # Time standard LSS (R optimized)   time_r_opt <- system.time({     beta_r <- lss(Y_bench, dm_bench, method = \"r_optimized\")   })[3]    # Time standard LSS (C++ optimized)   time_cpp <- system.time({     beta_cpp <- lss(Y_bench, dm_bench, method = \"cpp_optimized\")   })[3]    # Time OASIS using the pre-built design (fair comparison)   time_oasis <- system.time({     beta_oasis <- lss(Y = Y_bench, X = dm_bench, method = \"oasis\")   })[3]    # Time OASIS when it also has to build the design internally   time_oasis_build <- system.time({     beta_oasis_build <- lss(       Y = Y_bench,       X = NULL,       method = \"oasis\",       oasis = list(         design_spec = list(           sframe = sframe_bench,           cond = list(             onsets = onsets_bench,             hrf = fmrihrf::HRF_SPMG1,             span = 30           )         )       )     )   })[3]    # Store results   benchmark_results <- rbind(benchmark_results, data.frame(     Size = size_name,     Timepoints = n_time,     Voxels = n_vox,     Trials = n_trials,     R_Optimized = time_r_opt,     CPP_Optimized = time_cpp,     OASIS = time_oasis,     OASIS_with_design = time_oasis_build,     Speedup_vs_R = time_r_opt / time_oasis,     Speedup_vs_CPP = time_cpp / time_oasis,     Design_Build_Overhead = time_oasis_build - time_oasis   )) }  # Display rounded results for readability numeric_cols <- setdiff(names(benchmark_results), \"Size\") benchmark_display <- benchmark_results benchmark_display[numeric_cols] <- lapply(benchmark_display[numeric_cols], function(x) round(x, 3)) print(benchmark_display) #>            Size Timepoints Voxels Trials R_Optimized CPP_Optimized OASIS #> elapsed   small        300    500     30       0.005         0.013 0.002 #> elapsed1 medium        400   2000     40       0.015         0.140 0.009 #> elapsed2  large        600   8000     60       0.072         0.137 0.050 #> elapsed3 xlarge        800  16000     60       0.165         0.581 0.120 #>          OASIS_with_design Speedup_vs_R Speedup_vs_CPP Design_Build_Overhead #> elapsed              0.019        2.500          6.500                 0.017 #> elapsed1             0.030        1.667         15.556                 0.021 #> elapsed2             0.086        1.440          2.740                 0.036 #> elapsed3             0.162        1.375          4.842                 0.042  # Visualize scaling par(mfrow = c(1, 2))  # Time vs dataset size ylim_max <- max(benchmark_results[, c(\"R_Optimized\", \"CPP_Optimized\", \"OASIS_with_design\")]) plot(benchmark_results$Voxels, benchmark_results$R_Optimized,      type = \"b\", col = \"blue\", pch = 19,      xlab = \"Number of Voxels\", ylab = \"Time (seconds)\",      main = \"Computation Time Scaling\",      ylim = c(0, ylim_max)) lines(benchmark_results$Voxels, benchmark_results$CPP_Optimized,       type = \"b\", col = \"darkgreen\", pch = 15) lines(benchmark_results$Voxels, benchmark_results$OASIS,       type = \"b\", col = \"red\", pch = 17) lines(benchmark_results$Voxels, benchmark_results$OASIS_with_design,       type = \"b\", col = \"red\", lty = 2, pch = 1) legend(\"topleft\",        c(\"R Optimized\", \"C++ Optimized\", \"OASIS (pre-built X)\", \"OASIS (build design)\"),        col = c(\"blue\", \"darkgreen\", \"red\", \"red\"),        pch = c(19, 15, 17, 1),        lty = c(1, 1, 1, 2))  # Speedup factor barplot(benchmark_results$Speedup_vs_R,         names.arg = benchmark_results$Size,         main = \"OASIS Speedup vs R Optimized\",         ylab = \"Speedup Factor\",         col = \"steelblue\") abline(h = 1, lty = 2, col = \"gray\") These benchmarks show that all three optimized backends sit within a few percent of one another across the regimes we tested. The R and fused C++ paths are already very efficient, and OASIS closely tracks them even as we scale to tens of thousands of voxels and dozens of trials. The `OASIS (build design)` curve highlights another key point: if you let OASIS construct the design inside the call you pay the additional cost of HRF convolution, so for apples-to-apples comparisons you should pre-build and reuse `X` just as you would for the other methods.  The exact ordering will vary with hardware, trial spacing, and nuisance structure—on some reruns OASIS edges ahead, on others the R or C++ backend wins by a similar margin. The takeaway is that OASIS keeps pace with the existing optimized solvers while additionally providing HRF-aware design construction, ridge regularization, whitening, and diagnostics.  ## Creating Custom HRF Functions  OASIS's flexibility extends to custom HRF functions, allowing you to implement novel hemodynamic models:   ``` r # Create custom double-gamma HRF custom_hrf <- function(t, a1 = 6, a2 = 16, b1 = 1, b2 = 1, c = 1/6) {   # Double gamma function   dgamma(t, a1, b1) - c * dgamma(t, a2, b2) }  # Wrap as HRF object custom_hrf_obj <- structure(   custom_hrf,   class = c(\"hrf\", \"function\"),   span = 30 )  # Use with OASIS beta_custom <- lss(   Y = Y[, 1:10],   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(         onsets = onsets[1:10],         hrf = custom_hrf_obj,         span = 30       )     )   ) )  cat(\"Custom HRF results:\\n\") #> Custom HRF results: cat(\"  Beta dimensions:\", dim(beta_custom), \"\\n\") #>   Beta dimensions: 10 10 cat(\"  Mean beta:\", round(mean(beta_custom), 3), \"\\n\") #>   Mean beta: 7.921"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"practical-guidance-for-ridge-parameter-selection","dir":"Articles","previous_headings":"","what":"Practical Guidance for Ridge Parameter Selection","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Choosing appropriate ridge parameters crucial optimal performance. little regularization leaves estimates unstable; much biases toward zero. ’s systematic approach selection: condition number (κ) indicates numerical stability—lower values suggest stable estimates. tradeoff bias (reduced mean beta) variance (reduced SD) guides choice.","code":"# Test different ridge values ridge_values <- c(0, 0.001, 0.01, 0.05, 0.1) ridge_results <- list()  for (ridge in ridge_values) {   beta_r <- lss(     Y = Y[, 1:10],     X = NULL,     method = \"oasis\",     oasis = list(       design_spec = list(         sframe = sframe,         cond = list(onsets = onsets, hrf = HRF_SPMG1, span = 30)       ),       ridge_mode = \"fractional\",       ridge_x = ridge,       ridge_b = ridge     )   )    ridge_results[[as.character(ridge)]] <- list(     mean_beta = mean(abs(beta_r)),     sd_beta = sd(beta_r),     condition_number = kappa(cor(beta_r))   ) }  # Display results cat(\"Ridge parameter selection:\\n\") #> Ridge parameter selection: for (r in names(ridge_results)) {   cat(sprintf(\"  Ridge = %s: mean|β| = %.3f, SD = %.3f, κ = %.1f\\n\",               r, ridge_results[[r]]$mean_beta,               ridge_results[[r]]$sd_beta,               ridge_results[[r]]$condition_number)) } #>   Ridge = 0: mean|β| = 1.087, SD = 0.648, κ = 27.3 #>   Ridge = 0.001: mean|β| = 1.086, SD = 0.648, κ = 27.3 #>   Ridge = 0.01: mean|β| = 1.072, SD = 0.642, κ = 27.3 #>   Ridge = 0.05: mean|β| = 1.013, SD = 0.616, κ = 27.3 #>   Ridge = 0.1: mean|β| = 0.947, SD = 0.587, κ = 27.2"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"memory-usage-comparison","dir":"Articles","previous_headings":"","what":"Memory Usage Comparison","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Understanding memory trade-offs OASIS standard LSS important choosing right method computational resources:  shown, OASIS requires upfront memory due precomputed matrices, investment enables computational efficiency. memory overhead noticeable multi-basis HRFs large numbers trials. memory-constrained systems, consider using blocked processing standard LSS large datasets.","code":"# Compare memory usage across methods memory_comparison <- function(n_time, n_vox, n_trials) {    # Calculate memory requirements (in MB)   double_size <- 8  # bytes per double    # Standard LSS memory (per iteration)   # Stores: current X_trial (n_time × 2), beta result (n_trials × n_vox)   lss_per_iter <- (n_time * 2 + n_vox) * double_size / 1024^2   lss_total <- lss_per_iter  # Only peak memory matters    # OASIS memory (upfront)   # Stores: X (n_time × n_trials), precomputed terms, results   oasis_X <- n_time * n_trials * double_size / 1024^2   oasis_precomp <- (n_trials^2 + n_trials * 3) * double_size / 1024^2  # Gram matrices   oasis_results <- n_trials * n_vox * double_size / 1024^2   oasis_total <- oasis_X + oasis_precomp + oasis_results    # For multi-basis (K=3), multiply by K   oasis_multibasis <- oasis_total * 3    return(data.frame(     Timepoints = n_time,     Voxels = n_vox,     Trials = n_trials,     LSS_MB = round(lss_total, 2),     OASIS_MB = round(oasis_total, 2),     OASIS_Multi_MB = round(oasis_multibasis, 2),     Ratio = round(oasis_total / lss_total, 1),     Ratio_Multi = round(oasis_multibasis / lss_total, 1)   )) }  # Test different dataset sizes mem_results <- rbind(   memory_comparison(200, 100, 15),    # Small   memory_comparison(300, 1000, 30),   # Medium   memory_comparison(400, 10000, 50),  # Large   memory_comparison(500, 50000, 100)  # Very large )  print(mem_results) #>   Timepoints Voxels Trials LSS_MB OASIS_MB OASIS_Multi_MB Ratio Ratio_Multi #> 1        200    100     15   0.00     0.04           0.11   9.5        28.6 #> 2        300   1000     30   0.01     0.31           0.92  25.0        75.0 #> 3        400  10000     50   0.08     3.99          11.96  48.4       145.2 #> 4        500  50000    100   0.39    38.61         115.82  99.2       297.7  # Visualize memory scaling par(mfrow = c(1, 2))  # Memory usage comparison plot(mem_results$Voxels, mem_results$LSS_MB,      type = \"b\", col = \"blue\", pch = 19,      xlab = \"Number of Voxels\", ylab = \"Memory (MB)\",      main = \"Memory Usage Comparison\",      log = \"xy\") #> Warning in xy.coords(x, y, xlabel, ylabel, log): 1 y value <= 0 omitted from #> logarithmic plot lines(mem_results$Voxels, mem_results$OASIS_MB,       type = \"b\", col = \"red\", pch = 17) lines(mem_results$Voxels, mem_results$OASIS_Multi_MB,       type = \"b\", col = \"orange\", pch = 15) legend(\"topleft\", c(\"Standard LSS\", \"OASIS\", \"OASIS Multi-basis\"),        col = c(\"blue\", \"red\", \"orange\"), pch = c(19, 17, 15), lty = 1)  # Memory ratio barplot(t(as.matrix(mem_results[, c(\"Ratio\", \"Ratio_Multi\")])),         beside = TRUE,         names.arg = paste(mem_results$Voxels, \"vox\"),         main = \"Memory Usage Ratio (OASIS/LSS)\",         ylab = \"Memory Ratio\",         col = c(\"red\", \"orange\"),         legend.text = c(\"OASIS\", \"OASIS Multi-basis\")) abline(h = 1, lty = 2, col = \"gray\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"advanced-features-for-production-use","dir":"Articles","previous_headings":"","what":"Advanced Features for Production Use","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"deploying OASIS production analyses, several advanced features enhance efficiency robustness.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"memory-efficient-block-processing","dir":"Articles","previous_headings":"Advanced Features for Production Use","what":"Memory-Efficient Block Processing","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"datasets large fit memory, OASIS can process voxels blocks:","code":"# For very large datasets, use blocked processing block_size <- 1000 n_blocks <- ceiling(ncol(Y) / block_size)  # OASIS with blocked voxels oasis_config <- list(   design_spec = list(     sframe = sframe,     cond = list(onsets = onsets, hrf = HRF_SPMG1, span = 30)   ),   block_cols = block_size  # Process voxels in blocks )  beta_blocked <- lss(Y, X = NULL, method = \"oasis\", oasis = oasis_config)"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"temporal-autocorrelation-correction","dir":"Articles","previous_headings":"Advanced Features for Production Use","what":"Temporal Autocorrelation Correction","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"fMRI data exhibits temporal autocorrelation can bias standard errors. OASIS can apply AR(1) prewhitening: Prewhitening improves validity statistical inference, particularly standard errors hypothesis tests.","code":"# OASIS with AR(1) prewhitening beta_whitened <- lss(   Y = Y[, 1:10],   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(onsets = onsets[1:10], hrf = HRF_SPMG1, span = 30)     ),     whiten = \"ar1\"  # Enable AR(1) whitening   ) )  cat(\"AR(1) whitening applied\\n\") #> AR(1) whitening applied cat(\"  Beta dimensions:\", dim(beta_whitened), \"\\n\") #>   Beta dimensions: 10 10"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"when-oasis-shines-use-case-recommendations","dir":"Articles","previous_headings":"","what":"When OASIS Shines: Use Case Recommendations","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"extensive testing application, ’ve identified scenarios OASIS provides greatest benefits. Rapid event-related designs inter-stimulus intervals 10 seconds benefit enormously OASIS’s efficient handling overlapping responses. method’s speed advantage becomes crucial dealing experiments containing hundreds thousands trials. exploratory analyses optimal HRF unknown, OASIS’s ability quickly evaluate multiple HRF models enables data-driven model selection. computational efficiency makes feasible test dozens HRF variants across multiple brain regions. Large-scale analyses involving whole-brain data multiple subjects particularly benefit OASIS’s speed. might take days traditional LSS can often completed hours OASIS, enabling iterative thorough analyses. Designs prone collinearity—whether rapid presentation, long HRFs, correlated experimental factors—benefit OASIS’s integrated ridge regression. regularization happens naturally within estimation framework rather requiring post-hoc adjustments.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"limitations-and-considerations","dir":"Articles","previous_headings":"","what":"Limitations and Considerations","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"OASIS offers substantial advantages, ’s important understand limitations simpler approaches might suffice. method requires memory iterative LSS approaches since constructs larger intermediate matrices. extremely large datasets memory-constrained systems, traditional LSS careful memory management might necessary. OASIS’s design specification system, powerful, learning curve. simple analyses pre-constructed design matrices, standard LSS might straightforward implement. mathematical optimizations make OASIS fast also make less transparent. need understand modify estimation procedure, traditional LSS implementation offers clearer code paths.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"looking-ahead","dir":"Articles","previous_headings":"","what":"Looking Ahead","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"OASIS represents current state---art LSS implementation, combining theoretical rigor computational efficiency. fMRI data continues grow resolution complexity, methods like OASIS become just useful essential practical analysis. Future developments might include adaptive regularization automatically selects optimal ridge parameters, integration machine learning frameworks end--end optimization, extensions handle even complex experimental designs. fmrilss package continue evolve advances, maintaining OASIS cornerstone efficient trial-wise estimation. Whether ’re working standard datasets pushing boundaries fMRI acquisition, OASIS provides tools need rigorous, efficient analysis.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"summary-and-next-steps","dir":"Articles","previous_headings":"","what":"Summary and Next Steps","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"vignette taken full capabilities OASIS method, basic usage advanced features. ’ve seen OASIS achieves dramatic speedups mathematical reformulation, provides numerical stability integrated ridge regression, handles flexible HRF models seamlessly, scales large datasets efficiently. continue journey, explore getting started vignette foundational LSS concepts, voxel-wise HRF vignette spatial modeling hemodynamic responses, package examples directory real-world applications. theoretical details OASIS prepared publication, offering deeper insights mathematical innovations make method possible. OASIS transforms LSS computationally intensive procedure practical tool everyday fMRI analysis. combining speed, flexibility, robustness, enables analyses otherwise infeasible, opening new possibilities understanding brain function event-related fMRI.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further Reading","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"See vignette(\"getting_started\") LSS basics See vignette(\"voxel-wise-hrf\") spatial HRF variation Review examples/oasis_example.R additional demonstrations Consult OASIS paper (preparation) theoretical details","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"why-hrf-variability-matters","dir":"Articles","previous_headings":"","what":"Why HRF Variability Matters","title":"Voxel-wise HRF Modeling with fmrilss","text":"Picture scenario: ’re analyzing fMRI data study comparing young older adults performing memory task. notice certain brain regions, particularly known vascular changes aging, standard analysis seems systematically underestimate activation older group. genuine difference neural activity, might reflect age-related changes hemodynamic response ? question lies heart voxel-wise HRF modeling. hemodynamic response function represents complex cascade physiological processes translate neural activity BOLD signal measure fMRI. often assume canonical HRF shape across entire brain, reality nuanced. Different brain regions different vascular architectures, neural-vascular coupling can vary age disease, even within healthy young adults, ’s substantial variability HRF characteristics across cortical areas individuals. vignette guide process accounting HRF variability LSS analyses. assume ’re already familiar basic LSS concepts covered getting started vignette, understand fundamentals hemodynamic response function, comfortable working matrices R. foundations, ’ll explore voxel-wise HRF modeling can improve accuracy trial-wise beta estimates.","code":"library(fmrilss) library(fmrihrf) #>  #> Attaching package: 'fmrihrf' #> The following object is masked from 'package:stats': #>  #>     deriv set.seed(123)  # Helper function to create design matrix using fmrihrf API # (design_matrix is not exported from fmrihrf, so we create a wrapper) design_matrix <- function(sframe, conditions, tr_per_trial = FALSE) {   # Get block info from sframe   n_blocks <- length(fmrihrf::blocklens(sframe))    if (tr_per_trial) {     # Create trial-wise design (one column per trial)     X_list <- list()     for (cond in conditions) {       n_trials <- length(cond$onsets)       # Each trial gets its own regressor       X_trial <- fmrihrf::regressor_design(         onsets = cond$onsets,         fac = factor(1:n_trials),  # Each trial is its own level         block = rep(1, n_trials),  # Assume single block for simplicity         sframe = sframe,         hrf = cond$hrf,         duration = if (!is.null(cond$duration)) cond$duration else 0,         span = if (!is.null(cond$span)) cond$span else 30,         precision = 0.1,         method = \"conv\",         summate = FALSE  # Don't sum across trials       )       X_list[[length(X_list) + 1]] <- X_trial     }     X <- do.call(cbind, X_list)   } else {     # Create aggregate design (one column per condition)     X_list <- list()     for (cond in conditions) {       n_trials <- length(cond$onsets)       # All trials in same condition get summed       X_cond <- fmrihrf::regressor_design(         onsets = cond$onsets,         fac = factor(rep(1, n_trials)),  # All trials same level         block = rep(1, n_trials),         sframe = sframe,         hrf = cond$hrf,         duration = if (!is.null(cond$duration)) cond$duration else 0,         span = if (!is.null(cond$span)) cond$span else 30,         precision = 0.1,         method = \"conv\",         summate = TRUE  # Sum across trials in condition       )       X_list[[length(X_list) + 1]] <- X_cond     }     X <- do.call(cbind, X_list)   }    list(X = as.matrix(X)) }"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"building-intuition-through-simulation","dir":"Articles","previous_headings":"","what":"Building Intuition Through Simulation","title":"Voxel-wise HRF Modeling with fmrilss","text":"best way understand impact HRF variability see action. Let’s create controlled simulation know ground truth can observe different analysis approaches perform.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"creating-data-with-variable-hrfs","dir":"Articles","previous_headings":"Building Intuition Through Simulation","what":"Creating Data with Variable HRFs","title":"Voxel-wise HRF Modeling with fmrilss","text":"’ll simulate experiment rapid stimulus presentation, different voxels subtly different HRF characteristics. mimics might happen analyzing data regions different vascular properties:","code":"# Simulation parameters n_time <- 200      # Time points n_trials <- 10     # Number of trials n_vox <- 5         # Number of voxels TR <- 1.0          # Repetition time  # Create event design with rapid presentation events <- data.frame(   onset = seq(10, 180, length.out = n_trials),   duration = rep(1, n_trials),   condition = rep(\"task\", n_trials) )  # Create sampling frame sframe <- fmrihrf::sampling_frame(blocklens = n_time, TR = TR)  # Generate voxel-specific HRF parameters # Each voxel has slightly different HRF characteristics voxel_hrfs <- list() for (v in 1:n_vox) {   # Vary peak time (tau) and width (sigma) across voxels   tau_shift <- (v - 3) * 0.5  # Range: -1 to +1 seconds   sigma_scale <- 1 + (v - 3) * 0.1  # Range: 0.8 to 1.2    # Create voxel-specific HRF using SPM double gamma with modifications   voxel_hrfs[[v]] <- HRF_SPMG1 }  # Generate true betas for each trial and voxel true_betas <- matrix(rnorm(n_trials * n_vox, mean = 1, sd = 0.3),                      nrow = n_trials, ncol = n_vox)  # Create time series data Y <- matrix(0, n_time, n_vox)  # For each voxel, create signal with voxel-specific HRF for (v in 1:n_vox) {   # Create design matrix for this voxel   dm <- design_matrix(     sframe = sframe,     conditions = list(       list(onsets = events$onset,            hrf = voxel_hrfs[[v]],            name = \"task\")     ),     tr_per_trial = TRUE   )    # Generate signal for this voxel   Y[, v] <- dm$X %*% true_betas[, v] }  # Add realistic noise noise_sd <- 0.5 for (v in 1:n_vox) {   noise <- rnorm(n_time, sd = noise_sd)   # Add AR(1) structure   ar_coef <- 0.3   for (t in 2:n_time) {     noise[t] <- ar_coef * noise[t-1] + sqrt(1 - ar_coef^2) * noise[t]   }   Y[, v] <- Y[, v] + noise }  # Name the voxels colnames(Y) <- paste0(\"V\", 1:n_vox)  cat(\"Created synthetic data:\\n\") #> Created synthetic data: cat(\"  Time points:\", n_time, \"\\n\") #>   Time points: 200 cat(\"  Trials:\", n_trials, \"\\n\") #>   Trials: 10 cat(\"  Voxels:\", n_vox, \"\\n\") #>   Voxels: 5 cat(\"  Signal-to-noise ratio:\", round(var(Y[,1] - noise) / var(noise), 2), \"\\n\") #>   Signal-to-noise ratio: 3.06"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"the-standard-approach-and-its-limitations","dir":"Articles","previous_headings":"","what":"The Standard Approach and Its Limitations","title":"Voxel-wise HRF Modeling with fmrilss","text":"apply standard LSS canonical HRF data actually contains HRF variability, ’re making assumption may hold. Let’s see happens: estimates assume every voxel HRF shape. assumption violated, may get biased estimates, particularly voxels whose true HRF deviates substantially canonical form.","code":"# Create design matrix with canonical HRF dm_standard <- design_matrix(   sframe = sframe,   conditions = list(     list(onsets = events$onset,          hrf = HRF_SPMG1,  # Canonical HRF for all voxels          name = \"task\")   ),   tr_per_trial = TRUE )  # Run standard LSS standard_betas <- lss(Y, dm_standard$X, method = \"r_optimized\")  cat(\"Standard LSS beta estimates (first 3 trials, all voxels):\\n\") #> Standard LSS beta estimates (first 3 trials, all voxels): print(round(standard_betas[1:3, ], 2)) #>           V1   V2   V3   V4   V5 #> Trial_1 0.72 1.69 0.84 1.07 0.75 #> Trial_2 1.03 1.19 1.22 0.64 0.94 #> Trial_3 1.21 0.81 0.55 0.91 0.69"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"estimating-voxel-specific-hrfs","dir":"Articles","previous_headings":"","what":"Estimating Voxel-Specific HRFs","title":"Voxel-wise HRF Modeling with fmrilss","text":"account HRF variability, need first estimate voxel’s HRF characteristics. One powerful approach uses multi-basis set can capture different aspects HRF variation. SPM software popularized three-component basis set consisting canonical HRF, temporal derivative (capturing shifts peak time), dispersion derivative (capturing changes width): weights tell us voxel’s HRF differs canonical shape. positive temporal derivative weight suggests later peak, positive dispersion derivative indicates wider response. estimates capture unique hemodynamic characteristics voxel.","code":"# Step 1: Estimate voxel-specific HRF using multi-basis approach # We'll use SPMG3 which includes canonical HRF plus temporal and dispersion derivatives  # Create multi-basis design matrix dm_multibasis <- design_matrix(   sframe = sframe,   conditions = list(     list(onsets = events$onset,          hrf = HRF_SPMG3,  # 3-basis set          name = \"task\")   ),   tr_per_trial = FALSE  # Aggregate for HRF estimation )  # Estimate HRF basis weights for each voxel hrf_weights <- matrix(NA, 3, n_vox)  # 3 basis functions  for (v in 1:n_vox) {   # Simple GLM to estimate basis weights   fit <- lm(Y[, v] ~ dm_multibasis$X - 1)   hrf_weights[, v] <- coef(fit) }  cat(\"Estimated HRF basis weights (3 bases x\", n_vox, \"voxels):\\n\") #> Estimated HRF basis weights (3 bases x 5 voxels): print(round(hrf_weights, 2)) #>       [,1]  [,2]  [,3] [,4]  [,5] #> [1,]  0.92  1.07  0.87 1.12  1.03 #> [2,] -0.01 -0.05 -0.04 0.13 -0.25 #> [3,] -0.23 -0.01  0.35 0.36 -0.05  # Normalize weights (optional, for interpretation) hrf_weights_norm <- sweep(hrf_weights, 2, hrf_weights[1,], \"/\") cat(\"\\nNormalized weights (relative to canonical):\\n\") #>  #> Normalized weights (relative to canonical): print(round(hrf_weights_norm, 2)) #>       [,1]  [,2]  [,3] [,4]  [,5] #> [1,]  1.00  1.00  1.00 1.00  1.00 #> [2,] -0.01 -0.04 -0.05 0.12 -0.24 #> [3,] -0.25 -0.01  0.40 0.32 -0.05"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"applying-voxel-specific-hrfs-in-lss","dir":"Articles","previous_headings":"","what":"Applying Voxel-Specific HRFs in LSS","title":"Voxel-wise HRF Modeling with fmrilss","text":"HRF estimates hand, can now perform LSS using voxel’s specific hemodynamic response profile. two-stage approach first characterizes HRF, uses characterization accurate trial-wise estimation:","code":"# For demonstration, we'll use a simplified approach # In practice, you might use lss_with_hrf() with the appropriate backend  voxel_betas <- matrix(NA, n_trials, n_vox)  for (v in 1:n_vox) {   # Create voxel-specific design matrix using estimated weights   # Weight the basis functions by the estimated coefficients   X_voxel <- matrix(0, n_time, n_trials)    for (trial in 1:n_trials) {     # Create trial-specific regressors for each basis     dm_trial <- design_matrix(       sframe = sframe,       conditions = list(         list(onsets = events$onset[trial],              hrf = HRF_SPMG3,              name = \"trial\")       ),       tr_per_trial = FALSE     )      # Combine bases using voxel-specific weights     X_voxel[, trial] <- dm_trial$X %*% hrf_weights[, v]   }    # Run LSS for this voxel with its specific HRF   voxel_betas[, v] <- lss(Y[, v, drop = FALSE], X_voxel, method = \"r_optimized\") }  cat(\"Voxel-wise HRF LSS beta estimates (first 3 trials, all voxels):\\n\") #> Voxel-wise HRF LSS beta estimates (first 3 trials, all voxels): print(round(voxel_betas[1:3, ], 2)) #>      [,1] [,2] [,3] [,4] [,5] #> [1,] 0.74 1.57 1.06 1.04 0.74 #> [2,] 1.07 1.11 1.49 0.63 0.90 #> [3,] 1.28 0.75 0.67 0.85 0.69"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"the-oasis-alternative","dir":"Articles","previous_headings":"","what":"The OASIS Alternative","title":"Voxel-wise HRF Modeling with fmrilss","text":"OASIS method provides elegant alternative can handle HRF estimation LSS unified framework. Rather requiring separate stages, OASIS incorporates HRF flexibility directly estimation process, often improved computational efficiency: OASIS’s integrated approach often provides stable estimates, particularly designs closely spaced trials traditional two-stage approaches might struggle collinearity.","code":"# OASIS can automatically handle HRF estimation and LSS in one step oasis_betas <- lss(   Y = Y,   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(         onsets = events$onset,         hrf = HRF_SPMG3,  # Multi-basis HRF         span = 30       )     ),     ridge_mode = \"fractional\",     ridge_x = 0.01,  # Small ridge for stability     ridge_b = 0.01   ) )  # OASIS returns results for each basis function # Extract canonical component (first basis) oasis_canonical <- oasis_betas[seq(1, nrow(oasis_betas), by = 3), ]  cat(\"OASIS beta estimates (canonical component, first 3 trials):\\n\") #> OASIS beta estimates (canonical component, first 3 trials): print(round(oasis_canonical[1:3, ], 2)) #>           V1   V2   V3   V4   V5 #> Trial_1 0.73 1.48 0.98 1.29 0.75 #> Trial_4 1.03 1.14 1.24 0.66 0.86 #> Trial_7 1.05 0.87 0.53 0.91 0.72"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"evaluating-the-approaches","dir":"Articles","previous_headings":"","what":"Evaluating the Approaches","title":"Voxel-wise HRF Modeling with fmrilss","text":"Let’s quantitatively compare well method recovers true beta values used generate synthetic data:  scatter plots reveal accounting HRF variability can improve beta estimation accuracy. Points closer diagonal line indicate better recovery true values.","code":"# Calculate correlations with true betas cor_standard <- cor(as.vector(standard_betas), as.vector(true_betas)) cor_voxel <- cor(as.vector(voxel_betas), as.vector(true_betas)) cor_oasis <- cor(as.vector(oasis_canonical), as.vector(true_betas))  # Calculate RMSE rmse_standard <- sqrt(mean((standard_betas - true_betas)^2)) rmse_voxel <- sqrt(mean((voxel_betas - true_betas)^2)) rmse_oasis <- sqrt(mean((oasis_canonical - true_betas)^2))  # Create comparison table comparison <- data.frame(   Method = c(\"Standard LSS\", \"Voxel-wise HRF\", \"OASIS\"),   Correlation = round(c(cor_standard, cor_voxel, cor_oasis), 3),   RMSE = round(c(rmse_standard, rmse_voxel, rmse_oasis), 3) )  print(comparison) #>           Method Correlation  RMSE #> 1   Standard LSS       0.859 0.177 #> 2 Voxel-wise HRF       0.815 0.190 #> 3          OASIS       0.829 0.203  # Visualization par(mfrow = c(1, 3), mar = c(4, 4, 3, 1))  # Standard LSS plot(true_betas, standard_betas,      xlab = \"True Betas\", ylab = \"Estimated Betas\",      main = paste(\"Standard LSS\\n(r =\", round(cor_standard, 2), \")\"),      pch = 19, col = rep(1:n_vox, each = n_trials),      xlim = range(true_betas), ylim = range(true_betas)) abline(0, 1, lty = 2, col = \"gray\")  # Voxel-wise HRF plot(true_betas, voxel_betas,      xlab = \"True Betas\", ylab = \"Estimated Betas\",      main = paste(\"Voxel-wise HRF\\n(r =\", round(cor_voxel, 2), \")\"),      pch = 19, col = rep(1:n_vox, each = n_trials),      xlim = range(true_betas), ylim = range(true_betas)) abline(0, 1, lty = 2, col = \"gray\")  # OASIS plot(true_betas, oasis_canonical,      xlab = \"True Betas\", ylab = \"Estimated Betas\",      main = paste(\"OASIS\\n(r =\", round(cor_oasis, 2), \")\"),      pch = 19, col = rep(1:n_vox, each = n_trials),      xlim = range(true_betas), ylim = range(true_betas)) abline(0, 1, lty = 2, col = \"gray\")  legend(\"topleft\", legend = paste(\"Voxel\", 1:n_vox),        col = 1:n_vox, pch = 19, cex = 0.8)"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"when-to-consider-voxel-wise-hrf-modeling","dir":"Articles","previous_headings":"","what":"When to Consider Voxel-wise HRF Modeling","title":"Voxel-wise HRF Modeling with fmrilss","text":"decision use voxel-wise HRF modeling involves balancing increased model flexibility computational cost risk overfitting. experience literature, several scenarios particularly benefit approach. analyzing data different brain regions known vascular differences, comparing motor visual cortex, accounting HRF variability becomes important. vascular architecture differs substantially across cortical areas, leading systematic differences hemodynamic response can bias standard analyses ignored. Clinical populations present another compelling use case. Aging, neurological disorders, psychiatric conditions can affect neurovascular coupling. Even medications can alter hemodynamic response. cases, assuming canonical HRF derived young, healthy adults may lead systematic misestimation neural activity. advent high-resolution fMRI revealed fine-scale variations hemodynamic response. Sub-millimeter resolution can distinguish cortical layers columns, potentially distinct vascular properties. scales, assuming spatial homogeneity HRF becomes increasingly untenable. Long experimental sessions introduce temporal considerations. Habituation, fatigue, attention fluctuations can cause hemodynamic response evolve time. Voxel-wise approaches can adapt changes may provide accurate estimates throughout session.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"computational-strategies-for-large-scale-analysis","dir":"Articles","previous_headings":"","what":"Computational Strategies for Large-Scale Analysis","title":"Voxel-wise HRF Modeling with fmrilss","text":"voxel-wise HRF modeling offers theoretical advantages, can computationally demanding applied whole-brain data. package provides several strategies make feasible: choice backend depends data size computational resources. exploratory analyses subset regions, standard R implementation may suffice. scaling whole-brain analysis hundreds thousands voxels, C++ backend OASIS method become essential.","code":"# For large datasets, use optimized backends # C++ backend for medium-sized data betas_cpp <- lss(Y, X, method = \"cpp_optimized\")  # For very large data with multiple cores # betas_parallel <- lss(Y, X, method = \"cpp_parallel\", n_cores = 4)  # OASIS method is often fastest for complex designs betas_oasis <- lss(Y, X = NULL, method = \"oasis\",                    oasis = list(design_spec = design_spec))"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"choosing-the-right-method-for-your-study","dir":"Articles","previous_headings":"","what":"Choosing the Right Method for Your Study","title":"Voxel-wise HRF Modeling with fmrilss","text":"Selecting standard LSS, voxel-wise HRF LSS, OASIS depends specific research context constraints. Standard LSS remains appropriate reason believe HRF relatively homogeneous across regions interest, computational resources limited, need simplicity single-stage approach easier interpretation. Voxel-wise HRF modeling becomes valuable expect spatial HRF variability due anatomical pathological factors, need maximum accuracy pattern classification decoding analyses, pilot data suggests substantial HRF differences across regions subjects. OASIS offers particular advantages rapid event-related designs substantial response overlap, want explore different HRF models without committing specific parameterization, need computational efficiency unified estimation framework. built-ridge regression also helps designs might otherwise suffer collinearity.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"practical-recommendations","dir":"Articles","previous_headings":"","what":"Practical Recommendations","title":"Voxel-wise HRF Modeling with fmrilss","text":"Based experience implementing using methods, offer several practical recommendations. First, always validate HRF assumptions using independent data possible. might involve using separate localizer runs estimate HRF parameters comparing different models held-data. Second, consider signal--noise ratio data. Voxel-wise HRF estimation requires sufficient data quality reliably estimate additional parameters. low SNR situations, bias assuming canonical HRF might preferable variance introduced estimating voxel-specific parameters. Third, remember complex models aren’t always better. Start standard approaches add complexity justified research questions simpler models show clear inadequacies. Finally, document choices carefully. HRF modeling decisions can substantially affect results, transparency choices essential reproducibility interpretation.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"looking-forward","dir":"Articles","previous_headings":"","what":"Looking Forward","title":"Voxel-wise HRF Modeling with fmrilss","text":"vignette demonstrated voxel-wise HRF modeling can improve accuracy trial-wise beta estimation fMRI analysis. accounting spatial variability hemodynamic response, methods help separate neural vascular sources signal variation. field continues evolve, ongoing research adaptive HRF estimation, nonparametric approaches, methods handling even complex sources variability. fmrilss package provides flexible framework incorporating advances emerge. deeper exploration topics covered , recommend reviewing getting started vignette LSS fundamentals, OASIS method vignette advanced features approach, consulting fmrihrf package documentation details available HRF models. theoretical foundations can found Mumford et al. (2012) LSS basics growing literature HRF variability fMRI.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further Reading","title":"Voxel-wise HRF Modeling with fmrilss","text":"See vignette(\"getting_started\") LSS basics See vignette(\"oasis_method\") advanced OASIS features Consult fmrihrf package documentation HRF model options Review Mumford et al. (2012) theoretical background LSS","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Brad Buchsbaum. Maintainer.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Buchsbaum B (2025). fmrilss: Least Squares Separate (LSS) Analysis fMRI Data. R package version 0.1.0, https://bbuchsbaum.github.io/fmrilss/.","code":"@Manual{,   title = {fmrilss: Least Squares Separate (LSS) Analysis for fMRI Data},   author = {Brad Buchsbaum},   year = {2025},   note = {R package version 0.1.0},   url = {https://bbuchsbaum.github.io/fmrilss/}, }"},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"fmrilss","dir":"","previous_headings":"","what":"Least Squares Separate (LSS) Analysis for fMRI Data","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"Least Squares Separate (LSS) Analysis fMRI Data.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"fmrilss package provides efficient flexible implementation Least Squares Separate (LSS) method fMRI analysis, proposed Mumford et al. (2012). approach models trial separate GLM, making powerful technique multivariate pattern analysis (MVPA) connectivity studies trial-specific estimates needed. package offers multiple backends, simple reference implementation highly optimized, parallel C++ engine, accessible clean, unified interface.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"Five Implementations: Includes highly optimized C++ version, optimized R version, standard vectorized R C++ versions, simple R loop testing validation. Parallel Processing: optimized C++ version uses OpenMP multi-threaded execution maximize performance modern hardware. Flexible & Modern Interface: clean lss(Y, X, Z, Nuisance) signature powerful intuitive. Nuisance Regression: Built-support projecting nuisance regressors (e.g., motion parameters, physiological noise) LSS analysis. CRAN-Compliant: Built portable configurations suitable CRAN submission.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"can install development version fmrilss GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"bbuchsbaum/fmrilss\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"primary function lss(), takes data Y, trial design X, experimental regressors Z, optional nuisance regressors.","code":"library(fmrilss)  # 1. Generate synthetic data set.seed(123) n_timepoints <- 120 n_trials <- 15 n_voxels <- 50  # Trial design matrix (X): one column per trial X <- matrix(0, n_timepoints, n_trials) onsets <- seq(from = 5, to = n_timepoints - 10, length.out = n_trials) for(i in 1:n_trials) {   X[onsets[i]:(onsets[i] + 4), i] <- 1 } colnames(X) <- paste0(\"Trial_\", 1:n_trials)  # Experimental regressors (Z): intercept and condition-specific effects # These are experimental regressors we want to model and get beta estimates for, # but not trial-wise (e.g., condition differences, block effects) Z <- cbind(Intercept = 1, LinearTrend = scale(1:n_timepoints, center = TRUE, scale = FALSE))  # Nuisance regressors: e.g., 6 motion parameters Nuisance <- matrix(rnorm(n_timepoints * 6), n_timepoints, 6)  # Data (Y): timepoints x voxels # (Simulate some effects for demonstration) true_betas <- matrix(rnorm(n_trials * n_voxels, 0, 1.5), n_trials, n_voxels) Y <- Z %*% matrix(c(10, -0.2), 2, n_voxels) +       X %*% true_betas +      Nuisance %*% matrix(rnorm(6 * n_voxels, 0, 2), 6, n_voxels) +      matrix(rnorm(n_timepoints * n_voxels, 0, 0.8), n_timepoints, n_voxels) colnames(Y) <- paste0(\"Voxel_\", 1:n_voxels)   # 2. Run LSS analysis  # Example 1: Basic LSS with default intercept # If Z is NULL, an intercept is automatically added. beta_estimates <- lss(Y, X)  # Example 2: LSS with experimental regressors (intercept + condition effects) beta_fixed <- lss(Y, X, Z = Z)  # Example 3: LSS with experimental regressors and nuisance regression beta_clean <- lss(Y, X, Z = Z, Nuisance = Nuisance)  # Example 4: Use the super-fast, parallelized C++ implementation beta_fast <- lss(Y, X, Z = Z, Nuisance = Nuisance, method = \"cpp_optimized\")  # The result is a (trials x voxels) matrix of beta estimates print(dim(beta_fast)) #> [1] 15 50 print(beta_fast[1:5, 1:4])"},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"Mumford, J. ., Turner, B. O., Ashby, F. G., & Poldrack, R. . (2012). Deconvolving BOLD activation event-related designs multivoxel pattern classification analyses. NeuroImage, 59(3), 2636-2643.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"GPL-3","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/LSSBeta.html","id":null,"dir":"Reference","previous_headings":"","what":"LSSBeta object — LSSBeta","title":"LSSBeta object — LSSBeta","text":"Simple list-based S3 class returned lss_with_hrf containing trial-wise beta estimates.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/MixedWorkspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixed Model Workspace for Optimized Computation — MixedWorkspace","title":"Mixed Model Workspace for Optimized Computation — MixedWorkspace","text":"Stores precomputed matrices decompositions can reused across multiple voxels avoid repeated expensive computations.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/VoxelHRF.html","id":null,"dir":"Reference","previous_headings":"","what":"VoxelHRF object — VoxelHRF","title":"VoxelHRF object — VoxelHRF","text":"Simple list-based S3 class returned estimate_voxel_hrf containing voxel-wise HRF basis coefficients related metadata.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/calculate_recovery_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate HRF Recovery Metrics — calculate_recovery_metrics","title":"Calculate HRF Recovery Metrics — calculate_recovery_metrics","text":"Evaluates well method recovered true HRF","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/calculate_recovery_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate HRF Recovery Metrics — calculate_recovery_metrics","text":"","code":"calculate_recovery_metrics(results, true_hrf)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/calculate_recovery_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate HRF Recovery Metrics — calculate_recovery_metrics","text":"results Output compare_hrf_recovery true_hrf Ground truth HRF","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/calculate_recovery_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate HRF Recovery Metrics — calculate_recovery_metrics","text":"Data frame recovery metrics","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/compare_hrf_recovery.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare HRF Recovery Methods — compare_hrf_recovery","title":"Compare HRF Recovery Methods — compare_hrf_recovery","text":"Compares OASIS, SPMG1, SPMG3, FIR HRF recovery","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/compare_hrf_recovery.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare HRF Recovery Methods — compare_hrf_recovery","text":"","code":"compare_hrf_recovery(data, hrf_grid = NULL)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/compare_hrf_recovery.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare HRF Recovery Methods — compare_hrf_recovery","text":"data Synthetic data generate_lwu_data hrf_grid Optional pre-computed HRF grid OASIS","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/compare_hrf_recovery.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare HRF Recovery Methods — compare_hrf_recovery","text":"List results methods","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/create_lwu_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Create LWU HRF Grid for OASIS Search — create_lwu_grid","title":"Create LWU HRF Grid for OASIS Search — create_lwu_grid","text":"Generates grid LWU HRF models varying parameters","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/create_lwu_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create LWU HRF Grid for OASIS Search — create_lwu_grid","text":"","code":"create_lwu_grid(   tau_range = c(4, 8),   sigma_range = c(1.5, 3.5),   rho_range = c(0.1, 0.6),   n_tau = 5,   n_sigma = 3,   n_rho = 3 )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/create_lwu_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create LWU HRF Grid for OASIS Search — create_lwu_grid","text":"tau_range Range tau values test sigma_range Range sigma values test rho_range Range rho values test n_tau Number tau values grid n_sigma Number sigma values grid n_rho Number rho values grid","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/create_lwu_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create LWU HRF Grid for OASIS Search — create_lwu_grid","text":"List HRF models parameters","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-lss_oasis.html","id":null,"dir":"Reference","previous_headings":"","what":"OASIS backend for fmrilss::lss (internal entry) — .lss_oasis","title":"OASIS backend for fmrilss::lss (internal entry) — .lss_oasis","text":"Add `method=\"oasis\"` fmrilss::lss(). path:   - (optionally) builds trial-wise design X via fmrihrf   - residualizes Y (X downstream) confounds + Z + -condition aggregates   - computes trial betas one batched pass via closed-form LSS (exact; ridge-LSS)   - optionally returns per-trial SEs design diagnostics","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-lss_oasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"OASIS backend for fmrilss::lss (internal entry) — .lss_oasis","text":"","code":".lss_oasis(Y, X = NULL, Z = NULL, Nuisance = NULL, oasis = list())"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-lss_oasis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"OASIS backend for fmrilss::lss (internal entry) — .lss_oasis","text":"Y (T x V) numeric matrix X (T x N_trials) trial-wise design (NULL, use oasis$design_spec build) Z (T x K) fixed experimental regressors projected Nuisance (T x P) confounds (intercept, motion, drift, aCompCor, ...) oasis list options: - design_spec: list describing events/HRF build X via fmrihrf - K: explicit basis dimension (auto-detected provided) - ridge_mode: \"absolute\" (default) \"fractional\" - ridge_x, ridge_b: nonnegative ridge [a_j, b_j] Gram (default 0 -> exact LSS) - block_cols: voxel block size (default 4096) - return_se: logical (default FALSE) - return_diag: logical (default FALSE) - whiten: \"none\" | \"ar1\" (default \"none\"); \"ar1\", prewhiten Y design first","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-lss_oasis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"OASIS backend for fmrilss::lss (internal entry) — .lss_oasis","text":"default: (N_trials x V) matrix betas; `return_se` `return_diag`, list","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-mixed_solve_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixed Model Solver using C++ — .mixed_solve_cpp","title":"Mixed Model Solver using C++ — .mixed_solve_cpp","text":"C++ implementation mixed model solver. function typically called main `mixed_solve` function rather directly.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-mixed_solve_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mixed Model Solver using C++ — .mixed_solve_cpp","text":"","code":".mixed_solve_cpp(   Y,   X = NULL,   Z = NULL,   K = NULL,   method = \"REML\",   bounds = c(1e-09, 1e+09),   SE = FALSE,   return_Hinv = FALSE )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-mixed_solve_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mixed Model Solver using C++ — .mixed_solve_cpp","text":"Y Response vector. X Design matrix fixed effects (default: intercept ). Z Design matrix random effects (default: identity matrix). K Kinship matrix (default: identity matrix). method Optimization method, either \"REML\" \"ML\". bounds Bounds optimizer. SE Logical, whether return standard errors. return_Hinv Logical, whether return inverse H.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-mixed_solve_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mixed Model Solver using C++ — .mixed_solve_cpp","text":"list mixed model results.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/estimate_voxel_hrf.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Voxel-wise HRF Basis Coefficients — estimate_voxel_hrf","title":"Estimate Voxel-wise HRF Basis Coefficients — estimate_voxel_hrf","text":"Fits GLM estimate HRF basis coefficients every voxel.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/estimate_voxel_hrf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Voxel-wise HRF Basis Coefficients — estimate_voxel_hrf","text":"","code":"estimate_voxel_hrf(Y, events, basis, nuisance_regs = NULL)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/estimate_voxel_hrf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Voxel-wise HRF Basis Coefficients — estimate_voxel_hrf","text":"Y Numeric matrix BOLD data (time x voxels). events Data frame onset, duration condition columns. basis HRF object fmrihrf package. nuisance_regs Optional numeric matrix nuisance regressors.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/estimate_voxel_hrf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Voxel-wise HRF Basis Coefficients — estimate_voxel_hrf","text":"VoxelHRF object containing least: coefficients Matrix HRF basis coefficients. basis HRF basis object used. conditions Character vector modeled conditions.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/estimate_voxel_hrf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Voxel-wise HRF Basis Coefficients — estimate_voxel_hrf","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(1) Y <- matrix(rnorm(100), 50, 2) events <- data.frame(onset = c(5, 25), duration = 1,                      condition = \"A\") basis <- fmrihrf::hrf_gamma() sframe <- fmrihrf::sampling_frame(blocklens = nrow(Y), TR = 1) times <- fmrihrf::samples(sframe, global = TRUE) rset <- fmrihrf::regressor_set(onsets = events$onset,                                fac = factor(1:nrow(events)),                                hrf = basis, duration = events$duration,                                span = 30) X <- fmrihrf::evaluate(rset, grid = times, precision = 0.1, method = \"conv\") coef <- matrix(rnorm(ncol(X) * ncol(Y)), ncol(X), ncol(Y)) Y <- X %*% coef + Y * 0.1 est <- estimate_voxel_hrf(Y, events, basis) str(est) } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fast_reml_lambda.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast analytical REML estimation for single variance component — fast_reml_lambda","title":"Fast analytical REML estimation for single variance component — fast_reml_lambda","text":"single variance component model, REML estimate \\(\\lambda = \\sigma_e^2/\\sigma_u^2\\) closed-form solution can computed efficiently.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fast_reml_lambda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast analytical REML estimation for single variance component — fast_reml_lambda","text":"omega Transformed response vector Q'y theta Transformed eigenvalues tol Convergence tolerance Newton iterations max_iter Maximum Newton iterations","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fast_reml_lambda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fast analytical REML estimation for single variance component — fast_reml_lambda","text":"Estimated variance ratio \\(\\lambda\\)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fit_oasis_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit OASIS with HRF Grid Search — fit_oasis_grid","title":"Fit OASIS with HRF Grid Search — fit_oasis_grid","text":"Fits OASIS models different HRF parameters selects best","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fit_oasis_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit OASIS with HRF Grid Search — fit_oasis_grid","text":"","code":"fit_oasis_grid(Y, onsets, sframe, hrf_grid, ridge_x = 0.01, ridge_b = 0.01)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fit_oasis_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit OASIS with HRF Grid Search — fit_oasis_grid","text":"Y Data matrix (time x voxels) onsets Event onset times sframe Sampling frame hrf_grid List HRF models test ridge_x Ridge parameter design matrix ridge_b Ridge parameter aggregator","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fit_oasis_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit OASIS with HRF Grid Search — fit_oasis_grid","text":"List best HRF index, parameters, beta estimates","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fmrilss-package.html","id":null,"dir":"Reference","previous_headings":"","what":"fmrilss: Least Squares Separate (LSS) Analysis for fMRI Data — fmrilss-package","title":"fmrilss: Least Squares Separate (LSS) Analysis for fMRI Data — fmrilss-package","text":"package implements efficient least squares separate (LSS) analysis functional magnetic resonance imaging (fMRI) data. LSS used estimate trial--trial activation patterns event-related fMRI designs.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fmrilss-package.html","id":"main-functions","dir":"Reference","previous_headings":"","what":"Main functions","title":"fmrilss: Least Squares Separate (LSS) Analysis for fMRI Data — fmrilss-package","text":"lss: Main function performing LSS analysis lss_naive: Naive LSS implementation reference project_confounds: R implementation projecting confounds project_confounds_cpp: Fast C++ confound projection lss_beta_cpp: Vectorized C++ LSS beta computation get_data_matrix: Helper function data extraction","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fmrilss-package.html","id":"features","dir":"Reference","previous_headings":"","what":"Features","title":"fmrilss: Least Squares Separate (LSS) Analysis for fMRI Data — fmrilss-package","text":"Optimized C++ implementation using vectorized matrix algebra Memory-efficient projection without forming Q matrices Cholesky decomposition numerical stability Fallback R implementation QR decomposition Support various design matrix configurations Robust numerical handling edge cases OpenMP support multi-core processing","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fmrilss-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"fmrilss: Least Squares Separate (LSS) Analysis for fMRI Data — fmrilss-package","text":"Name <.email@example.com>","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_lwu_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Synthetic fMRI Data with LWU HRF — generate_lwu_data","title":"Generate Synthetic fMRI Data with LWU HRF — generate_lwu_data","text":"Creates synthetic fMRI time series using specified LWU HRF parameters","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_lwu_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Synthetic fMRI Data with LWU HRF — generate_lwu_data","text":"","code":"generate_lwu_data(   onsets,   tau = 6,   sigma = 2.5,   rho = 0.35,   TR = 1,   total_time = 300,   n_voxels = 10,   amplitudes = NULL,   noise_sd = 0.2,   seed = NULL )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_lwu_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Synthetic fMRI Data with LWU HRF — generate_lwu_data","text":"onsets Vector event onset times seconds tau LWU tau parameter (time--peak) sigma LWU sigma parameter (width) rho LWU rho parameter (undershoot amplitude) TR Repetition time seconds total_time Total scan time seconds n_voxels Number voxels simulate amplitudes Event amplitudes (scalar vector) noise_sd Standard deviation noise seed Random seed","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_lwu_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Synthetic fMRI Data with LWU HRF — generate_lwu_data","text":"List Y (data matrix), true_hrf, true_betas, design info","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_rapid_design.html","id":null,"dir":"Reference","previous_headings":"","what":"OASIS HRF Recovery Testing Functions — generate_rapid_design","title":"OASIS HRF Recovery Testing Functions — generate_rapid_design","text":"Functions test OASIS's ability recover HRF parameters rapid event-related designs overlapping HRFs. Generate Rapid Event-Related Design","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_rapid_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"OASIS HRF Recovery Testing Functions — generate_rapid_design","text":"","code":"generate_rapid_design(   n_events = 25,   total_time = 300,   min_isi = 2,   max_isi = 4,   seed = NULL )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_rapid_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"OASIS HRF Recovery Testing Functions — generate_rapid_design","text":"n_events Number events generate total_time Total time seconds min_isi Minimum inter-stimulus interval seconds max_isi Maximum inter-stimulus interval seconds seed Random seed reproducibility","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_rapid_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"OASIS HRF Recovery Testing Functions — generate_rapid_design","text":"Numeric vector event onset times","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_rapid_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"OASIS HRF Recovery Testing Functions — generate_rapid_design","text":"Creates rapid event-related design specified ISI range","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/get_data_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Data Matrix from Dataset — get_data_matrix","title":"Extract Data Matrix from Dataset — get_data_matrix","text":"Helper function extract data matrix various dataset formats. placeholder customized based data format.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/get_data_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Data Matrix from Dataset — get_data_matrix","text":"","code":"get_data_matrix(dset)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/get_data_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Data Matrix from Dataset — get_data_matrix","text":"dset Dataset object (format depends specific use case)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/get_data_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Data Matrix from Dataset — get_data_matrix","text":"numeric matrix rows timepoints columns voxels","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/list_to_workspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert R list back to MixedWorkspace — list_to_workspace","title":"Convert R list back to MixedWorkspace — list_to_workspace","text":"Convert R list back MixedWorkspace","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lsa.html","id":null,"dir":"Reference","previous_headings":"","what":"Least Squares All (LSA) Analysis — lsa","title":"Least Squares All (LSA) Analysis — lsa","text":"Performs standard multiple regression analysis trial regressors fitted simultaneously. provides reference comparison Least Squares Separate (LSS) approach.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lsa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Least Squares All (LSA) Analysis — lsa","text":"","code":"lsa(Y, X, Z = NULL, Nuisance = NULL, method = c(\"r\", \"cpp\"))"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lsa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Least Squares All (LSA) Analysis — lsa","text":"Y numeric matrix rows timepoints columns voxels/features. dependent variable data. X numeric matrix rows timepoints columns trial-specific regressors. column represents single trial event. Z numeric matrix nuisance regressors (e.g., motion parameters, drift terms). Defaults NULL. Nuisance alias Z, provided consistency LSS interface. Z Nuisance provided, Z takes precedence. method Character string specifying computational method: \"r\" - Pure R implementation using lm.fit \"cpp\" - C++ implementation better performance","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lsa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Least Squares All (LSA) Analysis — lsa","text":"numeric matrix size T × V containing beta estimates   trial regressor (rows) voxel (columns).","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lsa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Least Squares All (LSA) Analysis — lsa","text":"LSA fits model: Y = X*beta + Z*gamma + error, trial regressors X estimated simultaneously. contrast LSS, fits trial separately treating trials nuisance regressors.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lsa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Least Squares All (LSA) Analysis — lsa","text":"","code":"# Generate example data n_timepoints <- 100 n_trials <- 10 n_voxels <- 50  # Create trial design matrix X <- matrix(0, n_timepoints, n_trials) for(i in 1:n_trials) {   start <- (i-1) * 8 + 1   if(start + 5 <= n_timepoints) {     X[start:(start+5), i] <- 1   } }  # Create data with some signal Y <- matrix(rnorm(n_timepoints * n_voxels), n_timepoints, n_voxels) true_betas <- matrix(rnorm(n_trials * n_voxels, 0, 0.5), n_trials, n_voxels) for(i in 1:n_trials) {   Y <- Y + X[, i] %*% matrix(true_betas[i, ], 1, n_voxels) }  # Run LSA analysis beta_estimates <- lsa(Y, X)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":null,"dir":"Reference","previous_headings":"","what":"Least Squares Separate (LSS) Analysis — lss","title":"Least Squares Separate (LSS) Analysis — lss","text":"Computes trial-wise beta estimates using Least Squares Separate approach Mumford et al. (2012). method fits separate GLM trial, trial interest trials separate regressors.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Least Squares Separate (LSS) Analysis — lss","text":"","code":"lss(   Y,   X,   Z = NULL,   Nuisance = NULL,   method = c(\"r_optimized\", \"cpp_optimized\", \"r_vectorized\", \"cpp\", \"naive\", \"oasis\"),   block_size = 96,   oasis = list() )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Least Squares Separate (LSS) Analysis — lss","text":"Y numeric matrix size n × V n number timepoints V number voxels/variables X numeric matrix size n × T T number trials. column represents design one trial Z numeric matrix size n × F representing experimental regressors include trial-wise models. regressors want model get beta estimates , trial-wise (e.g., intercept, condition effects, block effects). NULL, intercept-design used. Defaults NULL Nuisance numeric matrix size n × N representing nuisance regressors projected LSS analysis (e.g., motion parameters, physiological noise). NULL, nuisance projection performed. Defaults NULL method Character string specifying implementation use. Options : \"r_optimized\" - Optimized R implementation (recommended, default) \"cpp_optimized\" - Optimized C++ implementation parallel support \"r_vectorized\" - Standard R vectorized implementation \"cpp\" - Standard C++ implementation \"naive\" - Simple loop-based R implementation (testing) \"oasis\" - OASIS method HRF support ridge regularization block_size integer specifying voxel block size parallel processing, applicable `method = \"cpp_optimized\"`. Defaults 96. oasis list options OASIS method. See Details available options.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Least Squares Separate (LSS) Analysis — lss","text":"numeric matrix size T × V containing trial-wise beta estimates.   Note: Currently returns estimates trial regressors (X). Beta   estimates experimental regressors (Z) computed returned.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Least Squares Separate (LSS) Analysis — lss","text":"LSS approach fits separate GLM trial, model includes: trial interest (column X) trials combined (sum columns X) Experimental regressors (Z matrix) - modeled get beta estimates trial-wise Nuisance regressors provided, first projected Y X using standard linear regression residualization. using method=\"oasis\", following options available oasis list: design_spec: list building trial-wise designs event onsets using fmrihrf.     Must contain: sframe (sampling frame), cond (list onsets,     hrf, optionally span), optionally others (list conditions     modeled nuisances). provided, X can NULL constructed automatically. K: Explicit basis dimension multi-basis HRF models (e.g., 3 SPMG3).     provided, auto-detected X dimensions defaults 1 single-basis HRFs. ridge_mode: Either \"absolute\" (default) \"fractional\". absolute mode,     ridge_x ridge_b used directly regularization parameters. fractional mode,     represent fractions maximum eigenvalue adaptive regularization. ridge_x: Ridge parameter trial-specific regressors (default 0). Controls     regularization strength individual trial estimates. ridge_b: Ridge parameter aggregator regressor (default 0). Controls     regularization strength sum trials. return_se: Logical, whether return standard errors (default FALSE). TRUE,     returns list beta (trial estimates) se (standard errors) components. return_diag: Logical, whether return design diagnostics (default FALSE).     TRUE, includes diagnostic information design matrix structure. block_cols: Integer, voxel block size memory-efficient processing (default 4096).     Larger values use memory may faster systems sufficient RAM. whiten: Logical, whether apply AR(1) whitening (default FALSE). TRUE,     estimates AR(1) coefficients pre-whitens data account temporal autocorrelation. ntrials: Explicit number trials (used K > 1 determine output dimensions).     provided, calculated ncol(X) / K. hrf_grid: Vector HRF indices grid-based HRF selection (advanced use).     Allows testing multiple HRF shapes simultaneously. OASIS method provides mathematically equivalent computationally optimized version standard LSS. reformulates per-trial GLM fitting single matrix operation, eliminating redundant computations. particularly beneficial designs many trials processing large datasets. K > 1 (multi-basis HRFs), output K*ntrials rows, basis functions trial arranged sequentially.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Least Squares Separate (LSS) Analysis — lss","text":"Mumford, J. ., Turner, B. O., Ashby, F. G., & Poldrack, R. . (2012). Deconvolving BOLD activation event-related designs multivoxel pattern classification analyses. NeuroImage, 59(3), 2636-2643.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Least Squares Separate (LSS) Analysis — lss","text":"","code":"# Generate example data n_timepoints <- 100 n_trials <- 10 n_voxels <- 50  # Create trial design matrix X <- matrix(0, n_timepoints, n_trials) for(i in 1:n_trials) {   start <- (i-1) * 8 + 1   if(start + 5 <= n_timepoints) {     X[start:(start+5), i] <- 1   } }  # Create data with some signal Y <- matrix(rnorm(n_timepoints * n_voxels), n_timepoints, n_voxels) true_betas <- matrix(rnorm(n_trials * n_voxels, 0, 0.5), n_trials, n_voxels) for(i in 1:n_trials) {   Y <- Y + X[, i] %*% matrix(true_betas[i, ], 1, n_voxels) }  # Run LSS analysis beta_estimates <- lss(Y, X)  # With experimental regressors (intercept + condition effects) Z <- cbind(1, scale(1:n_timepoints)) beta_estimates_with_regressors <- lss(Y, X, Z = Z)  # With nuisance regression (motion parameters) Nuisance <- matrix(rnorm(n_timepoints * 6), n_timepoints, 6) beta_estimates_clean <- lss(Y, X, Z = Z, Nuisance = Nuisance)  if (FALSE) { # \\dontrun{ # Using OASIS method with ridge regularization beta_oasis <- lss(Y, X, method = \"oasis\",                   oasis = list(ridge_x = 0.1, ridge_b = 0.1,                               ridge_mode = \"fractional\"))  # OASIS with standard errors result_with_se <- lss(Y, X, method = \"oasis\",                      oasis = list(return_se = TRUE)) beta_estimates <- result_with_se$beta standard_errors <- result_with_se$se  # Building design from event onsets using fmrihrf   sframe <- sampling_frame(blocklens = 200, TR = 1.0)    # OASIS with automatic design construction   beta_auto <- lss(Y, X = NULL, method = \"oasis\",                    oasis = list(                      design_spec = list(                        sframe = sframe,                        cond = list(                          onsets = c(10, 30, 50, 70, 90, 110, 130, 150),                          hrf = HRF_SPMG1,                          span = 25                        ),                        others = list(                          list(onsets = c(20, 40, 60, 80, 100, 120, 140))                        )                      )                    ))    # Multi-basis HRF example (3 basis functions per trial)   beta_multibasis <- lss(Y, X = NULL, method = \"oasis\",                         oasis = list(                           design_spec = list(                             sframe = sframe,                             cond = list(                               onsets = c(10, 30, 50, 70, 90),                               hrf = HRF_SPMG3,  # 3-basis HRF                               span = 30                             )                           ),                           K = 3  # Explicit basis dimension                         ))   # Returns 15 rows (5 trials * 3 basis functions) } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_beta_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","title":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","text":"Fast C++ implementation least squares separate (LSS) beta estimation using vectorized matrix operations. Computes trial betas single pass without loops.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_beta_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","text":"","code":"lss_beta_cpp(C_projected, Y_projected)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_beta_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","text":"C_projected Projected trial regressors (n x T) project_confounds_cpp Y_projected Projected data (n x V) project_confounds_cpp","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_beta_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","text":"Beta matrix (T x V) LSS estimates trial voxel","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_beta_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","text":"vectorized implementation computes LSS betas simultaneously using matrix algebra. significantly faster per-trial loops automatically benefits BLAS multithreading. algorithm handles numerical edge cases setting problematic denominators NaN. best performance large datasets, ensure R installation uses optimized BLAS (like OpenBLAS Intel MKL).","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_beta_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","text":"","code":"if (FALSE) { # \\dontrun{ # After projecting out confounds result <- project_confounds_cpp(X_confounds, Y_data, C_trials) betas <- lss_beta_cpp(result$Q_dmat_ran, result$residual_data) } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_cpp_optimized.html","id":null,"dir":"Reference","previous_headings":"","what":"A wrapper for the optimized C++ LSS implementation — lss_cpp_optimized","title":"A wrapper for the optimized C++ LSS implementation — lss_cpp_optimized","text":"wrapper optimized C++ LSS implementation","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_cpp_optimized.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A wrapper for the optimized C++ LSS implementation — lss_cpp_optimized","text":"","code":"lss_cpp_optimized(Y, bdes)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_cpp_optimized.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A wrapper for the optimized C++ LSS implementation — lss_cpp_optimized","text":"Y voxel time data matrix bdes block design list created block_design","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_cpp_optimized.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A wrapper for the optimized C++ LSS implementation — lss_cpp_optimized","text":"matrix beta estimates","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_fused_optim_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Fused Single-Pass LSS Solver (C++) — lss_fused_optim_cpp","title":"Fused Single-Pass LSS Solver (C++) — lss_fused_optim_cpp","text":"function computes Least Squares-Separate (LSS) beta estimates using memory-efficient, single-pass algorithm. fuses projection estimation steps, processing voxels parallel blocks maximize cache efficiency.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_fused_optim_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fused Single-Pass LSS Solver (C++) — lss_fused_optim_cpp","text":"","code":"lss_fused_optim_cpp(X, Y, C, block_size = 96L)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_fused_optim_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fused Single-Pass LSS Solver (C++) — lss_fused_optim_cpp","text":"X nuisance regressor matrix (confounds). Y data matrix (e.g., fMRI data). C trial-wise design matrix. block_size number voxels process parallel block.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_fused_optim_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fused Single-Pass LSS Solver (C++) — lss_fused_optim_cpp","text":"matrix LSS beta estimates.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_naive.html","id":null,"dir":"Reference","previous_headings":"","what":"Naive Least Squares Separate (LSS) Analysis — lss_naive","title":"Naive Least Squares Separate (LSS) Analysis — lss_naive","text":"Performs LSS analysis using naive approach trial model fit separately. conceptually simplest implementation less efficient optimized lss function.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_naive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Naive Least Squares Separate (LSS) Analysis — lss_naive","text":"","code":"lss_naive(Y = NULL, bdes, dset = NULL)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_naive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Naive Least Squares Separate (LSS) Analysis — lss_naive","text":"Y numeric matrix rows timepoints columns voxels/features. NULL, function attempt extract data dset. bdes list containing design matrices components: dmat_base: Base design matrix (e.g., intercept, drift terms) dmat_fixed: Fixed effects design matrix (optional) dmat_ran: Random/trial design matrix LSS analysis fixed_ind: Indices fixed effects (optional) dset Optional dataset object. provided Y NULL, data extracted using get_data_matrix.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_naive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Naive Least Squares Separate (LSS) Analysis — lss_naive","text":"numeric matrix dimensions (n_events x n_voxels) containing LSS beta estimates trial voxel.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_naive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Naive Least Squares Separate (LSS) Analysis — lss_naive","text":"function implements naive LSS approach trial, separate GLM fitted includes: base regressors (intercept, drift, etc.) fixed effects regressors () current trial's regressor trial design matrix less efficient optimized lss function, implementation conceptually simpler can serve reference validation purposes.","code":""},{"path":[]},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_naive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Naive Least Squares Separate (LSS) Analysis — lss_naive","text":"","code":"if (FALSE) { # \\dontrun{ # Using same setup as lss() examples beta_estimates_naive <- lss_naive(Y = Y, bdes = bdes)  # Compare with optimized version beta_estimates_fast <- lss(Y = Y, bdes = bdes) max(abs(beta_estimates_naive - beta_estimates_fast)) } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_optimized.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimized LSS Analysis (Pure R) — lss_optimized","title":"Optimized LSS Analysis (Pure R) — lss_optimized","text":"optimized version LSS analysis avoids creating large intermediate matrices, providing significant speedup lower memory usage pure R implementation.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_optimized.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimized LSS Analysis (Pure R) — lss_optimized","text":"","code":"lss_optimized(Y = NULL, bdes, dset = NULL, use_cpp = TRUE)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_optimized.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimized LSS Analysis (Pure R) — lss_optimized","text":"Y numeric matrix rows timepoints columns voxels/features. bdes list containing design matrices. dset Optional dataset object. use_cpp Logical. TRUE (default), uses C++ implementation. FALSE, uses new optimized R implementation.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_optimized.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimized LSS Analysis (Pure R) — lss_optimized","text":"numeric matrix LSS beta estimates.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform LSS using Voxel-wise HRFs — lss_with_hrf","title":"Perform LSS using Voxel-wise HRFs — lss_with_hrf","text":"Computes trial-wise beta estimates using voxel-specific HRFs.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform LSS using Voxel-wise HRFs — lss_with_hrf","text":"","code":"lss_with_hrf(   Y,   events,   hrf_estimates,   nuisance_regs = NULL,   engine = \"R\",   chunk_size = 5000,   verbose = TRUE,   backing_dir = NULL )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform LSS using Voxel-wise HRFs — lss_with_hrf","text":"Y Numeric matrix BOLD data (time x voxels). events Data frame onset, duration condition columns. hrf_estimates VoxelHRF object returned estimate_voxel_hrf. nuisance_regs Optional numeric matrix nuisance regressors. engine Computational engine: \"R\" pure R implementation (default), \"C++\" optimized C++ (experimental). chunk_size Number voxels process per batch (C++ engine ). verbose Logical; display progress bar. backing_dir Directory bigmemory backing files. NULL, temporary directory used (C++ engine ).","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform LSS using Voxel-wise HRFs — lss_with_hrf","text":"object class LSSBeta C++ engine, numeric matrix   (n_trials x n_vox) R engine.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform LSS using Voxel-wise HRFs — lss_with_hrf","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(1) Y <- matrix(rnorm(100), 50, 2) events <- data.frame(onset = c(5, 25), duration = 1,                      condition = \"A\") basis <- fmrihrf::hrf_gamma() sframe <- fmrihrf::sampling_frame(blocklens = nrow(Y), TR = 1) times <- fmrihrf::samples(sframe, global = TRUE) rset <- fmrihrf::regressor_set(onsets = events$onset,                                fac = factor(1:nrow(events)),                                hrf = basis, duration = events$duration,                                span = 30) X <- fmrihrf::evaluate(rset, grid = times, precision = 0.1, method = \"conv\") coef <- matrix(rnorm(ncol(X) * ncol(Y)), ncol(X), ncol(Y)) Y <- X %*% coef + Y * 0.1 est <- estimate_voxel_hrf(Y, events, basis) betas <- lss_with_hrf(Y, events, est, verbose = FALSE, engine = \"R\") dim(betas) } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf_pure_r.html","id":null,"dir":"Reference","previous_headings":"","what":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","title":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","text":"Compute LSS trial-wise betas voxel HRF formed linear combination K basis kernels sampled TR grid.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf_pure_r.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","text":"","code":"lss_with_hrf_pure_r(   Y,   onset_idx,   durations = NULL,   hrf_basis_kernels,   coefficients,   Z = NULL,   Nuisance = NULL,   verbose = FALSE,   method = c(\"r\", \"cpp\", \"cpp_arma\", \"cpp_omp\") )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf_pure_r.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","text":"Y numeric matrix (n_time x n_vox) onset_idx integer vector (length n_trials), 1-based TR indices durations numeric vector (length n_trials), TRs; 0 means impulse. Uses inclusive indexing: duration = d, samples o:(o+d) 1. hrf_basis_kernels numeric matrix (L x K), K basis kernels TR grid coefficients numeric matrix (K x n_vox), voxel-wise HRF weights Z optional numeric matrix (n_time x F) experimental regressors; NULL, intercept (column 1s) used. Nuisance optional numeric matrix (n_time x q) confounds project verbose logical; print progress every 1000 voxels method character: \"r\" (default, pure R), \"cpp\" (C++ backend), \"cpp_arma\" (Armadillo backend), \"cpp_omp\" (OpenMP parallel backend). Falls back automatically: cpp_omp -> cpp_arma -> cpp -> r.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf_pure_r.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","text":"numeric matrix (n_trials x n_vox) trial-wise beta estimates","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf_pure_r.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","text":"**Design & nuisance handling match `lss()`**:   - trial--interest (Xi) sum trials (Xother)     included per-trial GLM.   - `Nuisance` supplied, projected **Y** trial     regressors LSS (standard residualization). Experimental regressors     `Z` ** residualized, matching `lss()` documentation.   - `Z` `NULL`, intercept-design used.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf_pure_r.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","text":"","code":"if (FALSE) { # \\dontrun{ # Minimal use (R backend): betas <- lss_with_hrf_pure_r(Y, onset_idx, durations, basis, coeffs, Z = NULL, Nuisance = NULL) # Or with C++ backend: betas <- lss_with_hrf_pure_r(Y, onset_idx, durations, basis, coeffs, method = \"cpp\") } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_multi_voxel_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimized multi-voxel mixed model estimation — mixed_multi_voxel_cpp","title":"Optimized multi-voxel mixed model estimation — mixed_multi_voxel_cpp","text":"Uses precomputed workspace parallel processing efficiently estimate mixed models across many voxels.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_multi_voxel_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimized multi-voxel mixed model estimation — mixed_multi_voxel_cpp","text":"","code":"mixed_multi_voxel_cpp(Y, ws_list, compute_se = FALSE, n_threads = 0L)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_multi_voxel_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimized multi-voxel mixed model estimation — mixed_multi_voxel_cpp","text":"Y Response matrix (n × V) V number voxels ws_list Precomputed workspace (R list) compute_se Whether compute standard errors n_threads Number OpenMP threads (0 = auto)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_multi_voxel_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimized multi-voxel mixed model estimation — mixed_multi_voxel_cpp","text":"List matrices estimates across voxels","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute.html","id":null,"dir":"Reference","previous_headings":"","what":"Precompute Workspace for Optimized Mixed Model — mixed_precompute","title":"Precompute Workspace for Optimized Mixed Model — mixed_precompute","text":"Performs expensive matrix computations depend response vector, allowing efficient reuse across multiple voxels.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Precompute Workspace for Optimized Mixed Model — mixed_precompute","text":"","code":"mixed_precompute(X, Z, K = NULL)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Precompute Workspace for Optimized Mixed Model — mixed_precompute","text":"X Fixed effects design matrix (n × p) Z Random effects design matrix (n × q) K Kinship/covariance matrix random effects (q × q)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Precompute Workspace for Optimized Mixed Model — mixed_precompute","text":"Workspace object use mixed_solve_optimized","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute_workspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Precompute workspace for mixed model optimization — mixed_precompute_workspace","title":"Precompute workspace for mixed model optimization — mixed_precompute_workspace","text":"Performs expensive computations depend response vector y, can reused across multiple voxels.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute_workspace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Precompute workspace for mixed model optimization — mixed_precompute_workspace","text":"","code":"mixed_precompute_workspace(X, Z, K)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute_workspace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Precompute workspace for mixed model optimization — mixed_precompute_workspace","text":"X Fixed effects design matrix (n × p) Z Random effects design matrix (n × q) K Kinship/covariance matrix random effects (q × q)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute_workspace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Precompute workspace for mixed model optimization — mixed_precompute_workspace","text":"MixedWorkspace object containing precomputed matrices","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_single_voxel_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast single-voxel mixed model estimation using precomputed workspace — mixed_single_voxel_cpp","title":"Fast single-voxel mixed model estimation using precomputed workspace — mixed_single_voxel_cpp","text":"Fast single-voxel mixed model estimation using precomputed workspace","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_single_voxel_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast single-voxel mixed model estimation using precomputed workspace — mixed_single_voxel_cpp","text":"","code":"mixed_single_voxel_cpp(y, ws_list, compute_se = FALSE)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_single_voxel_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast single-voxel mixed model estimation using precomputed workspace — mixed_single_voxel_cpp","text":"y Response vector single voxel ws_list Precomputed workspace (R list) compute_se Whether compute standard errors","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_single_voxel_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fast single-voxel mixed model estimation using precomputed workspace — mixed_single_voxel_cpp","text":"List beta, u, Vu, Ve, optionally standard errors","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixed Model Solver — mixed_solve","title":"Mixed Model Solver — mixed_solve","text":"Solves mixed models random effects using REML ML estimation. function provides unified interface mixed model estimation, similar lss/lsa functions package.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mixed Model Solver — mixed_solve","text":"","code":"mixed_solve(   Y,   X = NULL,   Z = NULL,   K = NULL,   Nuisance = NULL,   method = c(\"REML\", \"ML\"),   bounds = c(1e-09, 1e+09),   SE = FALSE,   return_Hinv = FALSE )  mixed_solve_cpp(   Y,   X = NULL,   Z = NULL,   K = NULL,   Nuisance = NULL,   method = c(\"REML\", \"ML\"),   bounds = c(1e-09, 1e+09),   SE = FALSE,   return_Hinv = FALSE )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mixed Model Solver — mixed_solve","text":"Y Response vector matrix. matrix, column treated separate response variable. X Design matrix fixed effects. NULL, defaults intercept . Z Design matrix random effects. NULL, defaults identity matrix. K Kinship matrix random effects. NULL, defaults identity matrix. Nuisance alias X, provided consistency lss/lsa interface. X Nuisance provided, X takes precedence. method Character string specifying estimation method: \"REML\" - Restricted Maximum Likelihood (default) \"ML\" - Maximum Likelihood bounds Numeric vector length 2 specifying bounds variance component optimization. Defaults c(1e-9, 1e9). SE Logical, whether compute return standard errors. Defaults FALSE. return_Hinv Logical, whether return inverse H matrix. Defaults FALSE.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mixed Model Solver — mixed_solve","text":"list containing: Vu Estimated variance component random effects. Ve Estimated variance component residuals. beta Estimated fixed effects coefficients. u Estimated random effects coefficients. LL Log-likelihood model. beta.SE Standard errors fixed effects coefficients (SE = TRUE). u.SE Standard errors random effects coefficients (SE = TRUE). Hinv Inverse H matrix (return_Hinv = TRUE).","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mixed Model Solver — mixed_solve","text":"function fits mixed model: Y = X*beta + Z*u + error, u ~ N(0, Vu*K) error ~ N(0, Ve*). variance components Vu Ve estimated using REML ML.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mixed Model Solver — mixed_solve","text":"","code":"if (FALSE) { # \\dontrun{ # Example with random data set.seed(123) n <- 100 Y <- rnorm(n) Z <- matrix(rnorm(n * 5), n, 5) K <- diag(5) X <- matrix(1, n, 1)  # Fit mixed model result <- mixed_solve(Y, X, Z, K) } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve_optimized.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimized Mixed Model Solver — mixed_solve_optimized","title":"Optimized Mixed Model Solver — mixed_solve_optimized","text":"optimized implementation mixed model estimation precomputes expensive matrix operations can reused across multiple voxels significant performance improvements.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve_optimized.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimized Mixed Model Solver — mixed_solve_optimized","text":"","code":"mixed_solve_optimized(   X,   Z,   Y,   K = NULL,   workspace = NULL,   compute_se = FALSE,   n_threads = 0 )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve_optimized.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimized Mixed Model Solver — mixed_solve_optimized","text":"X Fixed effects design matrix (n × p) Z Random effects design matrix (n × q) Y Response data - can vector (single voxel) matrix (n × V multiple voxels) K Kinship/covariance matrix random effects (q × q). Defaults identity. workspace Precomputed workspace (optional, compute NULL) compute_se Whether compute standard errors (default: FALSE) n_threads Number OpenMP threads multi-voxel (0 = auto)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve_optimized.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimized Mixed Model Solver — mixed_solve_optimized","text":"List estimated parameters variance components","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/plot_hrf_comparison.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot HRF Recovery Comparison — plot_hrf_comparison","title":"Plot HRF Recovery Comparison — plot_hrf_comparison","text":"Creates visualization comparing true vs recovered HRFs","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/plot_hrf_comparison.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot HRF Recovery Comparison — plot_hrf_comparison","text":"","code":"plot_hrf_comparison(results, save_path = NULL)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/plot_hrf_comparison.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot HRF Recovery Comparison — plot_hrf_comparison","text":"results Output compare_hrf_recovery save_path Optional path save plot","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds.html","id":null,"dir":"Reference","previous_headings":"","what":"Project Out Confound Variables — project_confounds","title":"Project Out Confound Variables — project_confounds","text":"Computes orthogonal projection matrix Q = - X(X'X)^(-1)X' projects space spanned confound regressors X. useful advanced users want cache reuse projection matrices.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project Out Confound Variables — project_confounds","text":"","code":"project_confounds(X)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project Out Confound Variables — project_confounds","text":"X Confound design matrix (n x p) n number timepoints p number confound regressors","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project Out Confound Variables — project_confounds","text":"Projection matrix Q (n x n) projects column space X","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Project Out Confound Variables — project_confounds","text":"function uses QR decomposition numerical stability instead computing Moore-Penrose pseudoinverse directly. resulting matrix Q can applied data remove influence confound regressors.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project Out Confound Variables — project_confounds","text":"","code":"if (FALSE) { # \\dontrun{ # Create confound matrix (intercept + linear trend) n <- 100 X_confounds <- cbind(1, 1:n)  # Get projection matrix Q <- project_confounds(X_confounds)  # Apply to data to remove confounds Y_clean <- Q %*% Y_raw } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Project Out Confounds Using C++ — project_confounds_cpp","title":"Project Out Confounds Using C++ — project_confounds_cpp","text":"Fast C++ implementation projecting confound variables data trial design matrices. uses Cholesky decomposition numerical stability avoids creating large projection matrices.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project Out Confounds Using C++ — project_confounds_cpp","text":"","code":"project_confounds_cpp(X_confounds, Y_data, C_trials)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project Out Confounds Using C++ — project_confounds_cpp","text":"X_confounds Confound design matrix (n x k) Y_data Data matrix (n x V) V number voxels C_trials Trial design matrix (n x T) T number trials","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project Out Confounds Using C++ — project_confounds_cpp","text":"List projected data (residual_data) projected trials (Q_dmat_ran)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Project Out Confounds Using C++ — project_confounds_cpp","text":"function computes residuals Y - X(X'X)^(-1)X'Y C - X(X'X)^(-1)X'C without explicitly forming projection matrix Q = - X(X'X)^(-1)X'. approach uses ~100x less memory large n numerically stable.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project Out Confounds Using C++ — project_confounds_cpp","text":"","code":"if (FALSE) { # \\dontrun{ n <- 200; k <- 5; V <- 1000; T <- 50 X_confounds <- cbind(1, 1:n, rnorm(n*3))  # intercept + trend + noise Y_data <- matrix(rnorm(n*V), n, V) C_trials <- matrix(rnorm(n*T), n, T)  result <- project_confounds_cpp(X_confounds, Y_data, C_trials) } # }"}]
