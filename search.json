[{"path":"https://bbuchsbaum.github.io/fmrilss/CLAUDE.html","id":null,"dir":"","previous_headings":"","what":"CLAUDE.md","title":"CLAUDE.md","text":"file provides guidance Claude Code (claude.ai/code) working code repository.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/CLAUDE.html","id":"repository-overview","dir":"","previous_headings":"","what":"Repository Overview","title":"CLAUDE.md","text":"fmrilss R package implementing efficient Least Squares Separate (LSS) analysis functional magnetic resonance imaging (fMRI) data. LSS used estimate trial--trial activation patterns event-related fMRI designs, critical multivariate pattern analysis (MVPA) connectivity studies. package provides multiple backends, R implementations highly optimized C++ OpenMP parallelization.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/CLAUDE.html","id":"core-architecture","dir":"","previous_headings":"","what":"Core Architecture","title":"CLAUDE.md","text":"package provides five implementations LSS algorithm, accessible unified interface: - cpp_optimized: Parallelized C++ using OpenMP (fastest) - optimized: Optimized R version - vectorized: Standard vectorized R - cpp_vectorized: Standard C++ - loop: Simple R loop (reference implementation) Key design pattern: methods use lss(Y, X, Z, Nuisance) signature : - Y: data matrix (timepoints x voxels) - X: trial design matrix (one column per trial) - Z: experimental regressors (intercept, trends, blocks) - Nuisance: regressors project (motion, physiology)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/CLAUDE.html","id":"essential-commands","dir":"","previous_headings":"","what":"Essential Commands","title":"CLAUDE.md","text":"","code":"# Build and install package devtools::build() devtools::install()  # Run tests devtools::test()                    # Run all tests devtools::test_active_file()       # Test current file testthat::test_file(\"tests/testthat/test-lss-equivalence.R\")  # Single test file  # Check package devtools::check()                  # Full R CMD check devtools::check_examples()         # Check examples only  # Documentation devtools::document()               # Update roxygen documentation pkgdown::build_site()             # Build package website  # Load for development devtools::load_all()              # Load package without installing"},{"path":"https://bbuchsbaum.github.io/fmrilss/CLAUDE.html","id":"c-compilation","dir":"","previous_headings":"","what":"C++ Compilation","title":"CLAUDE.md","text":"package uses Rcpp Armadillo matrix operations. OpenMP configured via src/Makevars: - Automatic OpenMP detection configuration - Falls back gracefully OpenMP unavailable - Links: Rcpp, RcppArmadillo, roptim, bigmemory, BH","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/CLAUDE.html","id":"testing-strategy","dir":"","previous_headings":"","what":"Testing Strategy","title":"CLAUDE.md","text":"Tests verify: 1. Mathematical equivalence across implementations 2. Correctness ground truth 3. Edge cases (missing data, singular matrices) 4. HRF convolution integration 5. OASIS deconvolution methods Test files follow pattern test-{feature}.R tests/testthat/.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/CLAUDE.html","id":"key-dependencies","dir":"","previous_headings":"","what":"Key Dependencies","title":"CLAUDE.md","text":"fmrihrf: Custom HRF modeling (GitHub: bbuchsbaum/fmrihrf) RcppArmadillo: Matrix operations C++ roptim: Optimization routines MASS: Statistical functions","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/CLAUDE.html","id":"vignettes","dir":"","previous_headings":"","what":"Vignettes","title":"CLAUDE.md","text":"Three main vignettes demonstrate package usage: - getting_started.Rmd: Basic LSS concepts usage - oasis_method.Rmd: OASIS deconvolution integration - performance_optimization.Rmd: Backend comparison optimization","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"the-challenge-of-event-related-fmri-analysis","dir":"Articles","previous_headings":"","what":"The Challenge of Event-Related fMRI Analysis","title":"Getting Started with fmrilss","text":"event-related fMRI experiments rapid stimulus presentation, hemodynamic responses consecutive trials overlap substantially due slow temporal dynamics BOLD signal (10-15 seconds). Traditional general linear models (GLMs) estimate trials simultaneously suffer collinearity inter-stimulus intervals short (< 4 seconds), resulting unstable trial-specific activation estimates. unstable estimates compromise downstream analyses including multivariate pattern analysis (MVPA), representational similarity analysis (RSA), trial--trial connectivity methods. Least Squares Separate (LSS) approach (Mumford et al., 2012) addresses collinearity problem fitting separate GLM trial. model, one regressor represents trial interest second regressor aggregates trials, reducing collinearity improving estimate stability. fmrilss package provides optimized implementations LSS extensions including automatic HRF estimation, ridge regularization, parallel computation across multiple CPU cores.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"understanding-the-lss-approach","dir":"Articles","previous_headings":"","what":"Understanding the LSS Approach","title":"Getting Started with fmrilss","text":"vignette assumes familiarity fMRI general linear models, design matrices, hemodynamic response functions, R matrix operations. Standard GLM analysis (Least Squares , LSA) estimates trial coefficients simultaneously solving: β = (X’X)^(-1)X’Y. trials occur rapid succession, design matrix columns exhibit high correlation (condition number > 30), producing unstable estimates inflated variance. LSS reformulates problem fitting N separate models, N number trials. trial , design matrix contains: (1) regressor trial , (2) single regressor aggregating trials, (3) nuisance baseline regressors. reduces effective condition number produces stable single-trial estimates. Mathematically, trial : β_i = (X_i’X_i)^(-1)X_i’Y X_i = [x_i | Σ(j≠) x_j | Z | N], x_i trial regressor, Z experimental covariates, N nuisance regressors. Beyond two core regressors, LSS models can include experimental regressors capture session-wide effects like linear trends block effects, want model don’t need trial-specific estimates . model can also incorporate nuisance regressors motion parameters physiological noise, projected analysis begins.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"your-first-lss-analysis","dir":"Articles","previous_headings":"","what":"Your First LSS Analysis","title":"Getting Started with fmrilss","text":"following example demonstrates LSS analysis using synthetic data rapid event-related design.","code":"library(fmrihrf) #>  #> Attaching package: 'fmrihrf' #> The following object is masked from 'package:stats': #>  #>     deriv library(fmrilss)  set.seed(42) n_timepoints <- 150 n_trials <- 12 n_voxels <- 25"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"creating-the-experimental-design","dir":"Articles","previous_headings":"Your First LSS Analysis","what":"Creating the Experimental Design","title":"Getting Started with fmrilss","text":"design matrix encodes stimulus timing expected hemodynamic responses. Matrix X contains trial regressors (using box-car functions simplicity, though HRF convolution standard). Matrix Z contains experimental covariates (intercept linear trend). nuisance matrix models unwanted variance (e.g., motion parameters).","code":"# Trial design matrix (X) X <- matrix(0, n_timepoints, n_trials) # Ensure integer onsets within bounds onsets <- round(seq(from = 10, to = n_timepoints - 12, length.out = n_trials)) for(i in 1:n_trials) {   X[onsets[i]:(onsets[i] + 5), i] <- 1 }  # Experimental regressors (Z) - intercept and condition effects # These are regressors we want to model and get estimates for, but not trial-wise Z <- cbind(Intercept = 1, LinearTrend = as.vector(scale(1:n_timepoints, center = TRUE, scale = FALSE)))  # Nuisance regressors - e.g., 6 motion parameters Nuisance <- matrix(rnorm(n_timepoints * 6), n_timepoints, 6)"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"visualizing-regressors","dir":"Articles","previous_headings":"Your First LSS Analysis","what":"Visualizing Regressors","title":"Getting Started with fmrilss","text":"following visualizations show experimental regressors (excluding intercept) nuisance regressors, standardized comparability.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"single-trial-regressors","dir":"Articles","previous_headings":"Your First LSS Analysis","what":"Single-Trial Regressors","title":"Getting Started with fmrilss","text":"Trial regressor structure visualized time × trial heatmap:","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"generating-realistic-data","dir":"Articles","previous_headings":"Your First LSS Analysis","what":"Generating Realistic Data","title":"Getting Started with fmrilss","text":"Now ’ll create synthetic fMRI data includes contributions components, plus noise make realistic:","code":"# Simulate effects for each component true_trial_betas <- matrix(rnorm(n_trials * n_voxels, 0, 1.2), n_trials, n_voxels) true_fixed_effects <- matrix(rnorm(2 * n_voxels, c(5, -0.1), 0.5), 2, n_voxels) true_nuisance_effects <- matrix(rnorm(6 * n_voxels, 0, 2), 6, n_voxels)  # Combine signals and add noise Y <- (Z %*% true_fixed_effects) +      (X %*% true_trial_betas) +      (Nuisance %*% true_nuisance_effects) +      matrix(rnorm(n_timepoints * n_voxels, 0, 1), n_timepoints, n_voxels)"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"running-the-analysis","dir":"Articles","previous_headings":"Your First LSS Analysis","what":"Running the Analysis","title":"Getting Started with fmrilss","text":"lss() function provides clean, modern interface adapts needs. simplest, can provide just data trial matrix, function automatically includes intercept term: complete analysis accounts experimental effects removes nuisance signals, include Z Nuisance matrices. function handles nuisance regression efficiently, projecting signals data design matrix estimating trial-specific betas:","code":"beta_basic <- lss(Y, X) # The result is a trials-by-voxels matrix dim(beta_basic) #> [1] 12 25 beta_full <- lss(Y, X, Z = Z, Nuisance = Nuisance) # The output dimensions remain the same dim(beta_full) #> [1] 12 25"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"handling-temporal-autocorrelation-with-prewhitening","dir":"Articles","previous_headings":"","what":"Handling Temporal Autocorrelation with Prewhitening","title":"Getting Started with fmrilss","text":"fMRI time series exhibit temporal autocorrelation can affect statistical inference. fmrilss package now integrates fmriAR provide sophisticated prewhitening capabilities: advanced noise modeling, can use voxel-specific parameters ARMA models:","code":"# Basic AR(1) prewhitening beta_ar1 <- lss(Y, X, Z = Z, Nuisance = Nuisance,                 prewhiten = list(method = \"ar\", p = 1))  # Automatic AR order selection beta_auto <- lss(Y, X, Z = Z, Nuisance = Nuisance,                 prewhiten = list(method = \"ar\", p = \"auto\", p_max = 4))  # The prewhitened estimates account for temporal dependencies dim(beta_ar1) #> [1] 12 25 # Voxel-specific AR parameters beta_voxel <- lss(Y, X, Z = Z, Nuisance = Nuisance,                   prewhiten = list(method = \"ar\", p = 1, pooling = \"voxel\"))  # ARMA model for complex noise beta_arma <- lss(Y, X, Z = Z, Nuisance = Nuisance,                 prewhiten = list(method = \"arma\", p = 2, q = 1))"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"choosing-the-right-computational-backend","dir":"Articles","previous_headings":"","what":"Choosing the Right Computational Backend","title":"Getting Started with fmrilss","text":"fmrilss package offers multiple computational backends, optimized different scenarios. default R implementation well-optimized readable, making excellent understanding algorithm debugging, ’ll often want use high-performance C++ backend real analyses, especially large datasets. C++ implementation leverages Armadillo efficient linear algebra OpenMP parallel processing across multiple CPU cores: modular design allows seamless switching backends without code changes. R implementation facilitates debugging development, C++ version provides production performance.","code":"# Run the same analysis with the high-performance C++ engine beta_fast <- lss(Y, X, Z = Z, Nuisance = Nuisance, method = \"cpp_optimized\")  # The results are numerically identical to the R version all.equal(beta_full, beta_fast, tolerance = 1e-8) #> [1] TRUE  # Combine prewhitening with fast computation beta_fast_ar <- lss(Y, X, Z = Z, Nuisance = Nuisance,                     method = \"cpp_optimized\",                     prewhiten = list(method = \"ar\", p = 1))"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"lss-versus-traditional-glm-when-each-shines","dir":"Articles","previous_headings":"","what":"LSS versus Traditional GLM: When Each Shines","title":"Getting Started with fmrilss","text":"Comparison LSS standard Least Squares (LSA) methods:  LSS produces beta estimates different variance characteristics LSA. Method selection criteria: Use LSS : - MVPA pattern classification analyses - Rapid event-related designs (ISI < 4 seconds) - Trial--trial connectivity analyses - Representational similarity analysis (RSA) Use LSA : - Block designs well-separated trials - Group-level contrast estimation - Designs ISI > 6 seconds - computational efficiency critical","code":"# LSA: Standard GLM with all trials in one model beta_lsa <- lsa(Y, X, Z = Z, Nuisance = Nuisance)  # Compare dimensions cat(\"LSS beta dimensions:\", dim(beta_full), \"\\n\") #> LSS beta dimensions: 12 25 cat(\"LSA beta dimensions:\", dim(beta_lsa), \"\\n\") #> LSA beta dimensions: 12 25  # Compare variance in beta estimates var_lss <- apply(beta_full, 2, var) var_lsa <- apply(beta_lsa, 2, var)  cat(\"\\nMean variance across voxels:\\n\") #>  #> Mean variance across voxels: cat(\"  LSS:\", mean(var_lss), \"\\n\") #>   LSS: 1.826826 cat(\"  LSA:\", mean(var_lsa), \"\\n\") #>   LSA: 4.297449  # Plot comparison par(mfrow = c(1, 2)) hist(beta_full[, 1], main = \"LSS: Beta distribution (Voxel 1)\",      xlab = \"Beta values\", col = \"lightblue\") hist(beta_lsa[, 1], main = \"LSA: Beta distribution (Voxel 1)\",      xlab = \"Beta values\", col = \"lightgreen\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"introducing-the-oasis-method","dir":"Articles","previous_headings":"","what":"Introducing the OASIS Method","title":"Getting Started with fmrilss","text":"OASIS (Optimized Analytic Single-pass Inverse Solution) method extends LSS : automatic HRF estimation, ridge regularization stability, single-pass computation trials, multi-basis HRF model support. pass X = NULL together design_spec OASIS can rebuild trial-wise design event description HRF settings every call. Internally (see R/oasis_glue.R) solver calls fmrihrf generate appropriate basis requested HRF, apply span/precision choices, add extra conditions single-pass solve. keeps design sync changes HRF (example running grid search switching FIR basis) without requiring hand-maintain matching matrix. already fixed design matrix can still provide via X, high-level design_spec path recommended interface HRF part want OASIS manage.","code":"# Basic OASIS usage # fmrihrf is now imported automatically beta_oasis <- lss(   Y = Y,   X = NULL,  # OASIS builds design internally   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sampling_frame(blocklens = nrow(Y), TR = 1),       cond = list(         onsets = onsets,        # reuse onsets from above         hrf = HRF_SPMG1,        # HRF model         span = 30       )     ),     ridge_mode = \"fractional\",     ridge_x = 0.01,     ridge_b = 0.01   ) )  cat(\"OASIS beta dimensions:\", dim(beta_oasis), \"\\n\") #> OASIS beta dimensions: 12 25"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"working-with-different-computational-backends","dir":"Articles","previous_headings":"","what":"Working with Different Computational Backends","title":"Getting Started with fmrilss","text":"package provides multiple backends match computational needs resources. backend implements algorithm different optimization strategies. naive implementation offers clearest code understanding algorithm, vectorized optimized R versions provide good performance pure R code. production work large datasets, C++ backend offers best performance, especially combined parallel processing.","code":"# Benchmark different methods library(microbenchmark)  methods <- c(\"naive\", \"r_vectorized\", \"r_optimized\", \"cpp_optimized\") timings <- list()  for (m in methods) {   timings[[m]] <- system.time({     lss(Y, X, method = m)   })[3] }  # Display timing comparison timing_df <- data.frame(   Method = methods,   Time = unlist(timings) ) print(timing_df)  # For large datasets, consider threading for C++ backends if (require(\"parallel\")) {   n_cores <- parallel::detectCores() - 1   # Set OpenMP threads for C++ backend if supported   Sys.setenv(OMP_NUM_THREADS = n_cores) }"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"handling-complex-experimental-designs","dir":"Articles","previous_headings":"","what":"Handling Complex Experimental Designs","title":"Getting Started with fmrilss","text":"Real experiments often involve multiple conditions, parametric modulations, various covariates. fmrilss package handles complexities gracefully. working multiple conditions, can create separate design matrices condition include condition labels experimental regressors. allows model condition-specific effects still obtaining trial-wise estimates within condition. Parametric modulations, trial responses weighted continuous variables like reaction time stimulus intensity, also straightforward implement. quantitative demo, simulate parametric effect data show recovery without modulator:","code":"# Create design with multiple conditions n_cond <- 3 X_multi <- matrix(0, n_timepoints, n_trials * n_cond)  # Generate a simple HRF for demonstration hrf <- c(0, 0.2, 0.5, 0.8, 1, 0.9, 0.7, 0.5, 0.3, 0.1)  for (c in 1:n_cond) {   trial_idx <- ((c-1) * n_trials + 1):(c * n_trials)   for (i in 1:n_trials) {     onset <- 10 + (trial_idx[i] - 1) * 5     if (onset + 9 <= n_timepoints) {       X_multi[onset:(onset + 9), trial_idx[i]] <- hrf     }   } }  # Add condition labels as experimental regressors Z_cond <- matrix(0, n_timepoints, n_cond) for (c in 1:n_cond) {   trial_idx <- ((c-1) * n_trials + 1):(c * n_trials)   Z_cond[, c] <- rowSums(X_multi[, trial_idx, drop = FALSE]) }  # Run LSS with condition regressors beta_multi <- lss(Y, X_multi, Z = Z_cond, method = \"r_optimized\") #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_28' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_29' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_30' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_31' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_32' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_33' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_34' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_35' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .check_zero_regressors(X): Trial regressor 'Trial_36' appears to be #> zero (norm = 0). This may cause numerical issues or NaN results. #> Warning in .lss_engine_optimized(dset = dset, bdes = bdes, Y = Y, use_cpp = #> use_cpp): No intercept detected in dmat_base. Consider adding one for proper #> baseline modeling. # Add parametric modulator (e.g., reaction time, stimulus intensity) modulator <- scale(rnorm(n_trials, mean = 0, sd = 1), center = TRUE, scale = FALSE)  # Create parametrically modulated design (scale each trial by its modulator) X_param <- sweep(X, 2, as.numeric(modulator), `*`)  # Simulate data with a parametric effect (reuse fixed and nuisance parts) Y_mod <- (Z %*% true_fixed_effects) +          (X_param %*% true_trial_betas) +          (Nuisance %*% true_nuisance_effects) +          matrix(rnorm(n_timepoints * n_voxels, 0, 1), n_timepoints, n_voxels)  # Fit models with and without the parametric modulator beta_unmod <- lss(Y_mod, X,       Z = Z, method = \"r_optimized\") beta_param <- lss(Y_mod, X_param, Z = Z, method = \"r_optimized\")  # Ground truths for comparison # - For unmodulated design X, the true coefficients are modulator * true_trial_betas true_unmod_coefs <- sweep(true_trial_betas, 1, as.numeric(modulator), `*`) # - For parametrically modulated design X_param, the true coefficients are true_trial_betas  cor_unmod <- cor(as.vector(beta_unmod), as.vector(true_unmod_coefs)) cor_param <- cor(as.vector(beta_param), as.vector(true_trial_betas))  cat(\"Correlation with true coefficients (parametric effect simulated):\\n\") #> Correlation with true coefficients (parametric effect simulated): cat(\"  Using X (no modulator):\\t\", round(cor_unmod, 3), \"\\n\") #>   Using X (no modulator):     0.532 cat(\"  Using X_param (with modulator):\", round(cor_param, 3), \"\\n\") #>   Using X_param (with modulator): 0.37"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"optimizing-performance-for-large-scale-analyses","dir":"Articles","previous_headings":"","what":"Optimizing Performance for Large-Scale Analyses","title":"Getting Started with fmrilss","text":"working whole-brain data containing hundreds thousands voxels, memory management computational efficiency become critical. package provides several strategies handling large datasets effectively. large datasets exceed available memory, can process voxels chunks. approach maintains reasonable memory usage still benefiting vectorized operations within chunk: Another optimization strategy involves preprocessing data remove nuisance signals running LSS. LSS can handle nuisance regressors internally, preprocessing can efficient running multiple analyses: Choosing right backend data size crucial optimal performance. Based synthetic benchmarks OASIS vignette, optimized R fused C++ implementations perform almost identically small--medium problems (hundreds trials, thousand voxels); C++ path pulls slightly ahead voxel count grows tens thousands. OASIS stays ballpark workloads, typically reach also want HRF-aware features (automatic design construction, ridge, FIR support, grid search) rather purely speed, extras make comparison less apples--apples. practice pick backend matches tooling need (R ease debugging, C++ maximum throughput, OASIS want richer HRF workflow) validate short benchmark data.","code":"# For very large datasets, process in chunks chunk_size <- 1000 n_chunks <- ceiling(ncol(Y) / chunk_size)  beta_chunks <- list() for (chunk in 1:n_chunks) {   voxel_idx <- ((chunk - 1) * chunk_size + 1):min(chunk * chunk_size, ncol(Y))   beta_chunks[[chunk]] <- lss(Y[, voxel_idx], X, method = \"cpp_optimized\") }  # Combine results beta_full <- do.call(cbind, beta_chunks) # Project out nuisance before LSS (when appropriate) # project_confounds returns the projection matrix Q; apply it to both Y and X Q_nuis <- project_confounds(Nuisance) Y_clean <- Q_nuis %*% Y X_clean <- Q_nuis %*% X  # This can be faster than including Nuisance in each LSS iteration beta_preprocessed <- lss(Y_clean, X_clean, Z = Z, method = \"r_optimized\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"troubleshooting-common-challenges","dir":"Articles","previous_headings":"","what":"Troubleshooting Common Challenges","title":"Getting Started with fmrilss","text":"Even robust implementations, certain data characteristics can cause issues. Understanding diagnose address problems help get analyses. design matrices become singular near-singular due high collinearity regressors, standard least squares solutions become unstable. can detect examining correlation matrix design: Memory limitations can also pose challenges large datasets. starting analysis, ’s wise estimate memory requirements adjust approach accordingly: encounter unexpectedly slow performance, profiling can help identify bottlenecks:","code":"# Check for collinearity cor_matrix <- cor(X) high_cor <- which(abs(cor_matrix) > 0.9 & cor_matrix != 1, arr.ind = TRUE)  if (nrow(high_cor) > 0) {   warning(\"High correlation between regressors detected\")   # Consider using ridge regression via OASIS   beta_ridge <- lss(Y, X, method = \"oasis\",                     oasis = list(ridge_mode = \"absolute\", ridge_x = 0.1)) } # Monitor memory usage mem_required <- object.size(Y) * n_trials * 2  # Rough estimate # mem_available <- memory.limit()  # Windows only  # if (mem_required > mem_available * 0.8) { #   warning(\"May run out of memory. Consider chunking or using OASIS.\") # } # Profile code to find bottlenecks Rprof(\"lss_profile.out\") beta_slow <- lss(Y, X, method = \"naive\") Rprof(NULL) summaryRprof(\"lss_profile.out\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"where-to-go-from-here","dir":"Articles","previous_headings":"","what":"Where to Go From Here","title":"Getting Started with fmrilss","text":"vignette introduced core concepts capabilities fmrilss package. ’ve learned LSS addresses collinearity problem rapid event-related designs, choose different computational backends, strategies handling complex experimental designs large datasets. deepen understanding explore advanced features, recommend examining voxel-wise HRF vignette, demonstrates model spatial variation hemodynamic responses across brain. OASIS method vignette provides comprehensive coverage powerful extension, including HRF estimation ridge regression techniques. interested hierarchical analyses, mixed models vignette shows combine LSS mixed-effects modeling frameworks. fmrilss package represents comprehensive toolkit trial-wise beta estimation, providing options range simple, interpretable implementations highly optimized solutions large-scale analyses. Whether ’re conducting exploratory analyses laptop processing massive datasets computing cluster, package offers flexibility performance need modern fMRI analysis.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/getting_started.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Getting Started with fmrilss","text":"Mumford, J. ., Turner, B. O., Ashby, F. G., & Poldrack, R. . (2012). Deconvolving BOLD activation event-related designs multivoxel pattern classification analyses. NeuroImage, 59(3), 2636-2643.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"the-computational-challenge-of-modern-fmri","dir":"Articles","previous_headings":"","what":"The Computational Challenge of Modern fMRI","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Modern fMRI datasets sub-millimeter resolution thousands trials require millions model fits using standard LSS approaches. datasets 100,000 voxels 500 trials, traditional LSS requires 50 million separate GLM fits, involving matrix inversion parameter estimation. OASIS (Optimized Analytic Single-pass Inverse Solution) addresses computational challenge mathematical reformulation. Instead iterating trials sequentially, OASIS exploits shared structure across LSS models compute trial estimates simultaneously. method reduces computational complexity O(NT³) O(T³ + NTV) N = number trials, T = timepoints, V = voxels. OASIS also provides: automatic HRF estimation multi-basis functions, ridge regularization numerical stability, efficient handling complex experimental designs, integration prewhitening autocorrelation correction. Prerequisites: familiarity LSS concepts, HRF models basis functions, ridge regression principles, fmrihrf package.","code":"library(fmrihrf) #>  #> Attaching package: 'fmrihrf' #> The following object is masked from 'package:stats': #>  #>     deriv library(fmrilss) set.seed(42)  # Helper function to create design matrix using fmrihrf API # (design_matrix is not exported from fmrihrf, so we create a wrapper) design_matrix <- function(sframe, conditions, tr_per_trial = FALSE) {   # Helper to safely extract condition fields without partial matching   cond_field <- function(cond, name, default = NULL) {     if (!is.null(cond[[name]])) cond[[name]] else default   }    if (tr_per_trial) {     # Create trial-wise design (one column per trial)     X_list <- list()     for (cond in conditions) {       onsets <- cond_field(cond, \"onsets\")       n_trials <- length(onsets)       # Each trial gets its own regressor       X_trial <- fmrihrf::regressor_design(         onsets = onsets,         fac = factor(seq_len(n_trials)),  # Each trial is its own level         block = rep(1L, n_trials),        # Assume single block for simplicity         sframe = sframe,         hrf = cond_field(cond, \"hrf\", fmrihrf::HRF_SPMG1),         duration = cond_field(cond, \"duration\", 0),         span = cond_field(cond, \"span\", 30),         precision = cond_field(cond, \"precision\", 0.1),         method = cond_field(cond, \"method\", \"conv\"),         summate = FALSE  # Don't sum across trials       )       X_list[[length(X_list) + 1]] <- X_trial     }     X <- do.call(cbind, X_list)   } else {     # Create aggregate design (one column per condition)     X_list <- list()     for (cond in conditions) {       onsets <- cond_field(cond, \"onsets\")       n_trials <- length(onsets)       # All trials in same condition get summed       X_cond <- fmrihrf::regressor_design(         onsets = onsets,         fac = factor(rep(1L, n_trials)),  # All trials same level         block = rep(1L, n_trials),         sframe = sframe,         hrf = cond_field(cond, \"hrf\", fmrihrf::HRF_SPMG1),         duration = cond_field(cond, \"duration\", 0),         span = cond_field(cond, \"span\", 30),         precision = cond_field(cond, \"precision\", 0.1),         method = cond_field(cond, \"method\", \"conv\"),         summate = TRUE  # Sum across trials in condition       )       X_list[[length(X_list) + 1]] <- X_cond     }     X <- do.call(cbind, X_list)   }    list(X = as.matrix(X)) }"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"understanding-the-oasis-innovation","dir":"Articles","previous_headings":"","what":"Understanding the OASIS Innovation","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"OASIS exploits mathematical structure LSS: N separate GLMs share computational components can factored reused across trials. Note factoring already exploited fmrilss’s optimized backends (e.g., fused single‑pass solver residualizes reuses totals cross‑products across trials). OASIS uses core solve wraps richer, HRF-aware workflow: automatic design construction event specs, built-ridge scaling, AR(1) whitening, SE/diagnostic reporting, native support multi-basis FIR HRFs. Beyond computational efficiency, OASIS adds features generic LSS path expose: built‑ridge regularization (absolute fractional) two‑regressor Gram per trial, optional AR(1) whitening, analytical standard errors diagnostics, blocked multi‑basis solver treats K>1 HRF bases 2K×2K closed‑form systems per trial. Finally, OASIS integrates directly fmrihrf: builds trial‑wise designs event specs (including multi‑condition aggregates), auto‑detects basis dimension K, supports FIR/non‑parametric bases, can run fast HRF grid selection fitting. removes manual design construction preserving exact LSS equivalence.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"what-oasis-adds-over-optimized-lss","dir":"Articles","previous_headings":"Understanding the OASIS Innovation","what":"What OASIS Adds Over Optimized LSS","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"HRF‑aware design: Builds X events via fmrihrf (single multi‑basis), optional HRF grid search. Stabilization: Ridge regularization per‑trial Gram (absolute fractional scaling design energy). Inference: Optional standard errors design diagnostics without extra passes. Whitening: Optional AR(1) prewhitening applied consistently data design. Multi‑basis efficiency: Blocked products 2K×2K closed‑form solves K>1 bases.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"starting-with-oasis-a-simple-example","dir":"Articles","previous_headings":"","what":"Starting with OASIS: A Simple Example","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Let’s begin straightforward example demonstrates OASIS action. ’ll create synthetic data known ground truth, see OASIS recovers signal: Notice OASIS takes design specification rather pre-built design matrix. allows construct optimal internal representation efficient computation. results identical ’d get standard LSS, computed much efficiently.","code":"# Create synthetic data n_time <- 300 n_voxels <- 100 TR <- 1.0  # Generate event onsets (rapid design) onsets <- seq(10, 280, by = 15)  # Events every 15 seconds n_trials <- length(onsets)  # Create sampling frame sframe <- fmrihrf::sampling_frame(blocklens = n_time, TR = TR)  # Generate synthetic fMRI data Y <- matrix(rnorm(n_time * n_voxels), n_time, n_voxels)  # Add signal to data true_betas <- matrix(rnorm(n_trials * n_voxels, mean = 1, sd = 0.5),                      n_trials, n_voxels)  # Create signal using canonical HRF dm <- design_matrix(   sframe = sframe,   conditions = list(     list(onsets = onsets, hrf = fmrihrf::HRF_SPMG1, name = \"task\")   ),   tr_per_trial = TRUE )  Y <- Y + dm$X %*% true_betas  # Run OASIS beta_oasis <- lss(   Y = Y,   X = NULL,  # OASIS builds design internally   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(         onsets = onsets,         hrf = fmrihrf::HRF_SPMG1,         span = 30  # HRF duration       )     )   ) )  cat(\"OASIS results:\\n\") #> OASIS results: cat(\"  Beta dimensions:\", dim(beta_oasis), \"\\n\") #>   Beta dimensions: 19 100 cat(\"  Mean beta:\", round(mean(beta_oasis), 3), \"\\n\") #>   Mean beta: 1.01 cat(\"  Beta SD:\", round(sd(beta_oasis), 3), \"\\n\") #>   Beta SD: 0.587"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"the-power-of-ridge-regularization","dir":"Articles","previous_headings":"","what":"The Power of Ridge Regularization","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"One OASIS’s valuable features built-ridge regularization. rapid event-related designs, close temporal spacing trials can lead highly correlated regressors unstable estimates. Ridge regression adds small penalty term “shrinks” estimates toward zero, trading small amount bias large reduction variance. OASIS offers two approaches ridge regularization, suited different scenarios. Let’s explore :","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"absolute-ridge-regularization","dir":"Articles","previous_headings":"The Power of Ridge Regularization","what":"Absolute Ridge Regularization","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"absolute ridge, specify fixed penalty values added diagonal normal equations. approach gives direct control regularization strength:","code":"# Absolute ridge: fixed penalty values beta_ridge_abs <- lss(   Y = Y,   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(onsets = onsets, hrf = HRF_SPMG1, span = 30)     ),     ridge_mode = \"absolute\",     ridge_x = 0.1,  # Penalty on trial regressor     ridge_b = 0.1   # Penalty on aggregator regressor   ) )  # Compare with unregularized cat(\"Comparison with unregularized:\\n\") #> Comparison with unregularized: cat(\"  Correlation:\", round(cor(as.vector(beta_oasis),                                as.vector(beta_ridge_abs)), 3), \"\\n\") #>   Correlation: 1 cat(\"  Mean absolute difference:\",     round(mean(abs(beta_oasis - beta_ridge_abs)), 4), \"\\n\") #>   Mean absolute difference: 0.0092"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"fractional-ridge-regularization","dir":"Articles","previous_headings":"The Power of Ridge Regularization","what":"Fractional Ridge Regularization","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Fractional ridge scales penalty relative “energy” (sum squares) design matrix. adaptive approach automatically adjusts scale data: variance reduction demonstrates ridge regression’s stabilizing effect. practice, translates reliable estimates, especially noisy data complex designs.","code":"# Fractional ridge: penalty as fraction of design energy beta_ridge_frac <- lss(   Y = Y,   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(onsets = onsets, hrf = HRF_SPMG1, span = 30)     ),     ridge_mode = \"fractional\",     ridge_x = 0.05,  # 5% of mean design energy     ridge_b = 0.05   # 5% of mean aggregator energy   ) )  # Ridge typically reduces variance in estimates var_unreg <- apply(beta_oasis, 2, var) var_ridge <- apply(beta_ridge_frac, 2, var)  cat(\"\\nVariance reduction with ridge:\\n\") #>  #> Variance reduction with ridge: cat(\"  Mean variance (unregularized):\", round(mean(var_unreg), 4), \"\\n\") #>   Mean variance (unregularized): 0.3378 cat(\"  Mean variance (ridge):\", round(mean(var_ridge), 4), \"\\n\") #>   Mean variance (ridge): 0.3065 cat(\"  Reduction:\", round((1 - mean(var_ridge)/mean(var_unreg)) * 100, 1), \"%\\n\") #>   Reduction: 9.3 %"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"working-with-multi-basis-hrfs","dir":"Articles","previous_headings":"","what":"Working with Multi-Basis HRFs","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Real hemodynamic responses rarely match canonical HRF perfectly. might peak earlier later, wider narrower, different undershoot characteristics. Multi-basis HRF models capture variability representing response weighted combination basis functions. OASIS handles multi-basis HRFs naturally, returning separate estimates basis component:  multi-basis approach reveals hemodynamic response varies across trials. Large temporal derivative values suggest timing variability, dispersion derivative values indicate width changes. information can valuable understanding physiological variations task-related modulations hemodynamic response.","code":"# Use SPMG3: canonical + temporal derivative + dispersion derivative beta_spmg3 <- lss(   Y = Y,   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(         onsets = onsets,         hrf = HRF_SPMG3,  # 3 basis functions         span = 30       )     )   ) )  # SPMG3 returns K×N rows where K=number of basis functions, N=number of trials # The results are organized in blocks: [trial1_basis1, trial1_basis2, trial1_basis3, #                                       trial2_basis1, trial2_basis2, trial2_basis3, ...] cat(\"Multi-basis results:\\n\") #> Multi-basis results: cat(\"  Beta dimensions:\", dim(beta_spmg3), \"\\n\") #>   Beta dimensions: 57 100 cat(\"  Basis functions (K):\", 3, \"\\n\") #>   Basis functions (K): 3 cat(\"  Trials (N):\", n_trials, \"\\n\") #>   Trials (N): 19 cat(\"  Total rows (K×N):\", nrow(beta_spmg3), \"\\n\") #>   Total rows (K×N): 57  # Extract components using the K-stride pattern # For K=3 basis functions, every 3rd row starting from position k gives basis k K <- 3  # Number of basis functions in SPMG3 canonical_betas <- beta_spmg3[seq(1, nrow(beta_spmg3), by = K), ]    # Basis 1: Canonical temporal_betas <- beta_spmg3[seq(2, nrow(beta_spmg3), by = K), ]     # Basis 2: Temporal derivative dispersion_betas <- beta_spmg3[seq(3, nrow(beta_spmg3), by = K), ]   # Basis 3: Dispersion derivative  # Verify dimensions: each should be n_trials × n_voxels cat(\"\\nExtracted component dimensions:\\n\") #>  #> Extracted component dimensions: cat(\"  Each basis matrix:\", dim(canonical_betas), \"\\n\") #>   Each basis matrix: 19 100  # Analyze contributions cat(\"\\nBasis function contributions:\\n\") #>  #> Basis function contributions: cat(\"  Canonical mean |beta|:\", round(mean(abs(canonical_betas)), 3), \"\\n\") #>   Canonical mean |beta|: 1.046 cat(\"  Temporal deriv mean |beta|:\", round(mean(abs(temporal_betas)), 3), \"\\n\") #>   Temporal deriv mean |beta|: 0.686 cat(\"  Dispersion deriv mean |beta|:\", round(mean(abs(dispersion_betas)), 3), \"\\n\") #>   Dispersion deriv mean |beta|: 1.235  # Visualize first voxel par(mfrow = c(1, 3)) plot(canonical_betas[, 1], type = \"b\", main = \"Canonical\",      ylab = \"Beta\", xlab = \"Trial\") plot(temporal_betas[, 1], type = \"b\", main = \"Temporal Derivative\",      ylab = \"Beta\", xlab = \"Trial\") plot(dispersion_betas[, 1], type = \"b\", main = \"Dispersion Derivative\",      ylab = \"Beta\", xlab = \"Trial\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"non-parametric-hrf-modeling-with-fir","dir":"Articles","previous_headings":"","what":"Non-Parametric HRF Modeling with FIR","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Sometimes want make assumptions HRF shape . Finite Impulse Response (FIR) basis provides completely non-parametric approach, estimating response time point independently:  FIR approach reveals actual shape hemodynamic response without parametric constraints. trial now contributes one coefficient per time bin, individual voxel-level estimates can look jagged—variance simply much higher single-parameter canonical fit. Averaging across trials voxels (adding modest ridge penalty) recovers smooth, HRF-like curve still allowing deviations canonical shape. practice typically pool information across voxels/regions apply additional smoothing/regularization working FIR bases.","code":"# Create FIR basis with 15 time bins (2s width over a 30s window) fir_hrf <- hrf_fir_generator(nbasis = 15, span = 30) fir_params <- attr(fir_hrf, \"params\") bin_width <- as.numeric(fir_params[[\"bin_width\"]]) n_bins <- attr(fir_hrf, \"nbasis\")  beta_fir <- lss(   Y = Y,   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(         onsets = onsets,         hrf = fir_hrf,         span = 30       )     ),     ridge_mode = \"fractional\",     ridge_x = 0.2,  # Moderate ridge improves stability for high-dimensional FIR fits     ridge_b = 0.2   ) )  cat(\"FIR basis results:\\n\") #> FIR basis results: cat(\"  Beta dimensions:\", dim(beta_fir), \"\\n\") #>   Beta dimensions: 285 100 cat(\"  Time bins per trial:\", nrow(beta_fir) / n_trials, \"\\n\") #>   Time bins per trial: 15  # Organise coefficients as (time bin × trial × voxel) fir_array <- array(beta_fir, dim = c(n_bins, n_trials, ncol(beta_fir)))  # Average across trials and voxels to recover a smooth HRF estimate fir_mean <- apply(fir_array, 1, mean) fir_se <- apply(fir_array, 1, sd) / sqrt(n_trials * ncol(beta_fir)) time_points <- seq(0, (n_bins - 1) * bin_width, by = bin_width)  # Plot mean HRF with ±1 SE ribbon upper <- fir_mean + fir_se lower <- fir_mean - fir_se  plot(time_points, fir_mean, type = \"l\",      ylim = range(c(lower, upper)),      main = \"FIR-derived HRF (mean across trials/voxels)\",      xlab = \"Time (seconds)\", ylab = \"Response\",      col = \"navy\", lwd = 2) polygon(c(time_points, rev(time_points)), c(upper, rev(lower)),         col = grDevices::adjustcolor(\"navy\", alpha.f = 0.2), border = NA) lines(time_points, fir_mean, col = \"navy\", lwd = 2)  # Add canonical HRF sampled on the same grid for reference canonical <- evaluate(HRF_SPMG1, time_points) scale_factor <- max(fir_mean) / max(canonical) lines(time_points, canonical * scale_factor, col = \"firebrick\", lty = 2, lwd = 2) legend(\"topright\",        c(\"FIR mean\", \"±1 SE\", \"Canonical (scaled)\"),        col = c(\"navy\", NA, \"firebrick\"),        lty = c(1, NA, 2),        lwd = c(2, NA, 2),        pch = c(NA, 15, NA),        pt.cex = c(NA, 2, NA),        pt.bg = c(NA, grDevices::adjustcolor(\"navy\", alpha.f = 0.2), NA),        bty = \"n\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"optimizing-hrf-models-through-grid-search","dir":"Articles","previous_headings":"","what":"Optimizing HRF Models Through Grid Search","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"’re unsure HRF model best fits data, OASIS can efficiently evaluate multiple candidates. exploratory approach helps identify optimal HRF parameters specific dataset brain regions: Grid search reveals HRF parameters best explain data. data-driven approach can uncover unexpected characteristics hemodynamic response specific experimental context.","code":"# Create a grid of HRF models with varying parameters hrf_grid <- create_lwu_grid(   tau_range = c(4, 8),      # Peak time   sigma_range = c(2, 3.5),  # Width   rho_range = c(0.2, 0.5),  # Undershoot   n_tau = 3,   n_sigma = 2,   n_rho = 2 )  cat(\"Testing\", length(hrf_grid$hrfs), \"different HRF models\\n\\n\") #> Testing 12 different HRF models  # Test each HRF and select best based on fit best_fit <- -Inf best_idx <- 1  for (i in seq_along(hrf_grid$hrfs)) {   # Create HRF object   tau_val <- hrf_grid$parameters$tau[i]   sigma_val <- hrf_grid$parameters$sigma[i]   rho_val <- hrf_grid$parameters$rho[i]    hrf_obj <- structure(     function(t) {       hrf_lwu(t, tau = tau_val, sigma = sigma_val, rho = rho_val, normalize = \"height\")     },     class = c(\"hrf\", \"function\"),     span = 30   )    # Fit OASIS with this HRF   beta_test <- lss(     Y = Y[, 1:10],  # Test on subset for speed     X = NULL,     method = \"oasis\",     oasis = list(       design_spec = list(         sframe = sframe,         cond = list(onsets = onsets, hrf = hrf_obj, span = 30)       ),       ridge_mode = \"fractional\",       ridge_x = 0.01,       ridge_b = 0.01     )   )    # Calculate fit (simplified - residual sum of squares)   X_test <- design_matrix(     sframe = sframe,     conditions = list(list(onsets = onsets, hrf = hrf_obj)),     tr_per_trial = TRUE   )$X    fitted <- X_test %*% beta_test   rss <- sum((Y[, 1:10] - fitted)^2)    if (-rss > best_fit) {     best_fit <- -rss     best_idx <- i   } }  cat(\"Best HRF parameters:\\n\") #> Best HRF parameters: cat(\"  tau:\", hrf_grid$parameters$tau[best_idx], \"\\n\") #>   tau: 4 cat(\"  sigma:\", hrf_grid$parameters$sigma[best_idx], \"\\n\") #>   sigma: 2 cat(\"  rho:\", hrf_grid$parameters$rho[best_idx], \"\\n\") #>   rho: 0.2"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"handling-complex-experimental-designs","dir":"Articles","previous_headings":"","what":"Handling Complex Experimental Designs","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Real experiments often involve multiple conditions, trials interest others serving nuisance events. OASIS handles scenarios structured condition specification: approach ensures variance conditions properly accounted without conflating trials interest.","code":"# Create design with two conditions onsets_cond1 <- seq(10, 280, by = 30) onsets_cond2 <- seq(25, 280, by = 30)  # Condition 1 as target, Condition 2 as nuisance beta_multi <- lss(   Y = Y,   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(         onsets = onsets_cond1,         hrf = HRF_SPMG1,         span = 30       ),       others = list(         list(onsets = onsets_cond2)  # Other conditions as nuisance       )     )   ) )  cat(\"Multi-condition OASIS:\\n\") #> Multi-condition OASIS: cat(\"  Analyzing condition 1 trials:\", length(onsets_cond1), \"\\n\") #>   Analyzing condition 1 trials: 10 cat(\"  Condition 2 included as nuisance\\n\") #>   Condition 2 included as nuisance cat(\"  Beta dimensions:\", dim(beta_multi), \"\\n\") #>   Beta dimensions: 10 100"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"beyond-point-estimates-standard-errors-and-diagnostics","dir":"Articles","previous_headings":"","what":"Beyond Point Estimates: Standard Errors and Diagnostics","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"beta estimates valuable, understanding uncertainty crucial proper inference. OASIS can provide standard errors diagnostic information:  Standard errors reveal estimates reliable. Trials higher standard errors might overlapping responses occurring periods higher noise.","code":"# Request standard errors result_with_se <- lss(   Y = Y[, 1:10],  # Subset for demonstration   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(onsets = onsets[1:10], hrf = HRF_SPMG1, span = 30)     ),     return_se = TRUE,     return_diag = TRUE   ) )  cat(\"Results with diagnostics:\\n\") #> Results with diagnostics: cat(\"  Beta dimensions:\", dim(result_with_se$beta), \"\\n\") #>   Beta dimensions: 10 10 cat(\"  SE dimensions:\", dim(result_with_se$se), \"\\n\") #>   SE dimensions: 10 10 cat(\"  Mean SE:\", round(mean(result_with_se$se), 4), \"\\n\") #>   Mean SE: 0.3537  # Calculate t-statistics t_stats <- result_with_se$beta / result_with_se$se cat(\"  Mean |t-statistic|:\", round(mean(abs(t_stats)), 2), \"\\n\") #>   Mean |t-statistic|: 2.43  # Visualize SE across trials plot(rowMeans(result_with_se$se), type = \"b\",      main = \"Standard Error Across Trials\",      xlab = \"Trial\", ylab = \"Mean SE\",      col = \"darkblue\", pch = 19)"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"performance-in-practice","dir":"Articles","previous_headings":"","what":"Performance in Practice","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"understand OASIS’s efficiency, let’s conduct systematic benchmarks comparing traditional LSS implementations across different dataset sizes:  capability allows test hypotheses hemodynamic response characteristics adapt models software packages.","code":"# Benchmark across different dataset sizes sizes <- list(   small  = list(timepoints = 300, voxels = 500),   medium = list(timepoints = 400, voxels = 2000),   large  = list(timepoints = 600, voxels = 8000),   xlarge = list(timepoints = 800, voxels = 16000) )  benchmark_results <- data.frame()  for (size_name in names(sizes)) {   n_time <- sizes[[size_name]][['timepoints']]   n_vox  <- sizes[[size_name]][['voxels']]    # Create test data   Y_bench <- matrix(rnorm(n_time * n_vox), n_time, n_vox)    # Create sampling frame and onsets for this size   sframe_bench <- fmrihrf::sampling_frame(blocklens = n_time, TR = TR)   n_trials <- min(60, floor(n_time / 10))   onsets_bench <- seq(10, n_time - 20, length.out = n_trials)    # Standard LSS with pre-built design (shared across methods)   dm_bench <- design_matrix(     sframe = sframe_bench,     conditions = list(list(onsets = onsets_bench, hrf = fmrihrf::HRF_SPMG1)),     tr_per_trial = TRUE   )[['X']]    # Time standard LSS (R optimized)   time_r_opt <- system.time({     beta_r <- lss(Y_bench, dm_bench, method = \"r_optimized\")   })[3]    # Time standard LSS (C++ optimized)   time_cpp <- system.time({     beta_cpp <- lss(Y_bench, dm_bench, method = \"cpp_optimized\")   })[3]    # Time OASIS using the pre-built design (fair comparison)   time_oasis <- system.time({     beta_oasis <- lss(Y = Y_bench, X = dm_bench, method = \"oasis\")   })[3]    # Time OASIS when it also has to build the design internally   time_oasis_build <- system.time({     beta_oasis_build <- lss(       Y = Y_bench,       X = NULL,       method = \"oasis\",       oasis = list(         design_spec = list(           sframe = sframe_bench,           cond = list(             onsets = onsets_bench,             hrf = fmrihrf::HRF_SPMG1,             span = 30           )         )       )     )   })[3]    # Store results   benchmark_results <- rbind(benchmark_results, data.frame(     Size = size_name,     Timepoints = n_time,     Voxels = n_vox,     Trials = n_trials,     R_Optimized = time_r_opt,     CPP_Optimized = time_cpp,     OASIS = time_oasis,     OASIS_with_design = time_oasis_build,     Speedup_vs_R = time_r_opt / time_oasis,     Speedup_vs_CPP = time_cpp / time_oasis,     Design_Build_Overhead = time_oasis_build - time_oasis   )) }  # Display rounded results for readability numeric_cols <- setdiff(names(benchmark_results), \"Size\") benchmark_display <- benchmark_results benchmark_display[numeric_cols] <- lapply(benchmark_display[numeric_cols], function(x) round(x, 3)) print(benchmark_display) #>            Size Timepoints Voxels Trials R_Optimized CPP_Optimized OASIS #> elapsed   small        300    500     30       0.005         0.013 0.003 #> elapsed1 medium        400   2000     40       0.014         0.075 0.008 #> elapsed2  large        600   8000     60       0.075         0.357 0.049 #> elapsed3 xlarge        800  16000     60       0.162         0.285 0.117 #>          OASIS_with_design Speedup_vs_R Speedup_vs_CPP Design_Build_Overhead #> elapsed              0.016        1.667          4.333                 0.013 #> elapsed1             0.031        1.750          9.375                 0.023 #> elapsed2             0.082        1.531          7.286                 0.033 #> elapsed3             0.159        1.385          2.436                 0.042  # Visualize scaling par(mfrow = c(1, 2))  # Time vs dataset size ylim_max <- max(benchmark_results[, c(\"R_Optimized\", \"CPP_Optimized\", \"OASIS_with_design\")]) plot(benchmark_results$Voxels, benchmark_results$R_Optimized,      type = \"b\", col = \"blue\", pch = 19,      xlab = \"Number of Voxels\", ylab = \"Time (seconds)\",      main = \"Computation Time Scaling\",      ylim = c(0, ylim_max)) lines(benchmark_results$Voxels, benchmark_results$CPP_Optimized,       type = \"b\", col = \"darkgreen\", pch = 15) lines(benchmark_results$Voxels, benchmark_results$OASIS,       type = \"b\", col = \"red\", pch = 17) lines(benchmark_results$Voxels, benchmark_results$OASIS_with_design,       type = \"b\", col = \"red\", lty = 2, pch = 1) legend(\"topleft\",        c(\"R Optimized\", \"C++ Optimized\", \"OASIS (pre-built X)\", \"OASIS (build design)\"),        col = c(\"blue\", \"darkgreen\", \"red\", \"red\"),        pch = c(19, 15, 17, 1),        lty = c(1, 1, 1, 2))  # Speedup factor barplot(benchmark_results$Speedup_vs_R,         names.arg = benchmark_results$Size,         main = \"OASIS Speedup vs R Optimized\",         ylab = \"Speedup Factor\",         col = \"steelblue\") abline(h = 1, lty = 2, col = \"gray\") These benchmarks show that all three optimized backends sit within a few percent of one another across the regimes we tested. The R and fused C++ paths are already very efficient, and OASIS closely tracks them even as we scale to tens of thousands of voxels and dozens of trials. The `OASIS (build design)` curve highlights another key point: if you let OASIS construct the design inside the call you pay the additional cost of HRF convolution, so for apples-to-apples comparisons you should pre-build and reuse `X` just as you would for the other methods.  The exact ordering will vary with hardware, trial spacing, and nuisance structure—on some reruns OASIS edges ahead, on others the R or C++ backend wins by a similar margin. The takeaway is that OASIS keeps pace with the existing optimized solvers while additionally providing HRF-aware design construction, ridge regularization, whitening, and diagnostics.  ## Creating Custom HRF Functions  OASIS's flexibility extends to custom HRF functions, allowing you to implement novel hemodynamic models:   ``` r # Create custom double-gamma HRF custom_hrf <- function(t, a1 = 6, a2 = 16, b1 = 1, b2 = 1, c = 1/6) {   # Double gamma function   dgamma(t, a1, b1) - c * dgamma(t, a2, b2) }  # Wrap as HRF object custom_hrf_obj <- structure(   custom_hrf,   class = c(\"hrf\", \"function\"),   span = 30 )  # Use with OASIS beta_custom <- lss(   Y = Y[, 1:10],   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(         onsets = onsets[1:10],         hrf = custom_hrf_obj,         span = 30       )     )   ) )  cat(\"Custom HRF results:\\n\") #> Custom HRF results: cat(\"  Beta dimensions:\", dim(beta_custom), \"\\n\") #>   Beta dimensions: 10 10 cat(\"  Mean beta:\", round(mean(beta_custom), 3), \"\\n\") #>   Mean beta: 7.921"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"practical-guidance-for-ridge-parameter-selection","dir":"Articles","previous_headings":"","what":"Practical Guidance for Ridge Parameter Selection","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Choosing appropriate ridge parameters crucial optimal performance. little regularization leaves estimates unstable; much biases toward zero. ’s systematic approach selection: condition number (κ) indicates numerical stability—lower values suggest stable estimates. tradeoff bias (reduced mean beta) variance (reduced SD) guides choice.","code":"# Test different ridge values ridge_values <- c(0, 0.001, 0.01, 0.05, 0.1) ridge_results <- list()  for (ridge in ridge_values) {   beta_r <- lss(     Y = Y[, 1:10],     X = NULL,     method = \"oasis\",     oasis = list(       design_spec = list(         sframe = sframe,         cond = list(onsets = onsets, hrf = HRF_SPMG1, span = 30)       ),       ridge_mode = \"fractional\",       ridge_x = ridge,       ridge_b = ridge     )   )    ridge_results[[as.character(ridge)]] <- list(     mean_beta = mean(abs(beta_r)),     sd_beta = sd(beta_r),     condition_number = kappa(cor(beta_r))   ) }  # Display results cat(\"Ridge parameter selection:\\n\") #> Ridge parameter selection: for (r in names(ridge_results)) {   cat(sprintf(\"  Ridge = %s: mean|β| = %.3f, SD = %.3f, κ = %.1f\\n\",               r, ridge_results[[r]]$mean_beta,               ridge_results[[r]]$sd_beta,               ridge_results[[r]]$condition_number)) } #>   Ridge = 0: mean|β| = 1.087, SD = 0.648, κ = 27.3 #>   Ridge = 0.001: mean|β| = 1.086, SD = 0.648, κ = 27.3 #>   Ridge = 0.01: mean|β| = 1.072, SD = 0.642, κ = 27.3 #>   Ridge = 0.05: mean|β| = 1.013, SD = 0.616, κ = 27.3 #>   Ridge = 0.1: mean|β| = 0.947, SD = 0.587, κ = 27.2"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"memory-usage-comparison","dir":"Articles","previous_headings":"","what":"Memory Usage Comparison","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"Understanding memory trade-offs OASIS standard LSS important choosing right method computational resources:  shown, OASIS requires upfront memory due precomputed matrices, investment enables computational efficiency. memory overhead noticeable multi-basis HRFs large numbers trials. memory-constrained systems, consider using blocked processing standard LSS large datasets.","code":"# Compare memory usage across methods memory_comparison <- function(n_time, n_vox, n_trials) {    # Calculate memory requirements (in MB)   double_size <- 8  # bytes per double    # Standard LSS memory (per iteration)   # Stores: current X_trial (n_time × 2), beta result (n_trials × n_vox)   lss_per_iter <- (n_time * 2 + n_vox) * double_size / 1024^2   lss_total <- lss_per_iter  # Only peak memory matters    # OASIS memory (upfront)   # Stores: X (n_time × n_trials), precomputed terms, results   oasis_X <- n_time * n_trials * double_size / 1024^2   oasis_precomp <- (n_trials^2 + n_trials * 3) * double_size / 1024^2  # Gram matrices   oasis_results <- n_trials * n_vox * double_size / 1024^2   oasis_total <- oasis_X + oasis_precomp + oasis_results    # For multi-basis (K=3), multiply by K   oasis_multibasis <- oasis_total * 3    return(data.frame(     Timepoints = n_time,     Voxels = n_vox,     Trials = n_trials,     LSS_MB = round(lss_total, 2),     OASIS_MB = round(oasis_total, 2),     OASIS_Multi_MB = round(oasis_multibasis, 2),     Ratio = round(oasis_total / lss_total, 1),     Ratio_Multi = round(oasis_multibasis / lss_total, 1)   )) }  # Test different dataset sizes mem_results <- rbind(   memory_comparison(200, 100, 15),    # Small   memory_comparison(300, 1000, 30),   # Medium   memory_comparison(400, 10000, 50),  # Large   memory_comparison(500, 50000, 100)  # Very large )  print(mem_results) #>   Timepoints Voxels Trials LSS_MB OASIS_MB OASIS_Multi_MB Ratio Ratio_Multi #> 1        200    100     15   0.00     0.04           0.11   9.5        28.6 #> 2        300   1000     30   0.01     0.31           0.92  25.0        75.0 #> 3        400  10000     50   0.08     3.99          11.96  48.4       145.2 #> 4        500  50000    100   0.39    38.61         115.82  99.2       297.7  # Visualize memory scaling par(mfrow = c(1, 2))  # Memory usage comparison plot(mem_results$Voxels, mem_results$LSS_MB,      type = \"b\", col = \"blue\", pch = 19,      xlab = \"Number of Voxels\", ylab = \"Memory (MB)\",      main = \"Memory Usage Comparison\",      log = \"xy\") #> Warning in xy.coords(x, y, xlabel, ylabel, log): 1 y value <= 0 omitted from #> logarithmic plot lines(mem_results$Voxels, mem_results$OASIS_MB,       type = \"b\", col = \"red\", pch = 17) lines(mem_results$Voxels, mem_results$OASIS_Multi_MB,       type = \"b\", col = \"orange\", pch = 15) legend(\"topleft\", c(\"Standard LSS\", \"OASIS\", \"OASIS Multi-basis\"),        col = c(\"blue\", \"red\", \"orange\"), pch = c(19, 17, 15), lty = 1)  # Memory ratio barplot(t(as.matrix(mem_results[, c(\"Ratio\", \"Ratio_Multi\")])),         beside = TRUE,         names.arg = paste(mem_results$Voxels, \"vox\"),         main = \"Memory Usage Ratio (OASIS/LSS)\",         ylab = \"Memory Ratio\",         col = c(\"red\", \"orange\"),         legend.text = c(\"OASIS\", \"OASIS Multi-basis\")) abline(h = 1, lty = 2, col = \"gray\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"advanced-features-for-production-use","dir":"Articles","previous_headings":"","what":"Advanced Features for Production Use","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"deploying OASIS production analyses, several advanced features enhance efficiency robustness.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"memory-efficient-block-processing","dir":"Articles","previous_headings":"Advanced Features for Production Use","what":"Memory-Efficient Block Processing","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"datasets large fit memory, OASIS can process voxels blocks:","code":"# For very large datasets, use blocked processing block_size <- 1000 n_blocks <- ceiling(ncol(Y) / block_size)  # OASIS with blocked voxels oasis_config <- list(   design_spec = list(     sframe = sframe,     cond = list(onsets = onsets, hrf = HRF_SPMG1, span = 30)   ),   block_cols = block_size  # Process voxels in blocks )  beta_blocked <- lss(Y, X = NULL, method = \"oasis\", oasis = oasis_config)"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"temporal-autocorrelation-correction","dir":"Articles","previous_headings":"Advanced Features for Production Use","what":"Temporal Autocorrelation Correction","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"fMRI data exhibits temporal autocorrelation can bias standard errors. OASIS can apply AR(1) prewhitening: Prewhitening improves validity statistical inference, particularly standard errors hypothesis tests.","code":"# OASIS with AR(1) prewhitening using new fmriAR integration beta_whitened <- lss(   Y = Y[, 1:10],   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(onsets = onsets[1:10], hrf = HRF_SPMG1, span = 30)     )   ),   prewhiten = list(     method = \"ar\",     p = 1  # AR(1) model   ) )  cat(\"AR(1) whitening applied using fmriAR\\n\") #> AR(1) whitening applied using fmriAR cat(\"  Beta dimensions:\", dim(beta_whitened), \"\\n\") #>   Beta dimensions: 10 10  # Advanced: Auto-select AR order beta_auto_ar <- lss(   Y = Y[, 1:10],   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(onsets = onsets[1:10], hrf = HRF_SPMG1, span = 30)     )   ),   prewhiten = list(     method = \"ar\",     p = \"auto\",  # Automatically select optimal AR order     p_max = 4    # Maximum order to consider   ) )  cat(\"\\nAuto AR order selection applied\\n\") #>  #> Auto AR order selection applied cat(\"  Beta dimensions:\", dim(beta_auto_ar), \"\\n\") #>   Beta dimensions: 10 10"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"advanced-prewhitening-with-fmriar","dir":"Articles","previous_headings":"Advanced Features for Production Use","what":"Advanced Prewhitening with fmriAR","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"integration fmriAR provides sophisticated noise modeling capabilities beyond simple AR(1): advanced options provide better noise modeling complex experimental designs data structures.","code":"# Voxel-specific AR parameters beta_voxel_ar <- lss(   Y = Y,   X = X,   method = \"oasis\",   prewhiten = list(     method = \"ar\",     p = 1,     pooling = \"voxel\"  # Estimate separate AR(1) for each voxel   ) )  # Run-aware AR estimation for multi-run data runs <- rep(1:2, each = n_timepoints/2) beta_run_ar <- lss(   Y = Y,   X = X,   method = \"oasis\",   prewhiten = list(     method = \"ar\",     p = \"auto\",     pooling = \"run\",  # Separate parameters per run     runs = runs   ) )  # ARMA models for complex noise structure beta_arma <- lss(   Y = Y,   X = X,   method = \"oasis\",   prewhiten = list(     method = \"arma\",     p = 2,  # AR order     q = 1   # MA order   ) )  # Parcel-based pooling for spatial regularization parcels <- kmeans(t(Y), centers = 10)$cluster  # Example parcellation beta_parcel <- lss(   Y = Y,   X = X,   method = \"oasis\",   prewhiten = list(     method = \"ar\",     p = \"auto\",     pooling = \"parcel\",     parcels = parcels   ) )"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"when-oasis-shines-use-case-recommendations","dir":"Articles","previous_headings":"","what":"When OASIS Shines: Use Case Recommendations","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"extensive testing application, ’ve identified scenarios OASIS provides greatest benefits. Rapid event-related designs inter-stimulus intervals 10 seconds benefit enormously OASIS’s efficient handling overlapping responses. method’s speed advantage becomes crucial dealing experiments containing hundreds thousands trials. exploratory analyses optimal HRF unknown, OASIS’s ability quickly evaluate multiple HRF models enables data-driven model selection. computational efficiency makes feasible test dozens HRF variants across multiple brain regions. Large-scale analyses involving whole-brain data multiple subjects particularly benefit OASIS’s speed. might take days traditional LSS can often completed hours OASIS, enabling iterative thorough analyses. Designs prone collinearity—whether rapid presentation, long HRFs, correlated experimental factors—benefit OASIS’s integrated ridge regression. regularization happens naturally within estimation framework rather requiring post-hoc adjustments.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"limitations-and-considerations","dir":"Articles","previous_headings":"","what":"Limitations and Considerations","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"OASIS offers substantial advantages, ’s important understand limitations simpler approaches might suffice. method requires memory iterative LSS approaches since constructs larger intermediate matrices. extremely large datasets memory-constrained systems, traditional LSS careful memory management might necessary. OASIS’s design specification system, powerful, learning curve. simple analyses pre-constructed design matrices, standard LSS might straightforward implement. mathematical optimizations make OASIS fast also make less transparent. need understand modify estimation procedure, traditional LSS implementation offers clearer code paths.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"looking-ahead","dir":"Articles","previous_headings":"","what":"Looking Ahead","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"OASIS represents current state---art LSS implementation, combining theoretical rigor computational efficiency. fMRI data continues grow resolution complexity, methods like OASIS become just useful essential practical analysis. Future developments might include adaptive regularization automatically selects optimal ridge parameters, integration machine learning frameworks end--end optimization, extensions handle even complex experimental designs. fmrilss package continue evolve advances, maintaining OASIS cornerstone efficient trial-wise estimation. Whether ’re working standard datasets pushing boundaries fMRI acquisition, OASIS provides tools need rigorous, efficient analysis.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"summary-and-next-steps","dir":"Articles","previous_headings":"","what":"Summary and Next Steps","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"vignette taken full capabilities OASIS method, basic usage advanced features. ’ve seen OASIS achieves dramatic speedups mathematical reformulation, provides numerical stability integrated ridge regression, handles flexible HRF models seamlessly, scales large datasets efficiently. continue journey, explore getting started vignette foundational LSS concepts, voxel-wise HRF vignette spatial modeling hemodynamic responses, package examples directory real-world applications. theoretical details OASIS prepared publication, offering deeper insights mathematical innovations make method possible. OASIS transforms LSS computationally intensive procedure practical tool everyday fMRI analysis. combining speed, flexibility, robustness, enables analyses otherwise infeasible, opening new possibilities understanding brain function event-related fMRI.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_method.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further Reading","title":"The OASIS Method: Optimized Analytic Single-pass Inverse Solution","text":"See vignette(\"getting_started\") LSS basics See vignette(\"voxel-wise-hrf\") spatial HRF variation Review examples/oasis_example.R additional demonstrations Consult OASIS paper (preparation) theoretical details","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"motivation","dir":"Articles","previous_headings":"","what":"Motivation","title":"OASIS Theory: Algebra and Implementation Details","text":"Optimized Analytic Single-pass Inverse Solution (OASIS) extends Least Squares Separate (LSS) estimation algebraic reformulation enables single-pass computation trial estimates. document provides mathematical foundation implementation details.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"computational-intuition","dir":"Articles","previous_headings":"Motivation","what":"Computational Intuition","title":"OASIS Theory: Algebra and Implementation Details","text":"Standard LSS requires N separate GLM fits N trials, involving: 1. Matrix assembly: O(T²) operations 2. QR decomposition: O(T³) operations 3. Back-substitution: O(T²) operations Total complexity: O(NT³) N trials OASIS recognizes N models share substantial structure. factoring common computations, OASIS reduces complexity : 1. Single QR decomposition: O(T³) 2. Shared projections: O(NT²) 3. Per-trial solutions: O(N) Total complexity: O(T³ + NT²), significant reduction N large.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"visual-comparison-of-computational-scaling","dir":"Articles","previous_headings":"Motivation","what":"Visual Comparison of Computational Scaling","title":"OASIS Theory: Algebra and Implementation Details","text":"Computational complexity: Classical LSS vs OASIS","code":"# Demonstrate computational scaling N_trials <- c(10, 50, 100, 200, 500, 1000) T_points <- 200  # Fixed number of timepoints  # Simplified complexity models (arbitrary units) classical_ops <- N_trials * T_points^3 / 1e6  # O(NT³) oasis_ops <- (T_points^3 + N_trials * T_points^2) / 1e6  # O(T³ + NT²)  # Create comparison plot plot(N_trials, classical_ops, type='l', col='red', lwd=2,      xlab='Number of Trials', ylab='Computational Operations (millions)',      main='Computational Complexity: Classical LSS vs OASIS',      ylim=c(0, max(classical_ops))) lines(N_trials, oasis_ops, col='blue', lwd=2) legend('topleft', c('Classical LSS', 'OASIS'),        col=c('red', 'blue'), lwd=2, bty='n')  # Add shaded region showing computational savings polygon(c(N_trials, rev(N_trials)),         c(classical_ops, rev(oasis_ops)),         col=rgb(0.2, 0.8, 0.2, 0.3), border=NA) text(500, mean(c(classical_ops[4], oasis_ops[4])),      'Computational\\nSavings', col='darkgreen')"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"prerequisites","dir":"Articles","previous_headings":"Motivation","what":"Prerequisites","title":"OASIS Theory: Algebra and Implementation Details","text":"vignette assumes familiarity : - QR decomposition orthogonal projection matrices - Ridge regression regularization - Matrix calculus linear algebra - standard LSS formulation Code references point R/oasis_glue.R src/oasis_core.cpp implementations. Notation used throughout: Y∈ℝT×VY \\\\mathbb{R}^{T \\times V}: voxel data (TT time points, VV voxels) X=[x1,…,xN]∈ℝT×NX = [x_1, \\dots, x_N] \\\\mathbb{R}^{T \\times N}: trial regressors one condition Z∈ℝT×KzZ \\\\mathbb{R}^{T \\times K_z}: nuisance/experimental regressors shared across trials R=−QQTR = - QQ^T: orthogonal projector removing nuisance effects (QQ comes QR factorisation [Z,others][Z,\\text{others}]) Inner products denoted ⟨,b⟩=aTb\\langle , b \\rangle = ^T b first treat single-basis case (one regressor per trial) generalizing multi-basis HRFs.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"classical-lss-recap","dir":"Articles","previous_headings":"","what":"Classical LSS Recap","title":"OASIS Theory: Algebra and Implementation Details","text":"Classical LSS fits, trial jj, GLM design [xj,bj,Z][x_j, b_j, Z], bj=∑≠jxib_j = \\sum_{\\neq j} x_i. Solving model independently costs 𝒪(N)\\mathcal{O}(N) QR factorizations. Algebraically, trial-specific beta can expressed β̂j=⟨Rxj,RY⟩−⟨Rxj,Rbj⟩∥Rbj∥2⟨Rbj,RY⟩∥Rxj∥2−⟨Rxj,Rbj⟩2∥Rbj∥2. \\hat{\\beta}_j = \\frac{\\langle Rx_j, RY \\rangle - \\frac{\\langle Rx_j, Rb_j \\rangle}{\\|Rb_j\\|^2} \\langle Rb_j, RY \\rangle}{\\|Rx_j\\|^2 - \\frac{\\langle Rx_j, Rb_j \\rangle^2}{\\|Rb_j\\|^2}}. OASIS extracts reuses common computational components (projections, norms, cross-products) across trials, computing .","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"single-basis-oasis-algebra","dir":"Articles","previous_headings":"","what":"Single-Basis OASIS Algebra","title":"OASIS Theory: Algebra and Implementation Details","text":"residualising nuisance regressors define: aj=Rxja_j = Rx_j s=∑j=1Najs = \\sum_{j=1}^N a_j dj=∥aj∥2d_j = \\|a_j\\|^2 αj=⟨aj,s−aj⟩\\alpha_j = \\langle a_j, s - a_j \\rangle sj=∥s−aj∥2s_j = \\|s - a_j\\|^2 Let njv=⟨aj,RY⋅v⟩n_{jv} = \\langle a_j, RY_{\\cdot v} \\rangle mv=⟨s,RY⋅v⟩m_v = \\langle s, RY_{\\cdot v} \\rangle. pair (βj,γj)(\\beta_j, \\gamma_j) solving 2×2 system trial jj voxel vv obtained Gj[βjvγjv]=[njvmv−njv],Gj=[dj+λxαjαjsj+λb], G_j \\begin{bmatrix} \\beta_{jv} \\\\ \\gamma_{jv} \\end{bmatrix} = \\begin{bmatrix} n_{jv} \\\\ m_v - n_{jv} \\end{bmatrix}, \\quad G_j = \\begin{bmatrix} d_j + \\lambda_x & \\alpha_j \\\\ \\alpha_j & s_j + \\lambda_b \\end{bmatrix}, ridge penalties λx,λb≥0\\lambda_x, \\lambda_b \\ge 0. inverse GjG_j analytic, soβjv=(sj+λb)njv−αj(mv−njv)(dj+λx)(sj+λb)−αj2. \\beta_{jv} = \\frac{(s_j + \\lambda_b) n_{jv} - \\alpha_j (m_v - n_{jv})}{(d_j + \\lambda_x)(s_j + \\lambda_b) - \\alpha_j^2}. exactly oasis_betas_closed_form() implements (C++ file src/oasis_core.cpp). precomputation step oasis_precompute_design() produces aj,s,dj,αj,sja_j, s, d_j, \\alpha_j, s_j , oasis_AtY_SY_blocked() streams voxels obtain njvn_{jv} mvm_v.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"fractional-ridge","dir":"Articles","previous_headings":"Single-Basis OASIS Algebra","what":"Fractional Ridge","title":"OASIS Theory: Algebra and Implementation Details","text":"oasis$ridge_mode = \"fractional\" sets λx=ηx⋅d‾\\lambda_x = \\eta_x \\cdot \\bar{d} λb=ηb⋅s‾\\lambda_b = \\eta_b \\cdot \\bar{s}, d‾\\bar{d} s‾\\bar{s} means djd_j sjs_j. helper .oasis_resolve_ridge() implements scaling. Absolute ridge uses supplied values directly.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"standard-errors","dir":"Articles","previous_headings":"Single-Basis OASIS Algebra","what":"Standard Errors","title":"OASIS Theory: Algebra and Implementation Details","text":"Given Gj−1G_j^{-1} residual norm ∥RY∥2\\|RY\\|^2, variance βjv\\beta_{jv} Var(β̂jv)=σjv2(Gj−1)11,σjv2=SSEjvdof, \\operatorname{Var}(\\hat{\\beta}_{jv}) = \\sigma_{jv}^2 \\left( G_j^{-1} \\right)_{11}, \\quad \\sigma_{jv}^2 = \\frac{\\text{SSE}_{jv}}{\\text{dof}}, SSEjv=∥RY⋅v∥2−2(βjvnjv+γjv(mv−njv))+djβjv2+sjγjv2+2αjβjvγjv. \\text{SSE}_{jv} = \\|RY_{\\cdot v}\\|^2 - 2 (\\beta_{jv} n_{jv} + \\gamma_{jv} (m_v - n_{jv})) + d_j \\beta_{jv}^2 + s_j \\gamma_{jv}^2 + 2 \\alpha_j \\beta_{jv} \\gamma_{jv}. .oasis_se_from_norms() realises computation, reusing njvn_{jv}, mvm_v cached design scalars.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"multi-basis-extension","dir":"Articles","previous_headings":"","what":"Multi-Basis Extension","title":"OASIS Theory: Algebra and Implementation Details","text":"HRF contributes K>1K > 1 basis functions, trial columns Aj∈ℝT×KA_j \\\\mathbb{R}^{T \\times K}. Define S=∑jAjS = \\sum_j A_j Dj=AjTAjD_j = A_j^T A_j Cj=AjT(S−Aj)C_j = A_j^T (S - A_j) Ej=(S−Aj)T(S−Aj)E_j = (S - A_j)^T (S - A_j) Per voxel need N1=ATRYN1 = ^T RY (stacked NN blocks size KK) SY=STRYSY = S^T RY. block system [Dj+λxICjCjTEj+λbI][BjvΓjv]=[N1jvSYv−N1jv], \\begin{bmatrix} D_j + \\lambda_x & C_j \\\\ C_j^T & E_j + \\lambda_b \\end{bmatrix} \\begin{bmatrix} B_{jv} \\\\ \\Gamma_{jv} \\end{bmatrix} = \\begin{bmatrix} N1_{jv} \\\\ SY_v - N1_{jv} \\end{bmatrix}, Bjv∈ℝKB_{jv} \\\\mathbb{R}^K. oasisk_betas() solves 2K×2K system via Cholesky factorisation. Ridge adds λxI\\lambda_x λbI\\lambda_b block diagonals. Compared single-basis path, shapes cached matrices differ; solve still analytic per trial/voxel block. companion oasisk_betas_se() extends SSE/variance calculation multi-basis case, using building blocks.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"hrf-aware-design-construction","dir":"Articles","previous_headings":"","what":"HRF-Aware Design Construction","title":"OASIS Theory: Algebra and Implementation Details","text":"OASIS can construct XX fly event specifications. .oasis_build_X_from_events() uses fmrihrf::regressor_set() generate trial-wise columns (optional -condition aggregates) given: cond$onsets: per-trial onset times cond$hrf: HRF object (canonical, FIR, multi-basis, user-defined) cond$span, precision, method: convolution controls design residualised nuisance regressors fed algebra . HRF definition enters directly, switching HRFs running grid searches automatically regenerates matching design. provide explicit X, OASIS skips step assumes already encoded HRF matrix.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"ar1-whitening","dir":"Articles","previous_headings":"","what":"AR(1) Whitening","title":"OASIS Theory: Algebra and Implementation Details","text":"oasis$whiten = \"ar1\" estimates common AR(1) coefficient residualised data. .oasis_ar1_whitener() computes ρ\\rho applies Toeplitz-safe differencing: ỹt={1−ρ2y1t=1,yt−ρyt−1t>1. \\tilde{y}_t = \\begin{cases} \\sqrt{1 - \\rho^2} y_1 & t = 1, \\\\ y_t - \\rho y_{t-1} & t > 1. \\end{cases} transformation applied XX nuisance regressors standard OASIS algebra runs. Whitening preserves single-pass benefits transformed data treated exactly like original inputs.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"diagnostics-output","dir":"Articles","previous_headings":"","what":"Diagnostics Output","title":"OASIS Theory: Algebra and Implementation Details","text":"oasis$return_diag = TRUE, OASIS returns precomputed design scalars: Single-basis: dj,αj,sjd_j, \\alpha_j, s_j (oasis_precompute_design()) Multi-basis: Dj,Cj,EjD_j, C_j, E_j (oasisk_precompute_design()) matrices useful checking trial collinearity, energy, effect ridge scaling.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"algorithm-summary","dir":"Articles","previous_headings":"","what":"Algorithm Summary","title":"OASIS Theory: Algebra and Implementation Details","text":"Putting everything together, single-basis solver proceeds follows: Residualise YY XX nuisance regressors, optionally whitening. Compute aj,s,dj,αj,sja_j, s, d_j, \\alpha_j, s_j (oasis_precompute_design). Stream voxels blocks, forming NY=ATRYN_Y = ^T RY SY=sTRYS_Y = s^T RY (oasis_AtY_SY_blocked). Apply ridge scaling (absolute fractional) obtain λx,λb\\lambda_x, \\lambda_b. trial, evaluate closed-form βjv\\beta_{jv} (γjv\\gamma_{jv} SEs requested). Optionally compute SEs diagnostics. multi-basis path swaps steps 2–5 block equivalents. cases, cost dominated single projection YY matrix–vector multiplies step 3, giving 𝒪(TV)\\mathcal{O}(T V) complexity small trial-dependent overhead.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"complexity-and-memory","dir":"Articles","previous_headings":"","what":"Complexity and Memory","title":"OASIS Theory: Algebra and Implementation Details","text":"Projection / whitening: 𝒪(TVKz)\\mathcal{O}(T V K_z) arithmetic, 𝒪(TKz)\\mathcal{O}(T K_z) memory confounds Precomputation: 𝒪(TN)\\mathcal{O}(T N) Products (blocked): 𝒪(TV)\\mathcal{O}(T V) block size tuning Closed-form solves: 𝒪(NV)\\mathcal{O}(N V) negligible constants (2×2 2K×2K systems) Compared classical LSS (NN separate regressions), OASIS shaves repeated projections linear solves, yielding substantial speedups NN VV large.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/oasis_theory.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"OASIS Theory: Algebra and Implementation Details","text":"Mumford, J. ., Turner, B. O., Ashby, F. G., & Poldrack, R. . (2012). Deconvolving BOLD activation event-related designs multivoxel pattern classification analyses. NeuroImage, 59(3), 2636–2643. fmrilss source files R/oasis_glue.R src/oasis_core.cpp (implementation alignment).","code":"sessionInfo() #> R version 4.5.1 (2025-06-13) #> Platform: x86_64-pc-linux-gnu #> Running under: Ubuntu 24.04.3 LTS #>  #> Matrix products: default #> BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  #> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 #>  #> locale: #>  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        #>  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    #>  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           #> [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    #>  #> time zone: UTC #> tzcode source: system (glibc) #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> loaded via a namespace (and not attached): #>  [1] digest_0.6.37     desc_1.4.3        R6_2.6.1          fastmap_1.2.0     #>  [5] xfun_0.53         cachem_1.1.0      knitr_1.50        htmltools_0.5.8.1 #>  [9] rmarkdown_2.29    lifecycle_1.0.4   cli_3.6.5         pkgdown_2.1.3     #> [13] sass_0.4.10       textshaping_1.0.3 jquerylib_0.1.4   systemfonts_1.2.3 #> [17] compiler_4.5.1    tools_4.5.1       ragg_1.5.0        evaluate_1.0.5    #> [21] bslib_0.9.0       yaml_2.3.10       jsonlite_2.0.0    rlang_1.1.6       #> [25] fs_1.6.6"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"why-hrf-variability-matters","dir":"Articles","previous_headings":"","what":"Why HRF Variability Matters","title":"Voxel-wise HRF Modeling with fmrilss","text":"Voxel-wise HRF modeling addresses spatial subject-specific differences hemodynamic response can bias trial-wise estimates. Vascular properties, neurovascular coupling, acquisition protocols influence HRF, relying single canonical shape can misrepresent activation patterns. vignette shows estimate voxel-specific HRFs incorporate LSS analyses. Familiarity core LSS workflow fmrihrf basics assumed.","code":"library(fmrilss) library(fmrihrf) #>  #> Attaching package: 'fmrihrf' #> The following object is masked from 'package:stats': #>  #>     deriv set.seed(123)  # Helper function to create design matrix using fmrihrf API # (design_matrix is not exported from fmrihrf, so we create a wrapper) design_matrix <- function(sframe, conditions, tr_per_trial = FALSE) {   # Get block info from sframe   n_blocks <- length(fmrihrf::blocklens(sframe))    if (tr_per_trial) {     # Create trial-wise design (one column per trial)     X_list <- list()     for (cond in conditions) {       n_trials <- length(cond$onsets)       # Each trial gets its own regressor       X_trial <- fmrihrf::regressor_design(         onsets = cond$onsets,         fac = factor(1:n_trials),  # Each trial is its own level         block = rep(1, n_trials),  # Assume single block for simplicity         sframe = sframe,         hrf = cond$hrf,         duration = if (!is.null(cond$duration)) cond$duration else 0,         span = if (!is.null(cond$span)) cond$span else 30,         precision = 0.1,         method = \"conv\",         summate = FALSE  # Don't sum across trials       )       X_list[[length(X_list) + 1]] <- X_trial     }     X <- do.call(cbind, X_list)   } else {     # Create aggregate design (one column per condition)     X_list <- list()     for (cond in conditions) {       n_trials <- length(cond$onsets)       # All trials in same condition get summed       X_cond <- fmrihrf::regressor_design(         onsets = cond$onsets,         fac = factor(rep(1, n_trials)),  # All trials same level         block = rep(1, n_trials),         sframe = sframe,         hrf = cond$hrf,         duration = if (!is.null(cond$duration)) cond$duration else 0,         span = if (!is.null(cond$span)) cond$span else 30,         precision = 0.1,         method = \"conv\",         summate = TRUE  # Sum across trials in condition       )       X_list[[length(X_list) + 1]] <- X_cond     }     X <- do.call(cbind, X_list)   }    list(X = as.matrix(X)) }"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"building-intuition-through-simulation","dir":"Articles","previous_headings":"","what":"Building Intuition Through Simulation","title":"Voxel-wise HRF Modeling with fmrilss","text":"best way understand impact HRF variability see action. Let’s create controlled simulation know ground truth can observe different analysis approaches perform.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"creating-data-with-variable-hrfs","dir":"Articles","previous_headings":"Building Intuition Through Simulation","what":"Creating Data with Variable HRFs","title":"Voxel-wise HRF Modeling with fmrilss","text":"’ll simulate experiment rapid stimulus presentation, different voxels subtly different HRF characteristics. mimics might happen analyzing data regions different vascular properties:","code":"# Simulation parameters n_time <- 200      # Time points n_trials <- 10     # Number of trials n_vox <- 5         # Number of voxels TR <- 1.0          # Repetition time  # Create event design with rapid presentation events <- data.frame(   onset = seq(10, 180, length.out = n_trials),   duration = rep(1, n_trials),   condition = rep(\"task\", n_trials) )  # Create sampling frame sframe <- fmrihrf::sampling_frame(blocklens = n_time, TR = TR)  # Generate voxel-specific HRF parameters # Each voxel has slightly different HRF characteristics voxel_hrfs <- list() for (v in 1:n_vox) {   # Vary peak time and width across voxels   peak_shift <- (v - 3) * 0.5  # Range: -1 to +1 seconds   width_scale <- 1 + (v - 3) * 0.1  # Range: 0.8 to 1.2    # Create modified HRF parameters   # Use SPMG1 as base and modify peak and undershoot   base_hrf <- HRF_SPMG1    # Modify the HRF parameters   # SPMG1 uses double gamma with peak around 5s and undershoot around 15s   voxel_hrfs[[v]] <- fmrihrf::HRF(     fun = function(t) {       # Shift the peak time       t_shifted <- t - peak_shift       # Apply width scaling (preserve area by multiplying by scale)       base_response <- base_hrf(t_shifted / width_scale) * width_scale       base_response     },     name = paste0(\"voxel_\", v, \"_hrf\"),     span = attr(base_hrf, \"span\"),     nbasis = attr(base_hrf, \"nbasis\")   ) }  # Generate true betas for each trial and voxel true_betas <- matrix(rnorm(n_trials * n_vox, mean = 1, sd = 0.3),                      nrow = n_trials, ncol = n_vox)  # Create time series data Y <- matrix(0, n_time, n_vox)  # For each voxel, create signal with voxel-specific HRF for (v in 1:n_vox) {   # Create design matrix for this voxel   dm <- design_matrix(     sframe = sframe,     conditions = list(       list(onsets = events$onset,            hrf = voxel_hrfs[[v]],            name = \"task\")     ),     tr_per_trial = TRUE   )    # Generate signal for this voxel   Y[, v] <- dm$X %*% true_betas[, v] }  # Add realistic noise with AR(1) structure noise_sd <- 0.5 ar_coef <- 0.3 for (v in 1:n_vox) {   # Generate independent innovations   innovations <- rnorm(n_time, sd = noise_sd)    # Apply AR(1) process   noise <- numeric(n_time)   noise[1] <- innovations[1]   for (t in 2:n_time) {     noise[t] <- ar_coef * noise[t-1] + sqrt(1 - ar_coef^2) * innovations[t]   }    Y[, v] <- Y[, v] + noise }  # Name the voxels colnames(Y) <- paste0(\"V\", 1:n_vox)  cat(\"Created synthetic data:\\n\") #> Created synthetic data: cat(\"  Time points:\", n_time, \"\\n\") #>   Time points: 200 cat(\"  Trials:\", n_trials, \"\\n\") #>   Trials: 10 cat(\"  Voxels:\", n_vox, \"\\n\") #>   Voxels: 5 cat(\"  Signal-to-noise ratio:\", round(var(Y[,1] - noise) / var(noise), 2), \"\\n\") #>   Signal-to-noise ratio: 3.62"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"the-standard-approach-and-its-limitations","dir":"Articles","previous_headings":"","what":"The Standard Approach and Its Limitations","title":"Voxel-wise HRF Modeling with fmrilss","text":"apply standard LSS canonical HRF data actually contains HRF variability, ’re making assumption may hold. Let’s see happens: Standard LSS treats every voxel shared HRF, deviations template translate biased betas.","code":"# Create design matrix with canonical HRF dm_standard <- design_matrix(   sframe = sframe,   conditions = list(     list(onsets = events$onset,          hrf = HRF_SPMG1,  # Canonical HRF for all voxels          name = \"task\")   ),   tr_per_trial = TRUE )  # Run standard LSS standard_betas <- lss(Y, dm_standard$X, method = \"r_optimized\")  cat(\"Standard LSS beta estimates (first 3 trials, all voxels):\\n\") #> Standard LSS beta estimates (first 3 trials, all voxels): print(round(standard_betas[1:3, ], 2)) #>           V1   V2   V3   V4   V5 #> Trial_1 0.57 1.59 0.71 0.93 0.61 #> Trial_2 0.90 1.05 1.11 0.49 0.81 #> Trial_3 1.13 0.68 0.42 0.79 0.53"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"estimating-voxel-specific-hrfs","dir":"Articles","previous_headings":"","what":"Estimating Voxel-Specific HRFs","title":"Voxel-wise HRF Modeling with fmrilss","text":"account HRF variability, need first estimate voxel’s HRF characteristics. One powerful approach uses multi-basis set can capture different aspects HRF variation. SPM software popularized three-component basis set consisting canonical HRF, temporal derivative (capturing shifts peak time), dispersion derivative (capturing changes width): basis weights describe latency width shifts relative canonical HRF: temporal derivative tracks peak timing dispersion derivative tracks response width.","code":"# Step 1: Estimate voxel-specific HRF using multi-basis approach # We'll use SPMG3 which includes canonical HRF plus temporal and dispersion derivatives  # Create multi-basis design matrix dm_multibasis <- design_matrix(   sframe = sframe,   conditions = list(     list(onsets = events$onset,          hrf = HRF_SPMG3,  # 3-basis set          name = \"task\")   ),   tr_per_trial = FALSE  # Aggregate for HRF estimation )  # Estimate HRF basis weights for each voxel hrf_weights <- matrix(NA, 3, n_vox)  # 3 basis functions  for (v in 1:n_vox) {   # Simple GLM to estimate basis weights   fit <- lm(Y[, v] ~ dm_multibasis$X - 1)   hrf_weights[, v] <- coef(fit) }  cat(\"Estimated HRF basis weights (3 bases x\", n_vox, \"voxels):\\n\") #> Estimated HRF basis weights (3 bases x 5 voxels): print(round(hrf_weights, 2)) #>       [,1]  [,2]  [,3]  [,4]  [,5] #> [1,]  1.21  1.37  1.12  1.42  1.31 #> [2,] -1.80 -1.91 -1.57 -1.78 -1.99 #> [3,]  1.45  1.73  1.78  2.15  1.58  # Normalize weights (optional, for interpretation) hrf_weights_norm <- sweep(hrf_weights, 2, hrf_weights[1,], \"/\") cat(\"\\nNormalized weights (relative to canonical):\\n\") #>  #> Normalized weights (relative to canonical): print(round(hrf_weights_norm, 2)) #>       [,1]  [,2]  [,3]  [,4]  [,5] #> [1,]  1.00  1.00  1.00  1.00  1.00 #> [2,] -1.49 -1.39 -1.41 -1.25 -1.53 #> [3,]  1.20  1.26  1.59  1.51  1.21"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"applying-voxel-specific-hrfs-in-lss","dir":"Articles","previous_headings":"","what":"Applying Voxel-Specific HRFs in LSS","title":"Voxel-wise HRF Modeling with fmrilss","text":"HRF estimates hand, can now perform LSS using voxel’s specific hemodynamic response profile. two-stage approach first characterizes HRF, uses characterization accurate trial-wise estimation:","code":"# For demonstration, we'll use a simplified approach # In practice, you might use lss_with_hrf() with the appropriate backend  voxel_betas <- matrix(NA, n_trials, n_vox)  for (v in 1:n_vox) {   # Create voxel-specific design matrix using estimated weights   # Weight the basis functions by the estimated coefficients   X_voxel <- matrix(0, n_time, n_trials)    for (trial in 1:n_trials) {     # Create trial-specific regressors for each basis     dm_trial <- design_matrix(       sframe = sframe,       conditions = list(         list(onsets = events$onset[trial],              hrf = HRF_SPMG3,              name = \"trial\")       ),       tr_per_trial = FALSE     )      # Combine bases using voxel-specific weights     X_voxel[, trial] <- dm_trial$X %*% hrf_weights[, v]   }    # Run LSS for this voxel with its specific HRF   voxel_betas[, v] <- lss(Y[, v, drop = FALSE], X_voxel, method = \"r_optimized\") }  cat(\"Voxel-wise HRF LSS beta estimates (first 3 trials, all voxels):\\n\") #> Voxel-wise HRF LSS beta estimates (first 3 trials, all voxels): print(round(voxel_betas[1:3, ], 2)) #>      [,1] [,2] [,3] [,4] [,5] #> [1,] 0.81 1.30 1.01 0.94 0.74 #> [2,] 1.00 1.04 1.25 0.56 0.80 #> [3,] 1.20 0.77 0.57 0.94 0.68"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"the-oasis-alternative","dir":"Articles","previous_headings":"","what":"The OASIS Alternative","title":"Voxel-wise HRF Modeling with fmrilss","text":"OASIS method provides elegant alternative can handle HRF estimation LSS unified framework. Rather requiring separate stages, OASIS incorporates HRF flexibility directly estimation process, often improved computational efficiency: OASIS handles HRF expansion LSS solve one pass, limits redundant projections dense event-related designs.","code":"# OASIS can automatically handle HRF estimation and LSS in one step oasis_betas <- lss(   Y = Y,   X = NULL,   method = \"oasis\",   oasis = list(     design_spec = list(       sframe = sframe,       cond = list(         onsets = events$onset,         hrf = HRF_SPMG3,  # Multi-basis HRF         span = 30       )     ),     ridge_mode = \"fractional\",     ridge_x = 0.01,  # Small ridge for stability     ridge_b = 0.01   ) )  # OASIS returns results for each basis function # Extract canonical component (first basis) oasis_canonical <- oasis_betas[seq(1, nrow(oasis_betas), by = 3), ]  cat(\"OASIS beta estimates (canonical component, first 3 trials):\\n\") #> OASIS beta estimates (canonical component, first 3 trials): print(round(oasis_canonical[1:3, ], 2)) #>           V1   V2   V3   V4   V5 #> Trial_1 0.76 1.64 0.99 1.38 0.76 #> Trial_4 1.08 1.23 1.32 0.69 0.92 #> Trial_7 1.24 0.96 0.54 1.03 0.70"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"evaluating-the-approaches","dir":"Articles","previous_headings":"","what":"Evaluating the Approaches","title":"Voxel-wise HRF Modeling with fmrilss","text":"Let’s quantitatively compare well method recovers true beta values used generate synthetic data:  Points closer diagonal line indicate better recovery true betas.","code":"# Calculate correlations with true betas cor_standard <- cor(as.vector(standard_betas), as.vector(true_betas)) cor_voxel <- cor(as.vector(voxel_betas), as.vector(true_betas)) cor_oasis <- cor(as.vector(oasis_canonical), as.vector(true_betas))  # Calculate RMSE rmse_standard <- sqrt(mean((standard_betas - true_betas)^2)) rmse_voxel <- sqrt(mean((voxel_betas - true_betas)^2)) rmse_oasis <- sqrt(mean((oasis_canonical - true_betas)^2))  # Create comparison table comparison <- data.frame(   Method = c(\"Standard LSS\", \"Voxel-wise HRF\", \"OASIS\"),   Correlation = round(c(cor_standard, cor_voxel, cor_oasis), 3),   RMSE = round(c(rmse_standard, rmse_voxel, rmse_oasis), 3) )  print(comparison) #>           Method Correlation  RMSE #> 1   Standard LSS       0.875 0.249 #> 2 Voxel-wise HRF       0.847 0.197 #> 3          OASIS       0.877 0.207  # Visualization par(mfrow = c(1, 3), mar = c(4, 4, 3, 1))  # Standard LSS plot(true_betas, standard_betas,      xlab = \"True Betas\", ylab = \"Estimated Betas\",      main = paste(\"Standard LSS\\n(r =\", round(cor_standard, 2), \")\"),      pch = 19, col = rep(1:n_vox, each = n_trials),      xlim = range(true_betas), ylim = range(true_betas)) abline(0, 1, lty = 2, col = \"gray\")  # Voxel-wise HRF plot(true_betas, voxel_betas,      xlab = \"True Betas\", ylab = \"Estimated Betas\",      main = paste(\"Voxel-wise HRF\\n(r =\", round(cor_voxel, 2), \")\"),      pch = 19, col = rep(1:n_vox, each = n_trials),      xlim = range(true_betas), ylim = range(true_betas)) abline(0, 1, lty = 2, col = \"gray\")  # OASIS plot(true_betas, oasis_canonical,      xlab = \"True Betas\", ylab = \"Estimated Betas\",      main = paste(\"OASIS\\n(r =\", round(cor_oasis, 2), \")\"),      pch = 19, col = rep(1:n_vox, each = n_trials),      xlim = range(true_betas), ylim = range(true_betas)) abline(0, 1, lty = 2, col = \"gray\")  legend(\"topleft\", legend = paste(\"Voxel\", 1:n_vox),        col = 1:n_vox, pch = 19, cex = 0.8)"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"when-to-consider-voxel-wise-hrf-modeling","dir":"Articles","previous_headings":"","what":"When to Consider Voxel-wise HRF Modeling","title":"Voxel-wise HRF Modeling with fmrilss","text":"Use voxel-wise HRF modeling : - regions differ vascular architecture (e.g., motor vs. visual cortex); - cohorts show altered neurovascular coupling (aging, clinical populations, medication effects); - high-resolution acquisitions expose layer column specific responses; - sessions long enough HRF characteristics drift time.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"computational-strategies-for-large-scale-analysis","dir":"Articles","previous_headings":"","what":"Computational Strategies for Large-Scale Analysis","title":"Voxel-wise HRF Modeling with fmrilss","text":"Whole-brain analyses expensive, match backend workload: Choose backend according data size available hardware: R implementations work pilot subsets, whole-brain studies typically require optimized C++ path OASIS.","code":"# C++ backend for medium-sized data betas_cpp <- lss(Y, X, method = \"cpp_optimized\")  # For very large data with multiple cores # betas_parallel <- lss(Y, X, method = \"cpp_parallel\", n_cores = 4)  # OASIS method is often fastest for complex designs betas_oasis <- lss(Y, X = NULL, method = \"oasis\",                    oasis = list(design_spec = design_spec))"},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"choosing-the-right-method-for-your-study","dir":"Articles","previous_headings":"","what":"Choosing the Right Method for Your Study","title":"Voxel-wise HRF Modeling with fmrilss","text":"Method selection guidelines: - lss() canonical HRF sufficient responses expected homogeneous compute needs modest; - voxel-wise HRF LSS prioritizes accuracy anatomy pathology implies heterogeneous responses; - OASIS preferred rapid-event designs want single-step solve HRF flexibility ridge control.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"practical-recommendations","dir":"Articles","previous_headings":"","what":"Practical Recommendations","title":"Voxel-wise HRF Modeling with fmrilss","text":"Practical recommendations: - validate HRF assumptions independent data held-runs; - check signal--noise ratio supports estimation additional HRF parameters; - add complexity simpler models prove insufficient; - record HRF modeling choices reproducibility.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"looking-forward","dir":"Articles","previous_headings":"","what":"Looking Forward","title":"Voxel-wise HRF Modeling with fmrilss","text":"Voxel-wise HRF modeling improves trial-wise beta estimation accounting spatial variability hemodynamic response. fmrilss pipeline designed incorporate newer HRF estimation strategies appear literature.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/articles/voxel-wise-hrf.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further Reading","title":"Voxel-wise HRF Modeling with fmrilss","text":"vignette(\"getting_started\") LSS basics vignette(\"oasis_method\") advanced OASIS features ?fmrihrf HRF model options Mumford et al. (2012) core LSS theory","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Brad Buchsbaum. Maintainer.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Buchsbaum B (2025). fmrilss: Least Squares Separate (LSS) Analysis fMRI Data. R package version 0.1.0, https://bbuchsbaum.github.io/fmrilss/.","code":"@Manual{,   title = {fmrilss: Least Squares Separate (LSS) Analysis for fMRI Data},   author = {Brad Buchsbaum},   year = {2025},   note = {R package version 0.1.0},   url = {https://bbuchsbaum.github.io/fmrilss/}, }"},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"fmrilss","dir":"","previous_headings":"","what":"Least Squares Separate (LSS) Analysis for fMRI Data","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"Least Squares Separate (LSS) Analysis fMRI Data.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"fmrilss package provides efficient flexible implementation Least Squares Separate (LSS) method fMRI analysis, proposed Mumford et al. (2012). approach models trial separate GLM, making powerful technique multivariate pattern analysis (MVPA) connectivity studies trial-specific estimates needed. package offers multiple backends, simple reference implementation highly optimized, parallel C++ engine, accessible clean, unified interface.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"Five Implementations: Includes highly optimized C++ version, optimized R version, standard vectorized R C++ versions, simple R loop testing validation. Parallel Processing: optimized C++ version uses OpenMP multi-threaded execution maximize performance modern hardware. Flexible & Modern Interface: clean lss(Y, X, Z, Nuisance) signature powerful intuitive. Nuisance Regression: Built-support projecting nuisance regressors (e.g., motion parameters, physiological noise) LSS analysis. CRAN-Compliant: Built portable configurations suitable CRAN submission.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"can install development version fmrilss GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"bbuchsbaum/fmrilss\")"},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"primary function lss(), takes data Y, trial design X, experimental regressors Z, optional nuisance regressors.","code":"library(fmrilss)  # 1. Generate synthetic data set.seed(123) n_timepoints <- 120 n_trials <- 15 n_voxels <- 50  # Trial design matrix (X): one column per trial X <- matrix(0, n_timepoints, n_trials) onsets <- seq(from = 5, to = n_timepoints - 10, length.out = n_trials) for(i in 1:n_trials) {   X[onsets[i]:(onsets[i] + 4), i] <- 1 } colnames(X) <- paste0(\"Trial_\", 1:n_trials)  # Experimental regressors (Z): intercept and condition-specific effects # These are experimental regressors we want to model and get beta estimates for, # but not trial-wise (e.g., condition differences, block effects) Z <- cbind(Intercept = 1, LinearTrend = scale(1:n_timepoints, center = TRUE, scale = FALSE))  # Nuisance regressors: e.g., 6 motion parameters Nuisance <- matrix(rnorm(n_timepoints * 6), n_timepoints, 6)  # Data (Y): timepoints x voxels # (Simulate some effects for demonstration) true_betas <- matrix(rnorm(n_trials * n_voxels, 0, 1.5), n_trials, n_voxels) Y <- Z %*% matrix(c(10, -0.2), 2, n_voxels) +       X %*% true_betas +      Nuisance %*% matrix(rnorm(6 * n_voxels, 0, 2), 6, n_voxels) +      matrix(rnorm(n_timepoints * n_voxels, 0, 0.8), n_timepoints, n_voxels) colnames(Y) <- paste0(\"Voxel_\", 1:n_voxels)   # 2. Run LSS analysis  # Example 1: Basic LSS with default intercept # If Z is NULL, an intercept is automatically added. beta_estimates <- lss(Y, X)  # Example 2: LSS with experimental regressors (intercept + condition effects) beta_fixed <- lss(Y, X, Z = Z)  # Example 3: LSS with experimental regressors and nuisance regression beta_clean <- lss(Y, X, Z = Z, Nuisance = Nuisance)  # Example 4: Use the super-fast, parallelized C++ implementation beta_fast <- lss(Y, X, Z = Z, Nuisance = Nuisance, method = \"cpp_optimized\")  # The result is a (trials x voxels) matrix of beta estimates print(dim(beta_fast)) #> [1] 15 50 print(beta_fast[1:5, 1:4])"},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"Mumford, J. ., Turner, B. O., Ashby, F. G., & Poldrack, R. . (2012). Deconvolving BOLD activation event-related designs multivoxel pattern classification analyses. NeuroImage, 59(3), 2636-2643.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Least Squares Separate (LSS) Analysis for fMRI Data","text":"GPL-3","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/LSSBeta.html","id":null,"dir":"Reference","previous_headings":"","what":"LSSBeta object — LSSBeta","title":"LSSBeta object — LSSBeta","text":"Simple list-based S3 class returned lss_with_hrf containing trial-wise beta estimates.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/MixedWorkspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixed Model Workspace for Optimized Computation — MixedWorkspace","title":"Mixed Model Workspace for Optimized Computation — MixedWorkspace","text":"Stores precomputed matrices decompositions can reused across multiple voxels avoid repeated expensive computations.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/VoxelHRF.html","id":null,"dir":"Reference","previous_headings":"","what":"VoxelHRF object — VoxelHRF","title":"VoxelHRF object — VoxelHRF","text":"Simple list-based S3 class returned estimate_voxel_hrf containing voxel-wise HRF basis coefficients related metadata.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/calculate_recovery_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate HRF Recovery Metrics — calculate_recovery_metrics","title":"Calculate HRF Recovery Metrics — calculate_recovery_metrics","text":"Evaluates well method recovered true HRF","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/calculate_recovery_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate HRF Recovery Metrics — calculate_recovery_metrics","text":"","code":"calculate_recovery_metrics(results, true_hrf)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/calculate_recovery_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate HRF Recovery Metrics — calculate_recovery_metrics","text":"results Output compare_hrf_recovery true_hrf Ground truth HRF","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/calculate_recovery_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate HRF Recovery Metrics — calculate_recovery_metrics","text":"Data frame recovery metrics","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/compare_hrf_recovery.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare HRF Recovery Methods — compare_hrf_recovery","title":"Compare HRF Recovery Methods — compare_hrf_recovery","text":"Compares OASIS, SPMG1, SPMG3, FIR HRF recovery","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/compare_hrf_recovery.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare HRF Recovery Methods — compare_hrf_recovery","text":"","code":"compare_hrf_recovery(data, hrf_grid = NULL)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/compare_hrf_recovery.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare HRF Recovery Methods — compare_hrf_recovery","text":"data Synthetic data generate_lwu_data hrf_grid Optional pre-computed HRF grid OASIS","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/compare_hrf_recovery.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare HRF Recovery Methods — compare_hrf_recovery","text":"List results methods","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/create_lwu_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Create LWU HRF Grid for OASIS Search — create_lwu_grid","title":"Create LWU HRF Grid for OASIS Search — create_lwu_grid","text":"Generates grid LWU HRF models varying parameters","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/create_lwu_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create LWU HRF Grid for OASIS Search — create_lwu_grid","text":"","code":"create_lwu_grid(   tau_range = c(4, 8),   sigma_range = c(1.5, 3.5),   rho_range = c(0.1, 0.6),   n_tau = 5,   n_sigma = 3,   n_rho = 3 )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/create_lwu_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create LWU HRF Grid for OASIS Search — create_lwu_grid","text":"tau_range Range tau values test sigma_range Range sigma values test rho_range Range rho values test n_tau Number tau values grid n_sigma Number sigma values grid n_rho Number rho values grid","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/create_lwu_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create LWU HRF Grid for OASIS Search — create_lwu_grid","text":"List HRF models parameters","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-convert_legacy_whiten.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert old-style whitening options to new format — .convert_legacy_whiten","title":"Convert old-style whitening options to new format — .convert_legacy_whiten","text":"Internal helper maintain backward compatibility old oasis$whiten = \"ar1\" syntax converting new prewhiten format.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-convert_legacy_whiten.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert old-style whitening options to new format — .convert_legacy_whiten","text":"","code":".convert_legacy_whiten(oasis_opts)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-convert_legacy_whiten.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert old-style whitening options to new format — .convert_legacy_whiten","text":"oasis_opts List OASIS options potentially containing whiten field","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-convert_legacy_whiten.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert old-style whitening options to new format — .convert_legacy_whiten","text":"List prewhiten options NULL whitening","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-lss_oasis.html","id":null,"dir":"Reference","previous_headings":"","what":"OASIS backend for fmrilss::lss (internal entry) — .lss_oasis","title":"OASIS backend for fmrilss::lss (internal entry) — .lss_oasis","text":"Add `method=\"oasis\"` fmrilss::lss(). path:   - (optionally) builds trial-wise design X via fmrihrf   - residualizes Y (X downstream) confounds + Z + -condition aggregates   - computes trial betas one batched pass via closed-form LSS (exact; ridge-LSS)   - optionally returns per-trial SEs design diagnostics","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-lss_oasis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"OASIS backend for fmrilss::lss (internal entry) — .lss_oasis","text":"","code":".lss_oasis(   Y,   X = NULL,   Z = NULL,   Nuisance = NULL,   oasis = list(),   prewhiten = NULL )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-lss_oasis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"OASIS backend for fmrilss::lss (internal entry) — .lss_oasis","text":"Y (T x V) numeric matrix X (T x N_trials) trial-wise design (NULL, use oasis$design_spec build) Z (T x K) fixed experimental regressors projected Nuisance (T x P) confounds (intercept, motion, drift, aCompCor, ...) oasis list options: - design_spec: list describing events/HRF build X via fmrihrf - K: explicit basis dimension (auto-detected provided) - ridge_mode: \"absolute\" (default) \"fractional\" - ridge_x, ridge_b: nonnegative ridge [a_j, b_j] Gram (default 0 -> exact LSS) - block_cols: voxel block size (default 4096) - return_se: logical (default FALSE) - return_diag: logical (default FALSE) - whiten: \"none\" | \"ar1\" (default \"none\"); \"ar1\", prewhiten Y design first (DEPRECATED: use prewhiten parameter) prewhiten list prewhitening options using fmriAR (see ?lss details)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-lss_oasis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"OASIS backend for fmrilss::lss (internal entry) — .lss_oasis","text":"default: (N_trials x V) matrix betas; `return_se` `return_diag`, list","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-mixed_solve_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixed Model Solver using C++ — .mixed_solve_cpp","title":"Mixed Model Solver using C++ — .mixed_solve_cpp","text":"C++ implementation mixed model solver. function typically called main `mixed_solve` function rather directly.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-mixed_solve_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mixed Model Solver using C++ — .mixed_solve_cpp","text":"","code":".mixed_solve_cpp(   Y,   X = NULL,   Z = NULL,   K = NULL,   method = \"REML\",   bounds = c(1e-09, 1e+09),   SE = FALSE,   return_Hinv = FALSE )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-mixed_solve_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mixed Model Solver using C++ — .mixed_solve_cpp","text":"Y Response vector. X Design matrix fixed effects (default: intercept ). Z Design matrix random effects (default: identity matrix). K Kinship matrix (default: identity matrix). method Optimization method, either \"REML\" \"ML\". bounds Bounds optimizer. SE Logical, whether return standard errors. return_Hinv Logical, whether return inverse H.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-mixed_solve_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mixed Model Solver using C++ — .mixed_solve_cpp","text":"list mixed model results.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-needs_advanced_prewhitening.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if advanced prewhitening is needed — .needs_advanced_prewhitening","title":"Check if advanced prewhitening is needed — .needs_advanced_prewhitening","text":"Determines whether use fmriAR (advanced) keep simple AR(1) based requested features.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-needs_advanced_prewhitening.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if advanced prewhitening is needed — .needs_advanced_prewhitening","text":"","code":".needs_advanced_prewhitening(prewhiten)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-needs_advanced_prewhitening.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if advanced prewhitening is needed — .needs_advanced_prewhitening","text":"prewhiten List prewhitening options","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-needs_advanced_prewhitening.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if advanced prewhitening is needed — .needs_advanced_prewhitening","text":"Logical: TRUE fmriAR needed, FALSE simple AR(1)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-prewhiten_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prewhiten fMRI data using AR/ARMA models — .prewhiten_data","title":"Prewhiten fMRI data using AR/ARMA models — .prewhiten_data","text":"Internal function providing unified interface prewhitening fMRI data using fmriAR package. Supports various AR/ARMA models flexible parameter estimation strategies.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-prewhiten_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prewhiten fMRI data using AR/ARMA models — .prewhiten_data","text":"","code":".prewhiten_data(Y, X = NULL, Z = NULL, Nuisance = NULL, prewhiten = list())"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-prewhiten_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prewhiten fMRI data using AR/ARMA models — .prewhiten_data","text":"Y Numeric matrix (timepoints x voxels) fMRI data X Optional design matrix trials (timepoints x trials) Z Optional experimental design matrix (timepoints x regressors) Nuisance Optional nuisance regressors (timepoints x nuisance) prewhiten List prewhitening options: method Character: \"ar\" (default), \"arma\", \"none\" p Integer \"auto\": AR order (default \"auto\") q Integer: MA order ARMA (default 0) p_max Integer: Maximum AR order p=\"auto\" (default 6) pooling Character: \"global\" (default), \"voxel\", \"run\", \"parcel\" runs Integer vector: Run identifiers run-aware estimation parcels Integer vector: Parcel memberships parcel-based pooling exact_first Character: \"ar1\" \"none\" exact AR(1) scaling compute_residuals Logical: Whether compute residuals first (default TRUE)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/dot-prewhiten_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prewhiten fMRI data using AR/ARMA models — .prewhiten_data","text":"List containing: Y_whitened Whitened data matrix X_whitened Whitened trial design matrix (provided) Z_whitened Whitened experimental design (provided) Nuisance_whitened Whitened nuisance regressors (provided) whiten_plan fmriAR plan object diagnostics applied Logical: Whether whitening applied","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/estimate_voxel_hrf.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Voxel-wise HRF Basis Coefficients — estimate_voxel_hrf","title":"Estimate Voxel-wise HRF Basis Coefficients — estimate_voxel_hrf","text":"Fits GLM estimate HRF basis coefficients every voxel.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/estimate_voxel_hrf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Voxel-wise HRF Basis Coefficients — estimate_voxel_hrf","text":"","code":"estimate_voxel_hrf(Y, events, basis, nuisance_regs = NULL)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/estimate_voxel_hrf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Voxel-wise HRF Basis Coefficients — estimate_voxel_hrf","text":"Y Numeric matrix BOLD data (time x voxels). events Data frame onset, duration condition columns. basis HRF object fmrihrf package. nuisance_regs Optional numeric matrix nuisance regressors.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/estimate_voxel_hrf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Voxel-wise HRF Basis Coefficients — estimate_voxel_hrf","text":"VoxelHRF object containing least: coefficients Matrix HRF basis coefficients. basis HRF basis object used. conditions Character vector modeled conditions.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/estimate_voxel_hrf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Voxel-wise HRF Basis Coefficients — estimate_voxel_hrf","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(1) Y <- matrix(rnorm(100), 50, 2) events <- data.frame(onset = c(5, 25), duration = 1,                      condition = \"A\") basis <- fmrihrf::hrf_gamma() sframe <- fmrihrf::sampling_frame(blocklens = nrow(Y), TR = 1) times <- fmrihrf::samples(sframe, global = TRUE) rset <- fmrihrf::regressor_set(onsets = events$onset,                                fac = factor(1:nrow(events)),                                hrf = basis, duration = events$duration,                                span = 30) X <- fmrihrf::evaluate(rset, grid = times, precision = 0.1, method = \"conv\") coef <- matrix(rnorm(ncol(X) * ncol(Y)), ncol(X), ncol(Y)) Y <- X %*% coef + Y * 0.1 est <- estimate_voxel_hrf(Y, events, basis) str(est) } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fast_reml_lambda.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast analytical REML estimation for single variance component — fast_reml_lambda","title":"Fast analytical REML estimation for single variance component — fast_reml_lambda","text":"single variance component model, REML estimate \\(\\lambda = \\sigma_e^2/\\sigma_u^2\\) closed-form solution can computed efficiently.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fast_reml_lambda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast analytical REML estimation for single variance component — fast_reml_lambda","text":"omega Transformed response vector Q'y theta Transformed eigenvalues tol Convergence tolerance Newton iterations max_iter Maximum Newton iterations","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fast_reml_lambda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fast analytical REML estimation for single variance component — fast_reml_lambda","text":"Estimated variance ratio \\(\\lambda\\)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fit_oasis_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit OASIS with HRF Grid Search — fit_oasis_grid","title":"Fit OASIS with HRF Grid Search — fit_oasis_grid","text":"Fits OASIS models different HRF parameters selects best","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fit_oasis_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit OASIS with HRF Grid Search — fit_oasis_grid","text":"","code":"fit_oasis_grid(Y, onsets, sframe, hrf_grid, ridge_x = 0.01, ridge_b = 0.01)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fit_oasis_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit OASIS with HRF Grid Search — fit_oasis_grid","text":"Y Data matrix (time x voxels) onsets Event onset times sframe Sampling frame hrf_grid List HRF models test ridge_x Ridge parameter design matrix ridge_b Ridge parameter aggregator","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fit_oasis_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit OASIS with HRF Grid Search — fit_oasis_grid","text":"List best HRF index, parameters, beta estimates","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fmrilss-package.html","id":null,"dir":"Reference","previous_headings":"","what":"fmrilss: Least Squares Separate (LSS) Analysis for fMRI Data — fmrilss-package","title":"fmrilss: Least Squares Separate (LSS) Analysis for fMRI Data — fmrilss-package","text":"package implements efficient least squares separate (LSS) analysis functional magnetic resonance imaging (fMRI) data. LSS used estimate trial--trial activation patterns event-related fMRI designs.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fmrilss-package.html","id":"main-functions","dir":"Reference","previous_headings":"","what":"Main functions","title":"fmrilss: Least Squares Separate (LSS) Analysis for fMRI Data — fmrilss-package","text":"lss: Main function performing LSS analysis lss_naive: Naive LSS implementation reference project_confounds: R implementation projecting confounds project_confounds_cpp: Fast C++ confound projection lss_beta_cpp: Vectorized C++ LSS beta computation get_data_matrix: Helper function data extraction","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fmrilss-package.html","id":"features","dir":"Reference","previous_headings":"","what":"Features","title":"fmrilss: Least Squares Separate (LSS) Analysis for fMRI Data — fmrilss-package","text":"Optimized C++ implementation using vectorized matrix algebra Memory-efficient projection without forming Q matrices Cholesky decomposition numerical stability Fallback R implementation QR decomposition Support various design matrix configurations Robust numerical handling edge cases OpenMP support multi-core processing","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/fmrilss-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"fmrilss: Least Squares Separate (LSS) Analysis for fMRI Data — fmrilss-package","text":"Name <.email@example.com>","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_lwu_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Synthetic fMRI Data with LWU HRF — generate_lwu_data","title":"Generate Synthetic fMRI Data with LWU HRF — generate_lwu_data","text":"Creates synthetic fMRI time series using specified LWU HRF parameters","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_lwu_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Synthetic fMRI Data with LWU HRF — generate_lwu_data","text":"","code":"generate_lwu_data(   onsets,   tau = 6,   sigma = 2.5,   rho = 0.35,   TR = 1,   total_time = 300,   n_voxels = 10,   amplitudes = NULL,   noise_sd = 0.2,   seed = NULL )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_lwu_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Synthetic fMRI Data with LWU HRF — generate_lwu_data","text":"onsets Vector event onset times seconds tau LWU tau parameter (time--peak) sigma LWU sigma parameter (width) rho LWU rho parameter (undershoot amplitude) TR Repetition time seconds total_time Total scan time seconds n_voxels Number voxels simulate amplitudes Event amplitudes (scalar vector) noise_sd Standard deviation noise seed Random seed","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_lwu_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Synthetic fMRI Data with LWU HRF — generate_lwu_data","text":"List Y (data matrix), true_hrf, true_betas, design info","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_rapid_design.html","id":null,"dir":"Reference","previous_headings":"","what":"OASIS HRF Recovery Testing Functions — generate_rapid_design","title":"OASIS HRF Recovery Testing Functions — generate_rapid_design","text":"Functions test OASIS's ability recover HRF parameters rapid event-related designs overlapping HRFs. Generate Rapid Event-Related Design","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_rapid_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"OASIS HRF Recovery Testing Functions — generate_rapid_design","text":"","code":"generate_rapid_design(   n_events = 25,   total_time = 300,   min_isi = 2,   max_isi = 4,   seed = NULL )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_rapid_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"OASIS HRF Recovery Testing Functions — generate_rapid_design","text":"n_events Number events generate total_time Total time seconds min_isi Minimum inter-stimulus interval seconds max_isi Maximum inter-stimulus interval seconds seed Random seed reproducibility","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_rapid_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"OASIS HRF Recovery Testing Functions — generate_rapid_design","text":"Numeric vector event onset times","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/generate_rapid_design.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"OASIS HRF Recovery Testing Functions — generate_rapid_design","text":"Creates rapid event-related design specified ISI range","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/get_data_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Data Matrix from Dataset — get_data_matrix","title":"Extract Data Matrix from Dataset — get_data_matrix","text":"Helper function extract data matrix various dataset formats. placeholder customized based data format.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/get_data_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Data Matrix from Dataset — get_data_matrix","text":"","code":"get_data_matrix(dset)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/get_data_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Data Matrix from Dataset — get_data_matrix","text":"dset Dataset object (format depends specific use case)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/get_data_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Data Matrix from Dataset — get_data_matrix","text":"numeric matrix rows timepoints columns voxels","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/list_to_workspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert R list back to MixedWorkspace — list_to_workspace","title":"Convert R list back to MixedWorkspace — list_to_workspace","text":"Convert R list back MixedWorkspace","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lsa.html","id":null,"dir":"Reference","previous_headings":"","what":"Least Squares All (LSA) Analysis — lsa","title":"Least Squares All (LSA) Analysis — lsa","text":"Performs standard multiple regression analysis trial regressors fitted simultaneously. provides reference comparison Least Squares Separate (LSS) approach.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lsa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Least Squares All (LSA) Analysis — lsa","text":"","code":"lsa(Y, X, Z = NULL, Nuisance = NULL, method = c(\"r\", \"cpp\"))"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lsa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Least Squares All (LSA) Analysis — lsa","text":"Y numeric matrix rows timepoints columns voxels/features. dependent variable data. X numeric matrix rows timepoints columns trial-specific regressors. column represents single trial event. Z numeric matrix nuisance regressors (e.g., motion parameters, drift terms). Defaults NULL. Nuisance alias Z, provided consistency LSS interface. Z Nuisance provided, Z takes precedence. method Character string specifying computational method: \"r\" - Pure R implementation using lm.fit \"cpp\" - C++ implementation better performance","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lsa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Least Squares All (LSA) Analysis — lsa","text":"numeric matrix size T × V containing beta estimates   trial regressor (rows) voxel (columns).","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lsa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Least Squares All (LSA) Analysis — lsa","text":"LSA fits model: Y = X*beta + Z*gamma + error, trial regressors X estimated simultaneously. contrast LSS, fits trial separately treating trials nuisance regressors.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lsa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Least Squares All (LSA) Analysis — lsa","text":"","code":"# Generate example data n_timepoints <- 100 n_trials <- 10 n_voxels <- 50  # Create trial design matrix X <- matrix(0, n_timepoints, n_trials) for(i in 1:n_trials) {   start <- (i-1) * 8 + 1   if(start + 5 <= n_timepoints) {     X[start:(start+5), i] <- 1   } }  # Create data with some signal Y <- matrix(rnorm(n_timepoints * n_voxels), n_timepoints, n_voxels) true_betas <- matrix(rnorm(n_trials * n_voxels, 0, 0.5), n_trials, n_voxels) for(i in 1:n_trials) {   Y <- Y + X[, i] %*% matrix(true_betas[i, ], 1, n_voxels) }  # Run LSA analysis beta_estimates <- lsa(Y, X)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":null,"dir":"Reference","previous_headings":"","what":"Least Squares Separate (LSS) Analysis — lss","title":"Least Squares Separate (LSS) Analysis — lss","text":"Computes trial-wise beta estimates using Least Squares Separate approach Mumford et al. (2012). method fits separate GLM trial, trial interest trials separate regressors.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Least Squares Separate (LSS) Analysis — lss","text":"","code":"lss(   Y,   X,   Z = NULL,   Nuisance = NULL,   method = c(\"r_optimized\", \"cpp_optimized\", \"r_vectorized\", \"cpp\", \"naive\", \"oasis\"),   block_size = 96,   oasis = list(),   prewhiten = NULL )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Least Squares Separate (LSS) Analysis — lss","text":"Y numeric matrix size n × V n number timepoints V number voxels/variables X numeric matrix size n × T T number trials. column represents design one trial Z numeric matrix size n × F representing experimental regressors include trial-wise models. regressors want model get beta estimates , trial-wise (e.g., intercept, condition effects, block effects). NULL, intercept-design used. Defaults NULL Nuisance numeric matrix size n × N representing nuisance regressors projected LSS analysis (e.g., motion parameters, physiological noise). NULL, nuisance projection performed. Defaults NULL method Character string specifying implementation use. Options : \"r_optimized\" - Optimized R implementation (recommended, default) \"cpp_optimized\" - Optimized C++ implementation parallel support \"r_vectorized\" - Standard R vectorized implementation \"cpp\" - Standard C++ implementation \"naive\" - Simple loop-based R implementation (testing) \"oasis\" - OASIS method HRF support ridge regularization block_size integer specifying voxel block size parallel processing, applicable `method = \"cpp_optimized\"`. Defaults 96. oasis list options OASIS method. See Details available options. prewhiten list prewhitening options using fmriAR. See Details available options.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Least Squares Separate (LSS) Analysis — lss","text":"numeric matrix size T × V containing trial-wise beta estimates.   Note: Currently returns estimates trial regressors (X). Beta   estimates experimental regressors (Z) computed returned.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Least Squares Separate (LSS) Analysis — lss","text":"LSS approach fits separate GLM trial, model includes: trial interest (column X) trials combined (sum columns X) Experimental regressors (Z matrix) - modeled get beta estimates trial-wise Nuisance regressors provided, first projected Y X using standard linear regression residualization. using method=\"oasis\", following options available oasis list: design_spec: list building trial-wise designs event onsets using fmrihrf.     Must contain: sframe (sampling frame), cond (list onsets,     hrf, optionally span), optionally others (list conditions     modeled nuisances). provided, X can NULL constructed automatically. K: Explicit basis dimension multi-basis HRF models (e.g., 3 SPMG3).     provided, auto-detected X dimensions defaults 1 single-basis HRFs. ridge_mode: Either \"absolute\" (default) \"fractional\". absolute mode,     ridge_x ridge_b used directly regularization parameters. fractional mode,     represent fractions maximum eigenvalue adaptive regularization. ridge_x: Ridge parameter trial-specific regressors (default 0). Controls     regularization strength individual trial estimates. ridge_b: Ridge parameter aggregator regressor (default 0). Controls     regularization strength sum trials. return_se: Logical, whether return standard errors (default FALSE). TRUE,     returns list beta (trial estimates) se (standard errors) components. return_diag: Logical, whether return design diagnostics (default FALSE).     TRUE, includes diagnostic information design matrix structure. block_cols: Integer, voxel block size memory-efficient processing (default 4096).     Larger values use memory may faster systems sufficient RAM. whiten: Logical, whether apply AR(1) whitening (default FALSE). TRUE,     estimates AR(1) coefficients pre-whitens data account temporal autocorrelation. ntrials: Explicit number trials (used K > 1 determine output dimensions).     provided, calculated ncol(X) / K. hrf_grid: Vector HRF indices grid-based HRF selection (advanced use).     Allows testing multiple HRF shapes simultaneously. using prewhiten parameter, following options available: method: Character, \"ar\" (default), \"arma\", \"none\" noise model type. p: Integer \"auto\" AR order (default \"auto\"). q: Integer MA order ARMA models (default 0). p_max: Maximum AR order p=\"auto\" (default 6). pooling: Character, \"global\" (default), \"voxel\", \"run\", \"parcel\" parameter estimation strategy. runs: Integer vector run identifiers run-aware estimation. parcels: Integer vector parcel memberships parcel-based pooling. exact_first: Character, \"ar1\" \"none\" exact AR(1) scaling segment starts. Prewhitening applied LSS analysis account temporal autocorrelation fMRI time series. fmriAR package provides flexible AR/ARMA modeling various pooling strategies. backward compatibility, old oasis$whiten = \"ar1\" syntax still supported converted equivalent prewhiten settings. OASIS method provides mathematically equivalent computationally optimized version standard LSS. reformulates per-trial GLM fitting single matrix operation, eliminating redundant computations. particularly beneficial designs many trials processing large datasets. K > 1 (multi-basis HRFs), output K*ntrials rows, basis functions trial arranged sequentially.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Least Squares Separate (LSS) Analysis — lss","text":"Mumford, J. ., Turner, B. O., Ashby, F. G., & Poldrack, R. . (2012). Deconvolving BOLD activation event-related designs multivoxel pattern classification analyses. NeuroImage, 59(3), 2636-2643.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Least Squares Separate (LSS) Analysis — lss","text":"","code":"# Generate example data n_timepoints <- 100 n_trials <- 10 n_voxels <- 50  # Create trial design matrix X <- matrix(0, n_timepoints, n_trials) for(i in 1:n_trials) {   start <- (i-1) * 8 + 1   if(start + 5 <= n_timepoints) {     X[start:(start+5), i] <- 1   } }  # Create data with some signal Y <- matrix(rnorm(n_timepoints * n_voxels), n_timepoints, n_voxels) true_betas <- matrix(rnorm(n_trials * n_voxels, 0, 0.5), n_trials, n_voxels) for(i in 1:n_trials) {   Y <- Y + X[, i] %*% matrix(true_betas[i, ], 1, n_voxels) }  # Run LSS analysis beta_estimates <- lss(Y, X)  # With experimental regressors (intercept + condition effects) Z <- cbind(1, scale(1:n_timepoints)) beta_estimates_with_regressors <- lss(Y, X, Z = Z)  # With nuisance regression (motion parameters) Nuisance <- matrix(rnorm(n_timepoints * 6), n_timepoints, 6) beta_estimates_clean <- lss(Y, X, Z = Z, Nuisance = Nuisance)  if (FALSE) { # \\dontrun{ # Using OASIS method with ridge regularization beta_oasis <- lss(Y, X, method = \"oasis\",                   oasis = list(ridge_x = 0.1, ridge_b = 0.1,                               ridge_mode = \"fractional\"))  # OASIS with standard errors result_with_se <- lss(Y, X, method = \"oasis\",                      oasis = list(return_se = TRUE)) beta_estimates <- result_with_se$beta standard_errors <- result_with_se$se  # Building design from event onsets using fmrihrf   sframe <- sampling_frame(blocklens = 200, TR = 1.0)    # OASIS with automatic design construction   beta_auto <- lss(Y, X = NULL, method = \"oasis\",                    oasis = list(                      design_spec = list(                        sframe = sframe,                        cond = list(                          onsets = c(10, 30, 50, 70, 90, 110, 130, 150),                          hrf = HRF_SPMG1,                          span = 25                        ),                        others = list(                          list(onsets = c(20, 40, 60, 80, 100, 120, 140))                        )                      )                    ))    # Multi-basis HRF example (3 basis functions per trial)   beta_multibasis <- lss(Y, X = NULL, method = \"oasis\",                         oasis = list(                           design_spec = list(                             sframe = sframe,                             cond = list(                               onsets = c(10, 30, 50, 70, 90),                               hrf = HRF_SPMG3,  # 3-basis HRF                               span = 30                             )                           ),                           K = 3  # Explicit basis dimension                         ))   # Returns 15 rows (5 trials * 3 basis functions) } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_beta_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","title":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","text":"Fast C++ implementation least squares separate (LSS) beta estimation using vectorized matrix operations. Computes trial betas single pass without loops.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_beta_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","text":"","code":"lss_beta_cpp(C_projected, Y_projected)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_beta_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","text":"C_projected Projected trial regressors (n x T) project_confounds_cpp Y_projected Projected data (n x V) project_confounds_cpp","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_beta_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","text":"Beta matrix (T x V) LSS estimates trial voxel","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_beta_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","text":"vectorized implementation computes LSS betas simultaneously using matrix algebra. significantly faster per-trial loops automatically benefits BLAS multithreading. algorithm handles numerical edge cases setting problematic denominators NaN. best performance large datasets, ensure R installation uses optimized BLAS (like OpenBLAS Intel MKL).","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_beta_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vectorized LSS Beta Computation Using C++ — lss_beta_cpp","text":"","code":"if (FALSE) { # \\dontrun{ # After projecting out confounds result <- project_confounds_cpp(X_confounds, Y_data, C_trials) betas <- lss_beta_cpp(result$Q_dmat_ran, result$residual_data) } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_cpp_optimized.html","id":null,"dir":"Reference","previous_headings":"","what":"A wrapper for the optimized C++ LSS implementation — lss_cpp_optimized","title":"A wrapper for the optimized C++ LSS implementation — lss_cpp_optimized","text":"wrapper optimized C++ LSS implementation","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_cpp_optimized.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A wrapper for the optimized C++ LSS implementation — lss_cpp_optimized","text":"","code":"lss_cpp_optimized(Y, bdes)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_cpp_optimized.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A wrapper for the optimized C++ LSS implementation — lss_cpp_optimized","text":"Y voxel time data matrix bdes block design list created block_design","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_cpp_optimized.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A wrapper for the optimized C++ LSS implementation — lss_cpp_optimized","text":"matrix beta estimates","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_fused_optim_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Fused Single-Pass LSS Solver (C++) — lss_fused_optim_cpp","title":"Fused Single-Pass LSS Solver (C++) — lss_fused_optim_cpp","text":"function computes Least Squares-Separate (LSS) beta estimates using memory-efficient, single-pass algorithm. fuses projection estimation steps, processing voxels parallel blocks maximize cache efficiency.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_fused_optim_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fused Single-Pass LSS Solver (C++) — lss_fused_optim_cpp","text":"","code":"lss_fused_optim_cpp(X, Y, C, block_size = 96L)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_fused_optim_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fused Single-Pass LSS Solver (C++) — lss_fused_optim_cpp","text":"X nuisance regressor matrix (confounds). Y data matrix (e.g., fMRI data). C trial-wise design matrix. block_size number voxels process parallel block.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_fused_optim_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fused Single-Pass LSS Solver (C++) — lss_fused_optim_cpp","text":"matrix LSS beta estimates.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_naive.html","id":null,"dir":"Reference","previous_headings":"","what":"Naive Least Squares Separate (LSS) Analysis — lss_naive","title":"Naive Least Squares Separate (LSS) Analysis — lss_naive","text":"Performs LSS analysis using naive approach trial model fit separately. conceptually simplest implementation less efficient optimized lss function.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_naive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Naive Least Squares Separate (LSS) Analysis — lss_naive","text":"","code":"lss_naive(Y = NULL, bdes, dset = NULL)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_naive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Naive Least Squares Separate (LSS) Analysis — lss_naive","text":"Y numeric matrix rows timepoints columns voxels/features. NULL, function attempt extract data dset. bdes list containing design matrices components: dmat_base: Base design matrix (e.g., intercept, drift terms) dmat_fixed: Fixed effects design matrix (optional) dmat_ran: Random/trial design matrix LSS analysis fixed_ind: Indices fixed effects (optional) dset Optional dataset object. provided Y NULL, data extracted using get_data_matrix.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_naive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Naive Least Squares Separate (LSS) Analysis — lss_naive","text":"numeric matrix dimensions (n_events x n_voxels) containing LSS beta estimates trial voxel.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_naive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Naive Least Squares Separate (LSS) Analysis — lss_naive","text":"function implements naive LSS approach trial, separate GLM fitted includes: base regressors (intercept, drift, etc.) fixed effects regressors () current trial's regressor trial design matrix less efficient optimized lss function, implementation conceptually simpler can serve reference validation purposes.","code":""},{"path":[]},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_naive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Naive Least Squares Separate (LSS) Analysis — lss_naive","text":"","code":"if (FALSE) { # \\dontrun{ # Using same setup as lss() examples beta_estimates_naive <- lss_naive(Y = Y, bdes = bdes)  # Compare with optimized version beta_estimates_fast <- lss(Y = Y, bdes = bdes) max(abs(beta_estimates_naive - beta_estimates_fast)) } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_optimized.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimized LSS Analysis (Pure R) — lss_optimized","title":"Optimized LSS Analysis (Pure R) — lss_optimized","text":"optimized version LSS analysis avoids creating large intermediate matrices, providing significant speedup lower memory usage pure R implementation.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_optimized.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimized LSS Analysis (Pure R) — lss_optimized","text":"","code":"lss_optimized(Y = NULL, bdes, dset = NULL, use_cpp = TRUE)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_optimized.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimized LSS Analysis (Pure R) — lss_optimized","text":"Y numeric matrix rows timepoints columns voxels/features. bdes list containing design matrices. dset Optional dataset object. use_cpp Logical. TRUE (default), uses C++ implementation. FALSE, uses new optimized R implementation.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_optimized.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimized LSS Analysis (Pure R) — lss_optimized","text":"numeric matrix LSS beta estimates.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform LSS using Voxel-wise HRFs — lss_with_hrf","title":"Perform LSS using Voxel-wise HRFs — lss_with_hrf","text":"Computes trial-wise beta estimates using voxel-specific HRFs.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform LSS using Voxel-wise HRFs — lss_with_hrf","text":"","code":"lss_with_hrf(   Y,   events,   hrf_estimates,   nuisance_regs = NULL,   engine = \"R\",   chunk_size = 5000,   verbose = TRUE,   backing_dir = NULL )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform LSS using Voxel-wise HRFs — lss_with_hrf","text":"Y Numeric matrix BOLD data (time x voxels). events Data frame onset, duration condition columns. hrf_estimates VoxelHRF object returned estimate_voxel_hrf. nuisance_regs Optional numeric matrix nuisance regressors. engine Computational engine: \"R\" pure R implementation (default), \"C++\" optimized C++ (experimental). chunk_size Number voxels process per batch (C++ engine ). verbose Logical; display progress bar. backing_dir Directory bigmemory backing files. NULL, temporary directory used (C++ engine ).","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform LSS using Voxel-wise HRFs — lss_with_hrf","text":"object class LSSBeta C++ engine, numeric matrix   (n_trials x n_vox) R engine.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform LSS using Voxel-wise HRFs — lss_with_hrf","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(1) Y <- matrix(rnorm(100), 50, 2) events <- data.frame(onset = c(5, 25), duration = 1,                      condition = \"A\") basis <- fmrihrf::hrf_gamma() sframe <- fmrihrf::sampling_frame(blocklens = nrow(Y), TR = 1) times <- fmrihrf::samples(sframe, global = TRUE) rset <- fmrihrf::regressor_set(onsets = events$onset,                                fac = factor(1:nrow(events)),                                hrf = basis, duration = events$duration,                                span = 30) X <- fmrihrf::evaluate(rset, grid = times, precision = 0.1, method = \"conv\") coef <- matrix(rnorm(ncol(X) * ncol(Y)), ncol(X), ncol(Y)) Y <- X %*% coef + Y * 0.1 est <- estimate_voxel_hrf(Y, events, basis) betas <- lss_with_hrf(Y, events, est, verbose = FALSE, engine = \"R\") dim(betas) } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf_pure_r.html","id":null,"dir":"Reference","previous_headings":"","what":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","title":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","text":"Compute LSS trial-wise betas voxel HRF formed linear combination K basis kernels sampled TR grid.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf_pure_r.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","text":"","code":"lss_with_hrf_pure_r(   Y,   onset_idx,   durations = NULL,   hrf_basis_kernels,   coefficients,   Z = NULL,   Nuisance = NULL,   verbose = FALSE,   method = c(\"r\", \"cpp\", \"cpp_arma\", \"cpp_omp\") )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf_pure_r.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","text":"Y numeric matrix (n_time x n_vox) onset_idx integer vector (length n_trials), 1-based TR indices durations numeric vector (length n_trials), TRs; 0 means impulse. Uses inclusive indexing: duration = d, samples o:(o+d) 1. hrf_basis_kernels numeric matrix (L x K), K basis kernels TR grid coefficients numeric matrix (K x n_vox), voxel-wise HRF weights Z optional numeric matrix (n_time x F) experimental regressors; NULL, intercept (column 1s) used. Nuisance optional numeric matrix (n_time x q) confounds project verbose logical; print progress every 1000 voxels method character: \"r\" (default, pure R), \"cpp\" (C++ backend), \"cpp_arma\" (Armadillo backend), \"cpp_omp\" (OpenMP parallel backend). Falls back automatically: cpp_omp -> cpp_arma -> cpp -> r.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf_pure_r.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","text":"numeric matrix (n_trials x n_vox) trial-wise beta estimates","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf_pure_r.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","text":"**Design & nuisance handling match `lss()`**:   - trial--interest (Xi) sum trials (Xother)     included per-trial GLM.   - `Nuisance` supplied, projected **Y** trial     regressors LSS (standard residualization). Experimental regressors     `Z` ** residualized, matching `lss()` documentation.   - `Z` `NULL`, intercept-design used.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/lss_with_hrf_pure_r.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Least Squares Separate with voxel-wise HRF (basis-weighted) — lss_with_hrf_pure_r","text":"","code":"if (FALSE) { # \\dontrun{ # Minimal use (R backend): betas <- lss_with_hrf_pure_r(Y, onset_idx, durations, basis, coeffs, Z = NULL, Nuisance = NULL) # Or with C++ backend: betas <- lss_with_hrf_pure_r(Y, onset_idx, durations, basis, coeffs, method = \"cpp\") } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_multi_voxel_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimized multi-voxel mixed model estimation — mixed_multi_voxel_cpp","title":"Optimized multi-voxel mixed model estimation — mixed_multi_voxel_cpp","text":"Uses precomputed workspace parallel processing efficiently estimate mixed models across many voxels.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_multi_voxel_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimized multi-voxel mixed model estimation — mixed_multi_voxel_cpp","text":"","code":"mixed_multi_voxel_cpp(Y, ws_list, compute_se = FALSE, n_threads = 0L)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_multi_voxel_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimized multi-voxel mixed model estimation — mixed_multi_voxel_cpp","text":"Y Response matrix (n × V) V number voxels ws_list Precomputed workspace (R list) compute_se Whether compute standard errors n_threads Number OpenMP threads (0 = auto)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_multi_voxel_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimized multi-voxel mixed model estimation — mixed_multi_voxel_cpp","text":"List matrices estimates across voxels","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute.html","id":null,"dir":"Reference","previous_headings":"","what":"Precompute Workspace for Optimized Mixed Model — mixed_precompute","title":"Precompute Workspace for Optimized Mixed Model — mixed_precompute","text":"Performs expensive matrix computations depend response vector, allowing efficient reuse across multiple voxels.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Precompute Workspace for Optimized Mixed Model — mixed_precompute","text":"","code":"mixed_precompute(X, Z, K = NULL)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Precompute Workspace for Optimized Mixed Model — mixed_precompute","text":"X Fixed effects design matrix (n × p) Z Random effects design matrix (n × q) K Kinship/covariance matrix random effects (q × q)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Precompute Workspace for Optimized Mixed Model — mixed_precompute","text":"Workspace object use mixed_solve_optimized","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute_workspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Precompute workspace for mixed model optimization — mixed_precompute_workspace","title":"Precompute workspace for mixed model optimization — mixed_precompute_workspace","text":"Performs expensive computations depend response vector y, can reused across multiple voxels.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute_workspace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Precompute workspace for mixed model optimization — mixed_precompute_workspace","text":"","code":"mixed_precompute_workspace(X, Z, K)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute_workspace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Precompute workspace for mixed model optimization — mixed_precompute_workspace","text":"X Fixed effects design matrix (n × p) Z Random effects design matrix (n × q) K Kinship/covariance matrix random effects (q × q)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_precompute_workspace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Precompute workspace for mixed model optimization — mixed_precompute_workspace","text":"MixedWorkspace object containing precomputed matrices","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_single_voxel_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast single-voxel mixed model estimation using precomputed workspace — mixed_single_voxel_cpp","title":"Fast single-voxel mixed model estimation using precomputed workspace — mixed_single_voxel_cpp","text":"Fast single-voxel mixed model estimation using precomputed workspace","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_single_voxel_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast single-voxel mixed model estimation using precomputed workspace — mixed_single_voxel_cpp","text":"","code":"mixed_single_voxel_cpp(y, ws_list, compute_se = FALSE)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_single_voxel_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast single-voxel mixed model estimation using precomputed workspace — mixed_single_voxel_cpp","text":"y Response vector single voxel ws_list Precomputed workspace (R list) compute_se Whether compute standard errors","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_single_voxel_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fast single-voxel mixed model estimation using precomputed workspace — mixed_single_voxel_cpp","text":"List beta, u, Vu, Ve, optionally standard errors","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixed Model Solver — mixed_solve","title":"Mixed Model Solver — mixed_solve","text":"Solves mixed models random effects using REML ML estimation. function provides unified interface mixed model estimation, similar lss/lsa functions package.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mixed Model Solver — mixed_solve","text":"","code":"mixed_solve(   Y,   X = NULL,   Z = NULL,   K = NULL,   Nuisance = NULL,   method = c(\"REML\", \"ML\"),   bounds = c(1e-09, 1e+09),   SE = FALSE,   return_Hinv = FALSE )  mixed_solve_cpp(   Y,   X = NULL,   Z = NULL,   K = NULL,   Nuisance = NULL,   method = c(\"REML\", \"ML\"),   bounds = c(1e-09, 1e+09),   SE = FALSE,   return_Hinv = FALSE )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mixed Model Solver — mixed_solve","text":"Y Response vector matrix. matrix, column treated separate response variable. X Design matrix fixed effects. NULL, defaults intercept . Z Design matrix random effects. NULL, defaults identity matrix. K Kinship matrix random effects. NULL, defaults identity matrix. Nuisance alias X, provided consistency lss/lsa interface. X Nuisance provided, X takes precedence. method Character string specifying estimation method: \"REML\" - Restricted Maximum Likelihood (default) \"ML\" - Maximum Likelihood bounds Numeric vector length 2 specifying bounds variance component optimization. Defaults c(1e-9, 1e9). SE Logical, whether compute return standard errors. Defaults FALSE. return_Hinv Logical, whether return inverse H matrix. Defaults FALSE.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mixed Model Solver — mixed_solve","text":"list containing: Vu Estimated variance component random effects. Ve Estimated variance component residuals. beta Estimated fixed effects coefficients. u Estimated random effects coefficients. LL Log-likelihood model. beta.SE Standard errors fixed effects coefficients (SE = TRUE). u.SE Standard errors random effects coefficients (SE = TRUE). Hinv Inverse H matrix (return_Hinv = TRUE).","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mixed Model Solver — mixed_solve","text":"function fits mixed model: Y = X*beta + Z*u + error, u ~ N(0, Vu*K) error ~ N(0, Ve*). variance components Vu Ve estimated using REML ML.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mixed Model Solver — mixed_solve","text":"","code":"if (FALSE) { # \\dontrun{ # Example with random data set.seed(123) n <- 100 Y <- rnorm(n) Z <- matrix(rnorm(n * 5), n, 5) K <- diag(5) X <- matrix(1, n, 1)  # Fit mixed model result <- mixed_solve(Y, X, Z, K) } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve_optimized.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimized Mixed Model Solver — mixed_solve_optimized","title":"Optimized Mixed Model Solver — mixed_solve_optimized","text":"optimized implementation mixed model estimation precomputes expensive matrix operations can reused across multiple voxels significant performance improvements.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve_optimized.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimized Mixed Model Solver — mixed_solve_optimized","text":"","code":"mixed_solve_optimized(   X,   Z,   Y,   K = NULL,   workspace = NULL,   compute_se = FALSE,   n_threads = 0 )"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve_optimized.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimized Mixed Model Solver — mixed_solve_optimized","text":"X Fixed effects design matrix (n × p) Z Random effects design matrix (n × q) Y Response data - can vector (single voxel) matrix (n × V multiple voxels) K Kinship/covariance matrix random effects (q × q). Defaults identity. workspace Precomputed workspace (optional, compute NULL) compute_se Whether compute standard errors (default: FALSE) n_threads Number OpenMP threads multi-voxel (0 = auto)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/mixed_solve_optimized.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimized Mixed Model Solver — mixed_solve_optimized","text":"List estimated parameters variance components","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/plot_hrf_comparison.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot HRF Recovery Comparison — plot_hrf_comparison","title":"Plot HRF Recovery Comparison — plot_hrf_comparison","text":"Creates visualization comparing true vs recovered HRFs","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/plot_hrf_comparison.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot HRF Recovery Comparison — plot_hrf_comparison","text":"","code":"plot_hrf_comparison(results, save_path = NULL)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/plot_hrf_comparison.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot HRF Recovery Comparison — plot_hrf_comparison","text":"results Output compare_hrf_recovery save_path Optional path save plot","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds.html","id":null,"dir":"Reference","previous_headings":"","what":"Project Out Confound Variables — project_confounds","title":"Project Out Confound Variables — project_confounds","text":"Computes orthogonal projection matrix Q = - X(X'X)^(-1)X' projects space spanned confound regressors X. useful advanced users want cache reuse projection matrices.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project Out Confound Variables — project_confounds","text":"","code":"project_confounds(X)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project Out Confound Variables — project_confounds","text":"X Confound design matrix (n x p) n number timepoints p number confound regressors","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project Out Confound Variables — project_confounds","text":"Projection matrix Q (n x n) projects column space X","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Project Out Confound Variables — project_confounds","text":"function uses QR decomposition numerical stability instead computing Moore-Penrose pseudoinverse directly. resulting matrix Q can applied data remove influence confound regressors.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project Out Confound Variables — project_confounds","text":"","code":"if (FALSE) { # \\dontrun{ # Create confound matrix (intercept + linear trend) n <- 100 X_confounds <- cbind(1, 1:n)  # Get projection matrix Q <- project_confounds(X_confounds)  # Apply to data to remove confounds Y_clean <- Q %*% Y_raw } # }"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Project Out Confounds Using C++ — project_confounds_cpp","title":"Project Out Confounds Using C++ — project_confounds_cpp","text":"Fast C++ implementation projecting confound variables data trial design matrices. uses Cholesky decomposition numerical stability avoids creating large projection matrices.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project Out Confounds Using C++ — project_confounds_cpp","text":"","code":"project_confounds_cpp(X_confounds, Y_data, C_trials)"},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project Out Confounds Using C++ — project_confounds_cpp","text":"X_confounds Confound design matrix (n x k) Y_data Data matrix (n x V) V number voxels C_trials Trial design matrix (n x T) T number trials","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project Out Confounds Using C++ — project_confounds_cpp","text":"List projected data (residual_data) projected trials (Q_dmat_ran)","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Project Out Confounds Using C++ — project_confounds_cpp","text":"function computes residuals Y - X(X'X)^(-1)X'Y C - X(X'X)^(-1)X'C without explicitly forming projection matrix Q = - X(X'X)^(-1)X'. approach uses ~100x less memory large n numerically stable.","code":""},{"path":"https://bbuchsbaum.github.io/fmrilss/reference/project_confounds_cpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project Out Confounds Using C++ — project_confounds_cpp","text":"","code":"if (FALSE) { # \\dontrun{ n <- 200; k <- 5; V <- 1000; T <- 50 X_confounds <- cbind(1, 1:n, rnorm(n*3))  # intercept + trend + noise Y_data <- matrix(rnorm(n*V), n, V) C_trials <- matrix(rnorm(n*T), n, T)  result <- project_confounds_cpp(X_confounds, Y_data, C_trials) } # }"}]
